{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": [
    "O0ojKc7jYwv-"
   ],
   "authorship_tag": "ABX9TyNd/Rr7AvFn44dXXbIIo9It"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_m3P_rSzOtM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702579355025,
     "user_tz": 300,
     "elapsed": 14896,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "f40d816a-4da1-42cb-fbdd-db6c8734fec6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "mkdir /content/processed_st12000\n",
    "cp /content/drive/MyDrive/CSC2233/processed_st12000/* /content/processed_st12000/\n",
    "mkdir /content/processed_st8000\n",
    "cp /content/drive/MyDrive/CSC2233/processed_st8000/* /content/processed_st8000/"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yu1US9CMeUJs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702399243296,
     "user_tz": 300,
     "elapsed": 26748,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "0267cc2c-dcd8-405c-e1f1-fb55cf63f179"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "drive.flush_and_unmount()"
   ],
   "metadata": {
    "id": "0MyVv2IleWmR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDDIAL4NzgYT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702398838306,
     "user_tz": 300,
     "elapsed": 249,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "ffb1962d-1b38-461a-df5b-211ff20337f5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/NickHauptvogel/csc2233-2023.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJSpwWk3zjhL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702398902965,
     "user_tz": 300,
     "elapsed": 63299,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "8b723390-1c92-4804-9544-f26e3f9be6df"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'csc2233-2023'...\n",
      "remote: Enumerating objects: 1217, done.\u001B[K\n",
      "remote: Counting objects: 100% (437/437), done.\u001B[K\n",
      "remote: Compressing objects: 100% (208/208), done.\u001B[K\n",
      "remote: Total 1217 (delta 241), reused 423 (delta 227), pack-reused 780\u001B[K\n",
      "Receiving objects: 100% (1217/1217), 712.61 MiB | 32.41 MiB/s, done.\n",
      "Resolving deltas: 100% (489/489), done.\n",
      "Updating files: 100% (869/869), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd csc2233-2023"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RqLoP2ezx7V",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702398988849,
     "user_tz": 300,
     "elapsed": 121,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "3567feb0-d5b8-4c8f-8df6-a7c01de39541"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/csc2233-2023\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git pull"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVejUTpgJS9n",
    "outputId": "001a87e9-5605-48f7-e1b0-e34136ebf21e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702400607930,
     "user_tz": 300,
     "elapsed": 1096,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "remote: Enumerating objects: 6, done.\u001B[K\n",
      "remote: Counting objects:  16% (1/6)\u001B[K\rremote: Counting objects:  33% (2/6)\u001B[K\rremote: Counting objects:  50% (3/6)\u001B[K\rremote: Counting objects:  66% (4/6)\u001B[K\rremote: Counting objects:  83% (5/6)\u001B[K\rremote: Counting objects: 100% (6/6)\u001B[K\rremote: Counting objects: 100% (6/6), done.\u001B[K\n",
      "remote: Compressing objects:  33% (1/3)\u001B[K\rremote: Compressing objects:  66% (2/3)\u001B[K\rremote: Compressing objects: 100% (3/3)\u001B[K\rremote: Compressing objects: 100% (3/3), done.\u001B[K\n",
      "remote: Total 6 (delta 3), reused 6 (delta 3), pack-reused 0\u001B[K\n",
      "Unpacking objects:  16% (1/6)\rUnpacking objects:  33% (2/6)\rUnpacking objects:  50% (3/6)\rUnpacking objects:  66% (4/6)\rUnpacking objects:  83% (5/6)\rUnpacking objects: 100% (6/6)\rUnpacking objects: 100% (6/6), 11.81 KiB | 5.90 MiB/s, done.\n",
      "From https://github.com/NickHauptvogel/csc2233-2023\n",
      "   b49f6b8..aa1bf9d  master     -> origin/master\n",
      "Updating bb04a4d..aa1bf9d\n",
      "Fast-forward\n",
      " results/tuned_model_st8000_2_exp3/results/bf_search.pkl                  | Bin \u001B[31m0\u001B[m -> \u001B[32m20048\u001B[m bytes\n",
      " .../results/test_score.pkl                                               | Bin\n",
      " .../results/train_score.pkl                                              | Bin\n",
      " results/tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18/latest        |   2 \u001B[31m--\u001B[m\n",
      " .../results/config.defaults.json                                         |   1 \u001B[31m-\u001B[m\n",
      " .../results/config.json                                                  |   1 \u001B[31m-\u001B[m\n",
      " .../results/scaler.pkl                                                   | Bin \u001B[31m848\u001B[m -> \u001B[32m0\u001B[m bytes\n",
      " .../variables.dat.data-00000-of-00001                                    | Bin \u001B[31m36720448\u001B[m -> \u001B[32m0\u001B[m bytes\n",
      " .../variables.dat.index                                                  | Bin \u001B[31m2620\u001B[m -> \u001B[32m0\u001B[m bytes\n",
      " .../variables.dat.meta                                                   | Bin \u001B[31m2810227\u001B[m -> \u001B[32m0\u001B[m bytes\n",
      " 10 files changed, 4 deletions(-)\n",
      " create mode 100644 results/tuned_model_st8000_2_exp3/results/bf_search.pkl\n",
      " rename results/{tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18 => tuned_model_st8000_2_exp3}/results/test_score.pkl (100%)\n",
      " rename results/{tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18 => tuned_model_st8000_2_exp3}/results/train_score.pkl (100%)\n",
      " delete mode 100644 results/tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18/latest\n",
      " delete mode 100644 results/tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18/results/config.defaults.json\n",
      " delete mode 100644 results/tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18/results/config.json\n",
      " delete mode 100644 results/tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18/results/scaler.pkl\n",
      " delete mode 100644 results/tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18/variables.dat.data-00000-of-00001\n",
      " delete mode 100644 results/tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18/variables.dat.index\n",
      " delete mode 100644 results/tuned_model_st8000_2_exp3_test_2023-12-12_16-45-18/variables.dat.meta\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KypI0eEY076T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702399266944,
     "user_tz": 300,
     "elapsed": 19152,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "085fd125-8668-47df-b518-e5adab86624c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
      "ðŸ“¦ Installing...\n",
      "ðŸ“Œ Adjusting configuration...\n",
      "ðŸ©¹ Patching environment...\n",
      "â² Done in 0:00:13\n",
      "ðŸ” Restarting kernel...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/csc2233-2023"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXr0sghv17VJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702399275040,
     "user_tz": 300,
     "elapsed": 4,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "1d816a86-3301-4c25-c182-6a4c3f50b627"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/csc2233-2023\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!conda create -n myenv python=3.6"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vc1V4jib1ymc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702399314634,
     "user_tz": 300,
     "elapsed": 38640,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "d0ad6302-9784-401e-d4d5-813be5f2d7b7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
      "Solving environment: | \b\b/ \b\bdone\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.1.0\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/envs/myenv\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.6\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.11.17 |       hbcca054_0         151 KB  conda-forge\n",
      "    certifi-2016.9.26          |           py36_0         217 KB  conda-forge\n",
      "    libgcc-ng-13.2.0           |       h807b86a_3         755 KB  conda-forge\n",
      "    libgomp-13.2.0             |       h807b86a_3         412 KB  conda-forge\n",
      "    libnsl-2.0.1               |       hd590300_0          33 KB  conda-forge\n",
      "    libsqlite-3.44.2           |       h2797004_0         826 KB  conda-forge\n",
      "    libstdcxx-ng-13.2.0        |       h7e041cc_3         3.7 MB  conda-forge\n",
      "    libzlib-1.2.13             |       hd590300_5          60 KB  conda-forge\n",
      "    ncurses-6.4                |       h59595ed_2         864 KB  conda-forge\n",
      "    openssl-1.1.1w             |       hd590300_0         1.9 MB  conda-forge\n",
      "    pip-20.0.2                 |           py36_1         1.9 MB  conda-forge\n",
      "    python-3.6.15              |hb7a2778_0_cpython        38.4 MB  conda-forge\n",
      "    python_abi-3.6             |          2_cp36m           4 KB  conda-forge\n",
      "    setuptools-49.6.0          |   py36h5fab9bb_3         936 KB  conda-forge\n",
      "    sqlite-3.44.2              |       h2c6b66d_0         817 KB  conda-forge\n",
      "    tk-8.6.13                  |noxft_h4845f30_101         3.2 MB  conda-forge\n",
      "    wheel-0.36.2               |     pyhd3deb0d_0          31 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        54.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates-2023.11.17-hbcca054_0 \n",
      "  certifi            conda-forge/linux-64::certifi-2016.9.26-py36_0 \n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.40-h41732ed_0 \n",
      "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-13.2.0-h807b86a_3 \n",
      "  libgomp            conda-forge/linux-64::libgomp-13.2.0-h807b86a_3 \n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
      "  libsqlite          conda-forge/linux-64::libsqlite-3.44.2-h2797004_0 \n",
      "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-13.2.0-h7e041cc_3 \n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.13-hd590300_5 \n",
      "  ncurses            conda-forge/linux-64::ncurses-6.4-h59595ed_2 \n",
      "  openssl            conda-forge/linux-64::openssl-1.1.1w-hd590300_0 \n",
      "  pip                conda-forge/linux-64::pip-20.0.2-py36_1 \n",
      "  python             conda-forge/linux-64::python-3.6.15-hb7a2778_0_cpython \n",
      "  python_abi         conda-forge/linux-64::python_abi-3.6-2_cp36m \n",
      "  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n",
      "  setuptools         conda-forge/linux-64::setuptools-49.6.0-py36h5fab9bb_3 \n",
      "  sqlite             conda-forge/linux-64::sqlite-3.44.2-h2c6b66d_0 \n",
      "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
      "  wheel              conda-forge/noarch::wheel-0.36.2-pyhd3deb0d_0 \n",
      "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libsqlite-3.44.2     | 826 KB    | :   0% 0/1 [00:00<?, ?it/s]\n",
      "python-3.6.15        | 38.4 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "libgcc-ng-13.2.0     | 755 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "setuptools-49.6.0    | 936 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.13            | 3.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 1.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-13.2.0       | 412 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.44.2        | 817 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-13.2.0  | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 151 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.6       | 4 KB      | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.36.2         | 31 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libzlib-1.2.13       | 60 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2016.9.26    | 217 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.4          | 864 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.44.2     | 826 KB    | :   2% 0.019370322641665584/1 [00:00<00:07,  7.36s/it]\n",
      "\n",
      "libgcc-ng-13.2.0     | 755 KB    | :   2% 0.02117810992090524/1 [00:00<00:07,  7.49s/it]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.13            | 3.2 MB    | :   0% 0.00493661255696584/1 [00:00<00:31, 32.02s/it]\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :   0% 0.00040738642512046545/1 [00:00<06:46, 406.18s/it]\u001B[A\n",
      "\n",
      "\n",
      "setuptools-49.6.0    | 936 KB    | :   2% 0.017099511979260164/1 [00:00<00:09,  9.96s/it]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    | :   1% 0.00806380168087741/1 [00:00<00:28, 28.30s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :   4% 0.0435903474878898/1 [00:00<00:04,  4.98s/it]     \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.44.2     | 826 KB    | : 100% 1.0/1 [00:00<00:00,  4.33it/s]                 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.44.2     | 826 KB    | : 100% 1.0/1 [00:00<00:00,  4.33it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-13.2.0       | 412 KB    | :   4% 0.03883992281323933/1 [00:00<00:07,  7.32s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    | :  83% 0.8305715731303733/1 [00:00<00:00,  3.12it/s] \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.44.2        | 817 KB    | :   2% 0.019589228793679414/1 [00:00<00:17, 17.89s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  10% 0.10306876555547775/1 [00:00<00:02,  2.82s/it]\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 151 KB    | :  11% 0.1063088432814031/1 [00:00<00:03,  3.48s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-13.2.0  | 3.7 MB    | :   0% 0.004263402499128271/1 [00:00<01:28, 89.32s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.6       | 4 KB      | : 100% 1.0/1 [00:00<00:00,  2.53it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "libgcc-ng-13.2.0     | 755 KB    | : 100% 1.0/1 [00:00<00:00,  2.74it/s]                \u001B[A\u001B[A\n",
      "\n",
      "libgcc-ng-13.2.0     | 755 KB    | : 100% 1.0/1 [00:00<00:00,  2.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.36.2         | 31 KB     | :  52% 0.5220993594850387/1 [00:00<00:00,  1.26it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2016.9.26    | 217 KB    | :   7% 0.07390133558260902/1 [00:00<00:05,  5.94s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.4          | 864 KB    | :   2% 0.01852484187627341/1 [00:00<00:23, 24.44s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  15% 0.15195513656993362/1 [00:00<00:02,  2.48s/it]\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libnsl-2.0.1         | 33 KB     | :  49% 0.4904214559386973/1 [00:00<00:00,  1.03it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-13.2.0  | 3.7 MB    | :  61% 0.6139299598744711/1 [00:00<00:00,  1.67it/s]  \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libzlib-1.2.13       | 60 KB     | :  27% 0.26602584919140093/1 [00:00<00:01,  1.86s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-13.2.0       | 412 KB    | : 100% 1.0/1 [00:00<00:00,  2.17it/s]                \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgomp-13.2.0       | 412 KB    | : 100% 1.0/1 [00:00<00:00,  2.17it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  24% 0.2383210586954723/1 [00:00<00:01,  1.79s/it] \u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  39% 0.3890540359900445/1 [00:00<00:00,  1.16s/it]\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  1.51it/s]                 \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  1.51it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  49% 0.4868267780189562/1 [00:00<00:00,  1.12s/it]\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  58% 0.5780813372459405/1 [00:00<00:00,  1.30s/it]\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  69% 0.6925569227047913/1 [00:01<00:00,  1.15s/it]\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  82% 0.8168097823665332/1 [00:01<00:00,  1.03s/it]\u001B[A\n",
      "\n",
      "\n",
      "setuptools-49.6.0    | 936 KB    | : 100% 1.0/1 [00:01<00:00,  1.11s/it]                 \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "setuptools-49.6.0    | 936 KB    | : 100% 1.0/1 [00:01<00:00,  1.11s/it]\u001B[A\u001B[A\u001B[A\n",
      "python-3.6.15        | 38.4 MB   | :  94% 0.9394330963277933/1 [00:01<00:00,  1.04it/s]\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.13            | 3.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.59s/it]               \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.13            | 3.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.59s/it]\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.44.2        | 817 KB    | : 100% 1.0/1 [00:01<00:00,  1.40s/it]                 \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.44.2        | 817 KB    | : 100% 1.0/1 [00:01<00:00,  1.40s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 151 KB    | : 100% 1.0/1 [00:01<00:00,  1.45s/it]               \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 151 KB    | : 100% 1.0/1 [00:01<00:00,  1.45s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.6       | 4 KB      | : 100% 1.0/1 [00:01<00:00,  2.53it/s]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.36.2         | 31 KB     | : 100% 1.0/1 [00:01<00:00,  1.69s/it]               \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.36.2         | 31 KB     | : 100% 1.0/1 [00:01<00:00,  1.69s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2016.9.26    | 217 KB    | : 100% 1.0/1 [00:01<00:00,  1.55s/it]                \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2016.9.26    | 217 KB    | : 100% 1.0/1 [00:01<00:00,  1.55s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    | : 100% 1.0/1 [00:02<00:00,  3.12it/s]               \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libnsl-2.0.1         | 33 KB     | : 100% 1.0/1 [00:02<00:00,  2.86s/it]               \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libnsl-2.0.1         | 33 KB     | : 100% 1.0/1 [00:02<00:00,  2.86s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libzlib-1.2.13       | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.67s/it]                \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libzlib-1.2.13       | 60 KB     | : 100% 1.0/1 [00:02<00:00,  2.67s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-13.2.0  | 3.7 MB    | : 100% 1.0/1 [00:02<00:00,  3.18s/it]               \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libstdcxx-ng-13.2.0  | 3.7 MB    | : 100% 1.0/1 [00:02<00:00,  3.18s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.4          | 864 KB    | : 100% 1.0/1 [00:03<00:00,  3.11s/it]                \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.4          | 864 KB    | : 100% 1.0/1 [00:03<00:00,  3.11s/it]\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "                                                                        \n",
      "                                                                        \u001B[A\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "Preparing transaction: \\ \b\b| \b\b/ \b\bdone\n",
      "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
      "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate myenv\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#CPU"
   ],
   "metadata": {
    "id": "O0ojKc7jYwv-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "pip install -r requirements-cpu.txt --ignore-installed certifi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBXM8DSPYs-7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1701266259547,
     "user_tz": 300,
     "elapsed": 93731,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "dd47e6c0-f3cb-49a3-8659-0bbc06e6a615"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/thu-ml/zhusuan.git (from -r requirements-cpu.txt (line 15))\n",
      "  Cloning https://github.com/thu-ml/zhusuan.git to /tmp/pip-req-build-euu6563x\n",
      "  Running command git clone -q https://github.com/thu-ml/zhusuan.git /tmp/pip-req-build-euu6563x\n",
      "Collecting git+https://github.com/haowen-xu/tfsnippet.git@v0.2.0-alpha1 (from -r requirements-cpu.txt (line 16))\n",
      "  Cloning https://github.com/haowen-xu/tfsnippet.git (to revision v0.2.0-alpha1) to /tmp/pip-req-build-ccjkkdo3\n",
      "  Running command git clone -q https://github.com/haowen-xu/tfsnippet.git /tmp/pip-req-build-ccjkkdo3\n",
      "  Running command git checkout -q 7b43abdbdd29f1914dbc11b961b5d45b9de76653\n",
      "Collecting certifi\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162 kB 10.6 MB/s \n",
      "\u001B[?25hCollecting six==1.11.0\n",
      "  Downloading six-1.11.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting matplotlib==3.0.2\n",
      "  Downloading matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.9 MB 49.5 MB/s \n",
      "\u001B[?25hCollecting numpy==1.15.4\n",
      "  Downloading numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.9 MB 39.2 MB/s \n",
      "\u001B[?25hCollecting pandas==0.23.4\n",
      "  Downloading pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.9 MB 38.6 MB/s \n",
      "\u001B[?25hCollecting scipy==1.2.0\n",
      "  Downloading scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.6 MB 135 kB/s \n",
      "\u001B[?25hCollecting scikit_learn==0.20.2\n",
      "  Downloading scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.4 MB 35.5 MB/s \n",
      "\u001B[?25hCollecting tensorflow==1.12.0\n",
      "  Downloading tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.1 MB 86 kB/s \n",
      "\u001B[?25hCollecting tensorflow_probability==0.5.0\n",
      "  Downloading tensorflow_probability-0.5.0-py2.py3-none-any.whl (680 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680 kB 50.4 MB/s \n",
      "\u001B[?25hCollecting tqdm==4.28.1\n",
      "  Downloading tqdm-4.28.1-py2.py3-none-any.whl (45 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45 kB 3.0 MB/s \n",
      "\u001B[?25hCollecting imageio==2.4.1\n",
      "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 55.1 MB/s \n",
      "\u001B[?25hCollecting fs==2.3.0\n",
      "  Downloading fs-2.3.0-py2.py3-none-any.whl (124 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 124 kB 62.5 MB/s \n",
      "\u001B[?25hCollecting click==7.0\n",
      "  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81 kB 8.6 MB/s \n",
      "\u001B[?25hCollecting ipykernel\n",
      "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121 kB 51.1 MB/s \n",
      "\u001B[?25hCollecting pyyaml==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 640 kB 69.6 MB/s \n",
      "\u001B[?25hCollecting filelock>=3.0.10\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting frozendict>=1.2.0\n",
      "  Downloading frozendict-2.3.9-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100 kB 8.7 MB/s \n",
      "\u001B[?25hCollecting idx2numpy>=1.2.2\n",
      "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
      "Collecting lazy-object-proxy>=1.3.1\n",
      "  Downloading lazy_object_proxy-1.7.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (57 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57 kB 5.3 MB/s \n",
      "\u001B[?25hCollecting natsort>=5.3.3\n",
      "  Downloading natsort-8.2.0-py3-none-any.whl (37 kB)\n",
      "Collecting requests>=2.18.4\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 1.6 MB/s \n",
      "\u001B[?25hCollecting semver>=2.7.9\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 69.8 MB/s \n",
      "\u001B[?25hCollecting python-dateutil>=2.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 247 kB 35.0 MB/s \n",
      "\u001B[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103 kB 46.5 MB/s \n",
      "\u001B[?25hCollecting pytz>=2011k\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 502 kB 63.7 MB/s \n",
      "\u001B[?25hCollecting tensorboard<1.13.0,>=1.12.0\n",
      "  Downloading tensorboard-1.12.2-py3-none-any.whl (3.0 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0 MB 34.5 MB/s \n",
      "\u001B[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.6 MB 47.9 MB/s \n",
      "\u001B[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting wheel>=0.26\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting gast>=0.2.0\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42 kB 1.2 MB/s \n",
      "\u001B[?25hCollecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50 kB 6.3 MB/s \n",
      "\u001B[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 48.4 MB/s \n",
      "\u001B[?25hCollecting absl-py>=0.1.6\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 126 kB 38.5 MB/s \n",
      "\u001B[?25hCollecting pillow\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1 MB 41.1 MB/s \n",
      "\u001B[?25hCollecting setuptools\n",
      "  Downloading setuptools-59.6.0-py3-none-any.whl (952 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 952 kB 67.2 MB/s \n",
      "\u001B[?25hCollecting appdirs~=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting jupyter-client\n",
      "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130 kB 60.4 MB/s \n",
      "\u001B[?25hCollecting traitlets>=4.1.0\n",
      "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75 kB 3.5 MB/s \n",
      "\u001B[?25hCollecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting ipython>=5.0.0\n",
      "  Downloading ipython-7.16.3-py3-none-any.whl (783 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783 kB 65.3 MB/s \n",
      "\u001B[?25hCollecting tornado>=4.2\n",
      "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 427 kB 56.5 MB/s \n",
      "\u001B[?25hCollecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61 kB 124 kB/s \n",
      "\u001B[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143 kB 45.0 MB/s \n",
      "\u001B[?25hCollecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97 kB 6.4 MB/s \n",
      "\u001B[?25hCollecting werkzeug>=0.11.10\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 289 kB 71.8 MB/s \n",
      "\u001B[?25hCollecting h5py\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.0 MB 48.0 MB/s \n",
      "\u001B[?25hCollecting nest-asyncio>=1.5\n",
      "  Downloading nest_asyncio-1.5.8-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyzmq>=13\n",
      "  Downloading pyzmq-25.1.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 47.2 MB/s \n",
      "\u001B[?25hCollecting jupyter-core>=4.6.0\n",
      "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86 kB 6.2 MB/s \n",
      "\u001B[?25hCollecting entrypoints\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting decorator\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 56.1 MB/s \n",
      "\u001B[?25hCollecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting pexpect; sys_platform != \"win32\"\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 2.5 MB/s \n",
      "\u001B[?25hCollecting jedi<=0.17.2,>=0.10\n",
      "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4 MB 45.7 MB/s \n",
      "\u001B[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386 kB 55.8 MB/s \n",
      "\u001B[?25hCollecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting parso<0.8.0,>=0.7.0\n",
      "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109 kB 44.6 MB/s \n",
      "\u001B[?25hCollecting wcwidth\n",
      "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Building wheels for collected packages: imageio, zhusuan, TFSnippet, idx2numpy, termcolor\n",
      "  Building wheel for imageio (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303870 sha256=bd8381789d67088ff7905c878bdb0f8e566cf67cde856e2f10bb4f7631e4dd80\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/46/c8/1c4dcdfaa55e113be908e8a07c4a29b1b09c790651c67163e3\n",
      "  Building wheel for zhusuan (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for zhusuan: filename=zhusuan-0.4.0-py2.py3-none-any.whl size=73592 sha256=08e280a0d60440b2bbdec3ff81cd1534509360306acf56df026550a07f76e7b9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4xz3pvw6/wheels/49/d5/2d/0d1d2b55de2af504ff65e8f3de89957abe0d6a8d8207917cde\n",
      "  Building wheel for TFSnippet (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for TFSnippet: filename=TFSnippet-0.2.0a1-py3-none-any.whl size=207813 sha256=649381a9a46b4a6ec6278e1009782bedcc7e4420d19dfa532b5d0c3d0376d66b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4xz3pvw6/wheels/5e/01/f7/c1f1590f92940059b7bc3af7e88023fccfc1eb5360bd2cf481\n",
      "  Building wheel for idx2numpy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7904 sha256=1abf4e9e5750055af3af268bd834d69525ea3184d9d368b88deeb3586a0c56a9\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/34/28/e6938b3277d94e90acb425f0ea451fd3d4be7713e13f19966f\n",
      "  Building wheel for termcolor (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=ee11ff6a963fc37d5828f3dc1b2e791535ace2bb62fe6ca6f6abf72972d26770\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built imageio zhusuan TFSnippet idx2numpy termcolor\n",
      "Installing collected packages: certifi, six, cycler, numpy, kiwisolver, python-dateutil, pyparsing, matplotlib, pytz, pandas, scipy, scikit-learn, wheel, protobuf, zipp, typing-extensions, importlib-metadata, markdown, dataclasses, werkzeug, grpcio, tensorboard, termcolor, gast, keras-preprocessing, cached-property, h5py, keras-applications, astor, absl-py, tensorflow, tensorflow-probability, tqdm, pillow, imageio, setuptools, appdirs, fs, click, nest-asyncio, pyzmq, decorator, ipython-genutils, traitlets, jupyter-core, tornado, entrypoints, jupyter-client, pygments, pickleshare, ptyprocess, pexpect, parso, jedi, wcwidth, prompt-toolkit, backcall, ipython, ipykernel, pyyaml, zhusuan, filelock, frozendict, idx2numpy, lazy-object-proxy, natsort, idna, urllib3, charset-normalizer, requests, semver, TFSnippet\n",
      "Successfully installed TFSnippet-0.2.0a1 absl-py-1.4.0 appdirs-1.4.4 astor-0.8.1 backcall-0.2.0 cached-property-1.5.2 certifi-2023.11.17 charset-normalizer-2.0.12 click-7.0 cycler-0.11.0 dataclasses-0.8 decorator-5.1.1 entrypoints-0.4 filelock-3.4.1 frozendict-2.3.9 fs-2.3.0 gast-0.5.4 grpcio-1.48.2 h5py-3.1.0 idna-3.6 idx2numpy-1.2.3 imageio-2.4.1 importlib-metadata-4.8.3 ipykernel-5.5.6 ipython-7.16.3 ipython-genutils-0.2.0 jedi-0.17.2 jupyter-client-7.1.2 jupyter-core-4.9.2 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.3.1 lazy-object-proxy-1.7.1 markdown-3.3.7 matplotlib-3.0.2 natsort-8.2.0 nest-asyncio-1.5.8 numpy-1.15.4 pandas-0.23.4 parso-0.7.1 pexpect-4.9.0 pickleshare-0.7.5 pillow-8.4.0 prompt-toolkit-3.0.36 protobuf-3.19.6 ptyprocess-0.7.0 pygments-2.14.0 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 pyyaml-5.4.1 pyzmq-25.1.1 requests-2.27.1 scikit-learn-0.20.2 scipy-1.2.0 semver-2.13.0 setuptools-59.6.0 six-1.11.0 tensorboard-1.12.2 tensorflow-1.12.0 tensorflow-probability-0.5.0 termcolor-1.1.0 tornado-6.1 tqdm-4.28.1 traitlets-4.3.3 typing-extensions-4.1.1 urllib3-1.26.18 wcwidth-0.2.12 werkzeug-2.0.3 wheel-0.37.1 zhusuan-0.4.0 zipp-3.6.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#GPU"
   ],
   "metadata": {
    "id": "dUe76wMaYvdS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "pip install -r requirements.txt --ignore-installed certifi\n",
    "conda install -c anaconda cudatoolkit=9.0 cudnn=7"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pjwBjxoz_Bm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702399500225,
     "user_tz": 300,
     "elapsed": 185608,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "f10097a8-03ce-4a74-9712-7a865c1d7642"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/thu-ml/zhusuan.git (from -r requirements.txt (line 17))\n",
      "  Cloning https://github.com/thu-ml/zhusuan.git to /tmp/pip-req-build-zti1wiy9\n",
      "  Running command git clone -q https://github.com/thu-ml/zhusuan.git /tmp/pip-req-build-zti1wiy9\n",
      "Collecting git+https://github.com/haowen-xu/tfsnippet.git@v0.2.0-alpha1 (from -r requirements.txt (line 18))\n",
      "  Cloning https://github.com/haowen-xu/tfsnippet.git (to revision v0.2.0-alpha1) to /tmp/pip-req-build-h7dlmkr1\n",
      "  Running command git clone -q https://github.com/haowen-xu/tfsnippet.git /tmp/pip-req-build-h7dlmkr1\n",
      "  Running command git checkout -q 7b43abdbdd29f1914dbc11b961b5d45b9de76653\n",
      "Collecting certifi\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162 kB 1.2 MB/s \n",
      "\u001B[?25hCollecting six==1.11.0\n",
      "  Downloading six-1.11.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting matplotlib==3.0.2\n",
      "  Downloading matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.9 MB 11.0 MB/s \n",
      "\u001B[?25hCollecting numpy==1.15.4\n",
      "  Downloading numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.9 MB 51.7 MB/s \n",
      "\u001B[?25hCollecting pandas==0.23.4\n",
      "  Downloading pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.9 MB 65.0 MB/s \n",
      "\u001B[?25hCollecting scipy==1.2.0\n",
      "  Downloading scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.6 MB 1.3 MB/s \n",
      "\u001B[?25hCollecting scikit_learn==0.20.2\n",
      "  Downloading scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.4 MB 51.2 MB/s \n",
      "\u001B[?25hCollecting tensorflow-gpu==1.12.0\n",
      "  Downloading tensorflow_gpu-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (281.7 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281.7 MB 15 kB/s \n",
      "\u001B[?25hCollecting tensorflow_probability==0.5.0\n",
      "  Downloading tensorflow_probability-0.5.0-py2.py3-none-any.whl (680 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680 kB 72.5 MB/s \n",
      "\u001B[?25hCollecting tqdm==4.28.1\n",
      "  Downloading tqdm-4.28.1-py2.py3-none-any.whl (45 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45 kB 4.3 MB/s \n",
      "\u001B[?25hCollecting imageio==2.4.1\n",
      "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 58.0 MB/s \n",
      "\u001B[?25hCollecting fs==2.3.0\n",
      "  Downloading fs-2.3.0-py2.py3-none-any.whl (124 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 124 kB 66.1 MB/s \n",
      "\u001B[?25hCollecting click==8.0\n",
      "  Downloading click-8.0.0-py3-none-any.whl (96 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96 kB 7.5 MB/s \n",
      "\u001B[?25hCollecting ipykernel\n",
      "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121 kB 64.5 MB/s \n",
      "\u001B[?25hCollecting pyyaml==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 640 kB 64.1 MB/s \n",
      "\u001B[?25hCollecting wandb==0.15.11\n",
      "  Downloading wandb-0.15.11-py3-none-any.whl (2.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1 MB 60.4 MB/s \n",
      "\u001B[?25hCollecting filelock>=3.0.10\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting frozendict>=1.2.0\n",
      "  Downloading frozendict-2.3.10-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100 kB 562 kB/s \n",
      "\u001B[?25hCollecting idx2numpy>=1.2.2\n",
      "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
      "Collecting lazy-object-proxy>=1.3.1\n",
      "  Downloading lazy_object_proxy-1.7.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (57 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57 kB 6.8 MB/s \n",
      "\u001B[?25hCollecting natsort>=5.3.3\n",
      "  Downloading natsort-8.2.0-py3-none-any.whl (37 kB)\n",
      "Collecting requests>=2.18.4\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 205 kB/s \n",
      "\u001B[?25hCollecting semver>=2.7.9\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 65.4 MB/s \n",
      "\u001B[?25hCollecting python-dateutil>=2.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 247 kB 51.6 MB/s \n",
      "\u001B[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103 kB 65.6 MB/s \n",
      "\u001B[?25hCollecting pytz>=2011k\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 502 kB 68.2 MB/s \n",
      "\u001B[?25hCollecting tensorboard<1.13.0,>=1.12.0\n",
      "  Downloading tensorboard-1.12.2-py3-none-any.whl (3.0 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0 MB 60.0 MB/s \n",
      "\u001B[?25hCollecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50 kB 8.6 MB/s \n",
      "\u001B[?25hCollecting wheel>=0.26\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42 kB 1.7 MB/s \n",
      "\u001B[?25hCollecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 17.9 MB/s \n",
      "\u001B[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.6 MB 63.0 MB/s \n",
      "\u001B[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting gast>=0.2.0\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting absl-py>=0.1.6\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 126 kB 64.4 MB/s \n",
      "\u001B[?25hCollecting pillow\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1 MB 64.3 MB/s \n",
      "\u001B[?25hCollecting appdirs~=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-59.6.0-py3-none-any.whl (952 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 952 kB 57.4 MB/s \n",
      "\u001B[?25hCollecting tornado>=4.2\n",
      "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 427 kB 70.1 MB/s \n",
      "\u001B[?25hCollecting traitlets>=4.1.0\n",
      "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75 kB 5.7 MB/s \n",
      "\u001B[?25hCollecting ipython>=5.0.0\n",
      "  Downloading ipython-7.16.3-py3-none-any.whl (783 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783 kB 59.6 MB/s \n",
      "\u001B[?25hCollecting jupyter-client\n",
      "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130 kB 76.3 MB/s \n",
      "\u001B[?25hCollecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting typing-extensions; python_version < \"3.10\"\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting psutil>=5.0.0\n",
      "  Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 283 kB 55.0 MB/s \n",
      "\u001B[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.2.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.39.0-py2.py3-none-any.whl (254 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 254 kB 63.6 MB/s \n",
      "\u001B[?25hCollecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170 kB 67.8 MB/s \n",
      "\u001B[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143 kB 77.7 MB/s \n",
      "\u001B[?25hCollecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61 kB 78 kB/s \n",
      "\u001B[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97 kB 8.7 MB/s \n",
      "\u001B[?25hCollecting werkzeug>=0.11.10\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 289 kB 64.1 MB/s \n",
      "\u001B[?25hCollecting h5py\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.0 MB 54.9 MB/s \n",
      "\u001B[?25hCollecting decorator\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting jedi<=0.17.2,>=0.10\n",
      "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4 MB 73.3 MB/s \n",
      "\u001B[?25hCollecting pygments\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 63.1 MB/s \n",
      "\u001B[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386 kB 48.5 MB/s \n",
      "\u001B[?25hCollecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pexpect; sys_platform != \"win32\"\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 3.1 MB/s \n",
      "\u001B[?25hCollecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting entrypoints\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyzmq>=13\n",
      "  Downloading pyzmq-25.1.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 49.2 MB/s \n",
      "\u001B[?25hCollecting jupyter-core>=4.6.0\n",
      "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86 kB 8.0 MB/s \n",
      "\u001B[?25hCollecting nest-asyncio>=1.5\n",
      "  Downloading nest_asyncio-1.5.8-py3-none-any.whl (5.3 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 2.1 MB/s \n",
      "\u001B[?25hCollecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting parso<0.8.0,>=0.7.0\n",
      "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109 kB 76.7 MB/s \n",
      "\u001B[?25hCollecting wcwidth\n",
      "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Building wheels for collected packages: imageio, zhusuan, TFSnippet, idx2numpy, termcolor, pathtools\n",
      "  Building wheel for imageio (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303870 sha256=10f571e286fadf2aa256a451351ea39f8ad492ec45929f06c2d1c8fdb17f0e59\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/46/c8/1c4dcdfaa55e113be908e8a07c4a29b1b09c790651c67163e3\n",
      "  Building wheel for zhusuan (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for zhusuan: filename=zhusuan-0.4.0-py2.py3-none-any.whl size=73592 sha256=8014287075483e5bcb329d3a3dac0747dd740c90d86b8d346d7f28cc1bf43fa6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_8lyhgfl/wheels/49/d5/2d/0d1d2b55de2af504ff65e8f3de89957abe0d6a8d8207917cde\n",
      "  Building wheel for TFSnippet (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for TFSnippet: filename=TFSnippet-0.2.0a1-py3-none-any.whl size=207813 sha256=403becacc4a382780c16eb69a0aa66c6ee0dcdc608da739959a540dbc239303c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_8lyhgfl/wheels/5e/01/f7/c1f1590f92940059b7bc3af7e88023fccfc1eb5360bd2cf481\n",
      "  Building wheel for idx2numpy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7904 sha256=84bcd27ed3a55868836c5faa3e4b4f541254deeaa57e0136c779ef7a26145c10\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/34/28/e6938b3277d94e90acb425f0ea451fd3d4be7713e13f19966f\n",
      "  Building wheel for termcolor (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=ae30a368ff6f7c32ffa19ae807f961992c5ed13110695dc01020162f0eea1017\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for pathtools (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=6a26e7e243c33f249dcdbdd1ecd7a1183f6e36bda37bf4f6663fd29a020c0f75\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/ea/90/e37d463fb3b03848bf715080595de62545266f53dd546b2497\n",
      "Successfully built imageio zhusuan TFSnippet idx2numpy termcolor pathtools\n",
      "\u001B[31mERROR: wandb 0.15.11 has requirement Click!=8.0.0,>=7.1, but you'll have click 8.0.0 which is incompatible.\u001B[0m\n",
      "Installing collected packages: certifi, six, numpy, cycler, kiwisolver, python-dateutil, pyparsing, matplotlib, pytz, pandas, scipy, scikit-learn, typing-extensions, zipp, importlib-metadata, markdown, grpcio, wheel, protobuf, dataclasses, werkzeug, tensorboard, cached-property, h5py, keras-applications, keras-preprocessing, termcolor, astor, gast, absl-py, tensorflow-gpu, tensorflow-probability, tqdm, pillow, imageio, appdirs, setuptools, fs, click, tornado, ipython-genutils, decorator, traitlets, parso, jedi, pygments, wcwidth, prompt-toolkit, backcall, ptyprocess, pexpect, pickleshare, ipython, entrypoints, pyzmq, jupyter-core, nest-asyncio, jupyter-client, ipykernel, pyyaml, charset-normalizer, urllib3, idna, requests, pathtools, psutil, setproctitle, sentry-sdk, smmap, gitdb, GitPython, docker-pycreds, wandb, zhusuan, filelock, frozendict, idx2numpy, lazy-object-proxy, natsort, semver, TFSnippet\n",
      "Successfully installed GitPython-3.1.18 TFSnippet-0.2.0a1 absl-py-1.4.0 appdirs-1.4.4 astor-0.8.1 backcall-0.2.0 cached-property-1.5.2 certifi-2023.11.17 charset-normalizer-2.0.12 click-8.0.0 cycler-0.11.0 dataclasses-0.8 decorator-5.1.1 docker-pycreds-0.4.0 entrypoints-0.4 filelock-3.4.1 frozendict-2.3.10 fs-2.3.0 gast-0.5.4 gitdb-4.0.9 grpcio-1.48.2 h5py-3.1.0 idna-3.6 idx2numpy-1.2.3 imageio-2.4.1 importlib-metadata-4.8.3 ipykernel-5.5.6 ipython-7.16.3 ipython-genutils-0.2.0 jedi-0.17.2 jupyter-client-7.1.2 jupyter-core-4.9.2 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.3.1 lazy-object-proxy-1.7.1 markdown-3.3.7 matplotlib-3.0.2 natsort-8.2.0 nest-asyncio-1.5.8 numpy-1.15.4 pandas-0.23.4 parso-0.7.1 pathtools-0.1.2 pexpect-4.9.0 pickleshare-0.7.5 pillow-8.4.0 prompt-toolkit-3.0.36 protobuf-3.19.6 psutil-5.9.6 ptyprocess-0.7.0 pygments-2.14.0 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 pyyaml-5.4.1 pyzmq-25.1.2 requests-2.27.1 scikit-learn-0.20.2 scipy-1.2.0 semver-2.13.0 sentry-sdk-1.39.0 setproctitle-1.2.3 setuptools-59.6.0 six-1.11.0 smmap-5.0.0 tensorboard-1.12.2 tensorflow-gpu-1.12.0 tensorflow-probability-0.5.0 termcolor-1.1.0 tornado-6.1 tqdm-4.28.1 traitlets-4.3.3 typing-extensions-4.1.1 urllib3-1.26.18 wandb-0.15.11 wcwidth-0.2.12 werkzeug-2.0.3 wheel-0.37.1 zhusuan-0.4.0 zipp-3.6.0\n",
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
      "Solving environment: / \b\b- \b\bdone\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.1.0\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/envs/myenv\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=9.0\n",
      "    - cudnn=7\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       h06a4308_0         130 KB  anaconda\n",
      "    certifi-2020.6.20          |     pyhd3eb1b0_3         159 KB  anaconda\n",
      "    cudatoolkit-9.0            |       h13b8566_0       340.4 MB  anaconda\n",
      "    cudnn-7.6.5                |        cuda9.0_0       193.4 MB  anaconda\n",
      "    openssl-1.1.1w             |       h7f8727e_0         3.8 MB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       537.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        anaconda/linux-64::cudatoolkit-9.0-h13b8566_0 \n",
      "  cudnn              anaconda/linux-64::cudnn-7.6.5-cuda9.0_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi            conda-forge/linux-64::certifi-2016.9.~ --> anaconda/noarch::certifi-2020.6.20-pyhd3eb1b0_3 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.11.~ --> anaconda::ca-certificates-2023.08.22-h06a4308_0 \n",
      "  openssl            conda-forge::openssl-1.1.1w-hd590300_0 --> anaconda::openssl-1.1.1w-h7f8727e_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "cudnn-7.6.5          | 193.4 MB  | :   0% 0/1 [00:00<?, ?it/s]\n",
      "certifi-2020.6.20    | 159 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 130 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 130 KB    | :  12% 0.12343762949122662/1 [00:00<00:00,  1.13s/it]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.8 MB    | :   0% 0.004097420780655692/1 [00:00<00:34, 34.70s/it]\u001B[A\u001B[A\u001B[A\u001B[A\n",
      "certifi-2020.6.20    | 159 KB    | :  10% 0.10054679685054833/1 [00:00<00:01,  1.70s/it]\u001B[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 130 KB    | : 100% 1.0/1 [00:00<00:00,  1.13s/it]                \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :   0% 4.590003447069056e-05/1 [00:00<1:12:16, 4336.79s/it]\u001B[A\u001B[A\n",
      "certifi-2020.6.20    | 159 KB    | : 100% 1.0/1 [00:00<00:00,  1.70s/it]                \u001B[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.8 MB    | :  91% 0.9055299925249081/1 [00:00<00:00,  4.52it/s]  \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :   1% 0.011291408479789877/1 [00:00<00:20, 21.23s/it]     \u001B[A\u001B[A\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :   4% 0.039428129610323194/1 [00:00<00:07,  7.43s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :   0% 8.079861222071119e-05/1 [00:00<1:57:17, 7037.59s/it]\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :   2% 0.016078923831921527/1 [00:00<00:30, 31.17s/it]     \n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :   4% 0.04096489639590058/1 [00:00<00:11, 12.49s/it] \n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :   6% 0.06043736194109197/1 [00:00<00:08,  9.29s/it]\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  12% 0.12429729334663003/1 [00:00<00:05,  6.31s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :   8% 0.0779706607929863/1 [00:01<00:08,  9.43s/it] \n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  17% 0.172216929334031/1 [00:01<00:04,  4.95s/it]  \u001B[A\u001B[A\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  20% 0.1950292464659642/1 [00:01<00:03,  4.77s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  22% 0.22050376559719745/1 [00:01<00:03,  4.49s/it]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.8 MB    | : 100% 1.0/1 [00:01<00:00,  4.52it/s]               \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  12% 0.11635000159782412/1 [00:01<00:09, 11.05s/it]\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  28% 0.2756756070309675/1 [00:01<00:03,  4.75s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  30% 0.30064522578302316/1 [00:01<00:03,  4.53s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  32% 0.32359524301836845/1 [00:01<00:03,  4.90s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  13% 0.1313785434708764/1 [00:02<00:13, 15.78s/it] \n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  37% 0.37495738159107117/1 [00:02<00:02,  4.38s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  14% 0.1427711477939967/1 [00:02<00:14, 16.43s/it]\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  43% 0.428385021714955/1 [00:02<00:02,  4.38s/it]  \u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  16% 0.15699170354484185/1 [00:02<00:12, 14.51s/it]\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  17% 0.16967708566349352/1 [00:02<00:11, 14.39s/it]\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  18% 0.1847056275365458/1 [00:02<00:11, 13.68s/it] \n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  55% 0.5472202109595729/1 [00:02<00:02,  4.83s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  19% 0.1934318776563826/1 [00:02<00:12, 15.25s/it]\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  62% 0.6162079627690208/1 [00:02<00:01,  3.81s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  23% 0.227448093401302/1 [00:03<00:08, 11.02s/it]  \n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  69% 0.6872612161296497/1 [00:03<00:01,  3.76s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  24% 0.23859830188776016/1 [00:03<00:08, 11.48s/it]\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  25% 0.25144528123085325/1 [00:03<00:08, 11.15s/it]\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  27% 0.2692209759194097/1 [00:03<00:07,  9.84s/it] \n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  29% 0.2869966706079662/1 [00:03<00:06,  9.02s/it]\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  87% 0.8671893512547567/1 [00:03<00:00,  3.13s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | :  30% 0.29879326799218997/1 [00:03<00:07, 11.15s/it]\n",
      "\n",
      "cudatoolkit-9.0      | 340.4 MB  | :  94% 0.9385639048566806/1 [00:03<00:00,  2.97s/it]\u001B[A\u001B[A\n",
      "\n",
      "cudnn-7.6.5          | 193.4 MB  | : 100% 1.0/1 [00:49<00:00,  3.08s/it]               \n",
      "\n",
      "                                                                        \n",
      "                                                                        \u001B[A\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001B[A\u001B[A\u001B[A\u001B[A\n",
      "Preparing transaction: | \b\bdone\n",
      "Verifying transaction: - \b\b\\ \b\b| \b\bdone\n",
      "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Processing"
   ],
   "metadata": {
    "id": "XtWNYKSzZVRz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python data_preprocess.py --dataset_folder /content/drive/MyDrive/CSC2233/ST8000NM0055_final_dataset_Nov26 --output_folder /content/drive/MyDrive/CSC2233/processed_st8000"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3XDR13-3Y8i",
    "outputId": "c0ac9729-e0b5-4e69-db5c-189c95533f33",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1701546520362,
     "user_tz": 300,
     "elapsed": 5284905,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 26% 2962/11330 [18:16<53:07,  2.63it/s]Empty file: 1_ST8000NM0055_ZA1818ES.csv\n",
      " 27% 3037/11330 [18:43<50:48,  2.72it/s]Empty file: 1_ST8000NM0055_ZA1818LS.csv\n",
      " 31% 3538/11330 [21:47<51:35,  2.52it/s]Empty file: 1_ST8000NM0055_ZA181804.csv\n",
      " 42% 4813/11330 [29:31<38:55,  2.79it/s]Empty file: 1_ST8000NM0055_ZA1AZA3L.csv\n",
      " 46% 5223/11330 [31:59<37:33,  2.71it/s]Empty file: 1_ST8000NM0055_ZA1B2V7M.csv\n",
      " 55% 6220/11330 [37:56<32:56,  2.59it/s]Empty file: 1_ST8000NM0055_ZA1ERR9G.csv\n",
      " 69% 7831/11330 [47:38<23:00,  2.54it/s]Empty file: 1_ST8000NM0055_ZA181LAP.csv\n",
      " 74% 8417/11330 [51:09<16:03,  3.02it/s]Empty file: 1_ST8000NM0055_ZA1818AQ.csv\n",
      "100% 11330/11330 [1:08:37<00:00,  2.98it/s]\n",
      "100% 3230/3230 [19:17<00:00,  3.05it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python data_preprocess.py --dataset_folder /content/drive/MyDrive/CSC2233/ST12000NM0008_final_dataset_Nov26 --output_folder /content/drive/MyDrive/CSC2233/processed_st12000"
   ],
   "metadata": {
    "id": "iJHjRWDwMdwT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-Train"
   ],
   "metadata": {
    "id": "B0wedo11kdDf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --dataset_folder=/content/processed_st8000 --save_dir=results/tuned_model_st8000 --early_stopping_patience=20"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Rk6fL_8E6xz",
    "outputId": "ab9b1303-2525-4766-a372-1e1ad926fea0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702204317948,
     "user_tz": 300,
     "elapsed": 46600637,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/csc2233-2023/omni_anomaly/vae.py:378: DeprecationWarning: invalid escape sequence \\*\n",
      "  \"\"\"\n",
      "/content/csc2233-2023/omni_anomaly/vae.py:419: DeprecationWarning: invalid escape sequence \\*\n",
      "  \"\"\"\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "===============================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st8000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': None,\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'tuned_model_st8000',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': None,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (2782127, 16)\n",
      "test set shape:  (834888, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-09 20:34:59,721 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-09 20:35:04.647450: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-09 20:35:04.920236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-09 20:35:04.920430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-09 20:35:04.920457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-09 20:35:05.206572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-09 20:35:05.206623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-09 20:35:05.206639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-09 20:35:05.206729: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-09 20:35:05.206773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (2225702, 16)\n",
      "[Epoch 1/100, Step 4347] Best valid loss updated: from inf to -42.798930\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 1/100, Step 4347, ETA 13h 55m 17.8s] epoch time: 8m 26.24s; step time: 0.1014s (Â±0.1261s); train time: 7m 44.28s; valid time: 41.96s; loss: -39.146 (Â±7.77563); valid loss: -42.7989 (*)\n",
      "[Epoch 2/100, Step 8694, ETA 13h 42m 50.92s] Best valid loss updated: from -42.798930 to -52.241732\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 2/100, Step 8694, ETA 13h 44m 8.847s] epoch time: 8m 22.92s; step time: 0.1004s (Â±0.002051s); train time: 7m 40.97s; valid time: 41.95s; loss: -49.471 (Â±2.49482); valid loss: -52.2417 (*)\n",
      "[Epoch 3/100, Step 13041, ETA 13h 33m 29.83s] Best valid loss updated: from -52.241732 to -55.048356\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 3/100, Step 13041, ETA 13h 33m 58.7s] epoch time: 8m 21.31s; step time: 0.1003s (Â±0.001915s); train time: 7m 40.17s; valid time: 41.14s; loss: -53.3328 (Â±2.1861); valid loss: -55.0484 (*)\n",
      "[Epoch 4/100, Step 17388, ETA 13h 24m 26.05s] Best valid loss updated: from -55.048356 to -57.221264\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 4/100, Step 17388, ETA 13h 24m 46.91s] epoch time: 8m 21.48s; step time: 0.1004s (Â±0.001967s); train time: 7m 40.27s; valid time: 41.2s; loss: -56.152 (Â±2.16807); valid loss: -57.2213 (*)\n",
      "[Epoch 5/100, Step 21735, ETA 13h 15m 38.44s] Best valid loss updated: from -57.221264 to -61.880004\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 5/100, Step 21735, ETA 13h 16m 6.665s] epoch time: 8m 22.08s; step time: 0.1004s (Â±0.001991s); train time: 7m 40.43s; valid time: 41.65s; loss: -59.0298 (Â±2.31539); valid loss: -61.88 (*)\n",
      "[Epoch 6/100, Step 26082, ETA 13h 7m 10.41s] Best valid loss updated: from -61.880004 to -64.900702\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 6/100, Step 26082, ETA 13h 7m 24.86s] epoch time: 8m 21.59s; step time: 0.1003s (Â±0.001905s); train time: 7m 40.09s; valid time: 41.5s; loss: -61.3361 (Â±2.28764); valid loss: -64.9007 (*)\n",
      "[Epoch 7/100, Step 30429, ETA 12h 58m 58.97s] epoch time: 8m 22.36s; step time: 0.1004s (Â±0.001996s); train time: 7m 42.07s; valid time: 40.29s; loss: -63.6113 (Â±2.26178); valid loss: -64.5531\n",
      "[Epoch 8/100, Step 34776, ETA 12h 49m 56.13s] Best valid loss updated: from -64.900702 to -65.944928\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 8/100, Step 34776, ETA 12h 50m 10.15s] epoch time: 8m 20.29s; step time: 0.1003s (Â±0.001886s); train time: 7m 39.08s; valid time: 41.21s; loss: -65.6664 (Â±2.31067); valid loss: -65.9449 (*)\n",
      "[Epoch 9/100, Step 39123, ETA 12h 41m 12.95s] Best valid loss updated: from -65.944928 to -68.164096\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 9/100, Step 39123, ETA 12h 41m 22.53s] epoch time: 8m 19.78s; step time: 0.1003s (Â±0.001928s); train time: 7m 38.96s; valid time: 40.82s; loss: -67.5413 (Â±2.43117); valid loss: -68.1641 (*)\n",
      "[Epoch 10/100, Step 43470, ETA 12h 32m 30.64s] Best valid loss updated: from -68.164096 to -70.982483\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 10/100, Step 43470, ETA 12h 32m 39.53s] epoch time: 8m 19.67s; step time: 0.1003s (Â±0.00186s); train time: 7m 38.74s; valid time: 40.93s; loss: -68.8576 (Â±2.44356); valid loss: -70.9825 (*)\n",
      "[Epoch 11/100, Step 47817, ETA 12h 23m 47.46s] epoch time: 8m 18.03s; step time: 0.1002s (Â±0.001986s); train time: 7m 38.19s; valid time: 39.84s; loss: -70.1109 (Â±2.54009); valid loss: -69.9722\n",
      "[Epoch 12/100, Step 52164, ETA 12h 15m 2.092s] Best valid loss updated: from -70.982483 to -74.230282\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 12/100, Step 52164, ETA 12h 15m 9.868s] epoch time: 8m 19.23s; step time: 0.1002s (Â±0.001899s); train time: 7m 38.28s; valid time: 40.95s; loss: -71.0744 (Â±2.39086); valid loss: -74.2303 (*)\n",
      "[Epoch 13/100, Step 56511, ETA 12h 6m 37.75s] epoch time: 8m 19.62s; step time: 0.1003s (Â±0.001984s); train time: 7m 39.19s; valid time: 40.43s; loss: -72.1989 (Â±2.22747); valid loss: -72.2867\n",
      "[Epoch 14/100, Step 60858, ETA 11h 58m 7.704s] epoch time: 8m 19.67s; step time: 0.1004s (Â±0.001976s); train time: 7m 39.77s; valid time: 39.9s; loss: -73.0432 (Â±2.22937); valid loss: -69.915\n",
      "[Epoch 15/100, Step 65205, ETA 11h 49m 33.17s] epoch time: 8m 18.63s; step time: 0.1003s (Â±0.001942s); train time: 7m 38.66s; valid time: 39.97s; loss: -73.9052 (Â±2.45938); valid loss: -70.9545\n",
      "[Epoch 16/100, Step 69552, ETA 11h 40m 58.98s] Best valid loss updated: from -74.230282 to -76.607264\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 16/100, Step 69552, ETA 11h 41m 4.23s] epoch time: 8m 19.32s; step time: 0.1003s (Â±0.001943s); train time: 7m 38.47s; valid time: 40.85s; loss: -74.7618 (Â±2.40034); valid loss: -76.6073 (*)\n",
      "[Epoch 17/100, Step 73899, ETA 11h 32m 39.04s] Best valid loss updated: from -76.607264 to -78.521581\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 17/100, Step 73899, ETA 11h 32m 46.12s] epoch time: 8m 21.31s; step time: 0.1003s (Â±0.00201s); train time: 7m 39.92s; valid time: 41.39s; loss: -75.4362 (Â±2.29703); valid loss: -78.5216 (*)\n",
      "[Epoch 18/100, Step 78246, ETA 11h 24m 13.3s] epoch time: 8m 18.16s; step time: 0.1003s (Â±0.001952s); train time: 7m 38.28s; valid time: 39.87s; loss: -76.1736 (Â±2.32139); valid loss: -74.0703\n",
      "[Epoch 19/100, Step 82593, ETA 11h 15m 40.73s] epoch time: 8m 17.85s; step time: 0.1002s (Â±0.001904s); train time: 7m 38s; valid time: 39.86s; loss: -76.6316 (Â±2.39644); valid loss: -75.0285\n",
      "[Epoch 20/100, Step 86940, ETA 11h 7m 11.14s] epoch time: 8m 18.23s; step time: 0.1003s (Â±0.001958s); train time: 7m 38.3s; valid time: 39.93s; loss: -77.4025 (Â±2.22847); valid loss: -77.7976\n",
      "[Epoch 20/100, Step 86940, ETA 11h 7m 11.14s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 91287, ETA 10h 58m 43.35s] Best valid loss updated: from -78.521581 to -85.347961\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 21/100, Step 91287, ETA 10h 58m 47.27s] epoch time: 8m 19.46s; step time: 0.1003s (Â±0.001906s); train time: 7m 38.44s; valid time: 41.02s; loss: -83.2144 (Â±1.93574); valid loss: -85.348 (*)\n",
      "[Epoch 22/100, Step 95634, ETA 10h 50m 22.52s] epoch time: 8m 19.1s; step time: 0.1005s (Â±0.001932s); train time: 7m 39.17s; valid time: 39.93s; loss: -83.3414 (Â±2.16352); valid loss: -82.9988\n",
      "[Epoch 23/100, Step 99981, ETA 10h 41m 58.58s] epoch time: 8m 19.2s; step time: 0.1003s (Â±0.00185s); train time: 7m 39.22s; valid time: 39.98s; loss: -83.5976 (Â±2.48679); valid loss: -82.8126\n",
      "[Epoch 24/100, Step 104328, ETA 10h 33m 37.3s] Best valid loss updated: from -85.347961 to -85.392605\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 24/100, Step 104328, ETA 10h 33m 40.6s] epoch time: 8m 20.96s; step time: 0.1004s (Â±0.001868s); train time: 7m 40s; valid time: 40.96s; loss: -84.0694 (Â±2.00581); valid loss: -85.3926 (*)\n",
      "[Epoch 25/100, Step 108675, ETA 10h 25m 15.92s] epoch time: 8m 18.8s; step time: 0.1004s (Â±0.001915s); train time: 7m 38.87s; valid time: 39.93s; loss: -84.0891 (Â±2.47982); valid loss: -84.9492\n",
      "[Epoch 26/100, Step 113022, ETA 10h 16m 50.53s] epoch time: 8m 18.39s; step time: 0.1003s (Â±0.001966s); train time: 7m 38.46s; valid time: 39.93s; loss: -84.273 (Â±2.33475); valid loss: -80.8485\n",
      "[Epoch 27/100, Step 117369, ETA 10h 8m 28.38s] epoch time: 8m 19.4s; step time: 0.1005s (Â±0.001897s); train time: 7m 39.5s; valid time: 39.9s; loss: -84.4276 (Â±2.36085); valid loss: -84.136\n",
      "[Epoch 28/100, Step 121716, ETA 10h 4.481s] epoch time: 8m 18.64s; step time: 0.1004s (Â±0.001893s); train time: 7m 38.65s; valid time: 40s; loss: -84.6286 (Â±2.35467); valid loss: -81.7162\n",
      "[Epoch 29/100, Step 126063, ETA 9h 51m 40.91s] Best valid loss updated: from -85.392605 to -85.982089\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 29/100, Step 126063, ETA 9h 51m 45.23s] epoch time: 8m 20.39s; step time: 0.1004s (Â±0.0019s); train time: 7m 38.74s; valid time: 41.66s; loss: -84.8154 (Â±2.34554); valid loss: -85.9821 (*)\n",
      "[Epoch 30/100, Step 130410, ETA 9h 43m 22.41s] epoch time: 8m 18.9s; step time: 0.1003s (Â±0.001948s); train time: 7m 38.99s; valid time: 39.91s; loss: -84.8913 (Â±2.35569); valid loss: -84.9806\n",
      "[Epoch 31/100, Step 134757, ETA 9h 34m 58.5s] epoch time: 8m 18.29s; step time: 0.1003s (Â±0.001859s); train time: 7m 38.39s; valid time: 39.9s; loss: -85.2566 (Â±2.20577); valid loss: -85.8584\n",
      "[Epoch 32/100, Step 139104, ETA 9h 26m 35.27s] epoch time: 8m 18.45s; step time: 0.1004s (Â±0.001964s); train time: 7m 38.59s; valid time: 39.86s; loss: -85.2596 (Â±2.34823); valid loss: -81.1996\n",
      "[Epoch 33/100, Step 143451, ETA 9h 18m 11.19s] epoch time: 8m 17.89s; step time: 0.1002s (Â±0.001872s); train time: 7m 37.96s; valid time: 39.93s; loss: -85.516 (Â±2.15507); valid loss: -85.0243\n",
      "[Epoch 34/100, Step 147798, ETA 9h 9m 48.28s] epoch time: 8m 18.3s; step time: 0.1003s (Â±0.001901s); train time: 7m 38.47s; valid time: 39.83s; loss: -85.506 (Â±2.35211); valid loss: -85.8093\n",
      "[Epoch 35/100, Step 152145, ETA 9h 1m 25.67s] Best valid loss updated: from -85.982089 to -87.642543\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 35/100, Step 152145, ETA 9h 1m 27.68s] epoch time: 8m 19.4s; step time: 0.1003s (Â±0.00193s); train time: 7m 38.46s; valid time: 40.94s; loss: -85.7207 (Â±2.25784); valid loss: -87.6425 (*)\n",
      "[Epoch 36/100, Step 156492, ETA 8h 53m 8.971s] epoch time: 8m 20.43s; step time: 0.1004s (Â±0.001901s); train time: 7m 40.54s; valid time: 39.89s; loss: -85.7227 (Â±2.48825); valid loss: -86.8558\n",
      "[Epoch 37/100, Step 160839, ETA 8h 44m 46.97s] epoch time: 8m 18.55s; step time: 0.1004s (Â±0.001901s); train time: 7m 38.65s; valid time: 39.9s; loss: -85.9299 (Â±2.45438); valid loss: -86.3269\n",
      "[Epoch 38/100, Step 165186, ETA 8h 36m 24.66s] epoch time: 8m 18.25s; step time: 0.1003s (Â±0.001898s); train time: 7m 38.34s; valid time: 39.91s; loss: -86.1987 (Â±2.36056); valid loss: -87.0976\n",
      "[Epoch 39/100, Step 169533, ETA 8h 28m 3.468s] epoch time: 8m 18.83s; step time: 0.1004s (Â±0.00202s); train time: 7m 38.93s; valid time: 39.9s; loss: -86.541 (Â±2.15438); valid loss: -87.134\n",
      "[Epoch 40/100, Step 173880, ETA 8h 19m 41.73s] epoch time: 8m 18.39s; step time: 0.1003s (Â±0.001882s); train time: 7m 38.47s; valid time: 39.92s; loss: -86.6586 (Â±2.07032); valid loss: -86.6548\n",
      "[Epoch 40/100, Step 173880, ETA 8h 19m 41.73s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 178227, ETA 8h 11m 20.04s] Best valid loss updated: from -87.642543 to -92.070197\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 41/100, Step 178227, ETA 8h 11m 22.17s] epoch time: 8m 19.79s; step time: 0.1004s (Â±0.001962s); train time: 7m 38.41s; valid time: 41.37s; loss: -91.601 (Â±1.69107); valid loss: -92.0702 (*)\n",
      "[Epoch 42/100, Step 182574, ETA 8h 3m 2.163s] epoch time: 8m 19.48s; step time: 0.1004s (Â±0.001858s); train time: 7m 39.58s; valid time: 39.89s; loss: -91.8483 (Â±2.30372); valid loss: -84.5376\n",
      "[Epoch 43/100, Step 186921, ETA 7h 54m 40.62s] epoch time: 8m 18.29s; step time: 0.1003s (Â±0.001988s); train time: 7m 38.34s; valid time: 39.95s; loss: -91.9454 (Â±2.45095); valid loss: -86.6453\n",
      "[Epoch 44/100, Step 191268, ETA 7h 46m 19.12s] Best valid loss updated: from -92.070197 to -92.071386\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 44/100, Step 191268, ETA 7h 46m 20.56s] epoch time: 8m 19.35s; step time: 0.1003s (Â±0.001924s); train time: 7m 38.32s; valid time: 41.03s; loss: -91.8872 (Â±2.75728); valid loss: -92.0714 (*)\n",
      "[Epoch 45/100, Step 195615, ETA 7h 37m 59.69s] epoch time: 8m 18.66s; step time: 0.1004s (Â±0.001952s); train time: 7m 38.77s; valid time: 39.89s; loss: -92.1973 (Â±2.16809); valid loss: -91.4179\n",
      "[Epoch 46/100, Step 199962, ETA 7h 29m 38.66s] Best valid loss updated: from -92.071386 to -92.073112\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 46/100, Step 199962, ETA 7h 29m 40.06s] epoch time: 8m 19.63s; step time: 0.1003s (Â±0.001883s); train time: 7m 38.56s; valid time: 41.07s; loss: -92.122 (Â±2.34727); valid loss: -92.0731 (*)\n",
      "[Epoch 47/100, Step 204309, ETA 7h 21m 19.9s] epoch time: 8m 19.16s; step time: 0.1003s (Â±0.001911s); train time: 7m 39.28s; valid time: 39.88s; loss: -92.4067 (Â±2.2088); valid loss: -90.1614\n",
      "[Epoch 48/100, Step 208656, ETA 7h 13m 0.2754s] Best valid loss updated: from -92.073112 to -92.378371\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 48/100, Step 208656, ETA 7h 13m 1.563s] epoch time: 8m 20.81s; step time: 0.1003s (Â±0.001858s); train time: 7m 39.72s; valid time: 41.09s; loss: -92.3285 (Â±2.50125); valid loss: -92.3784 (*)\n",
      "[Epoch 49/100, Step 213003, ETA 7h 4m 40.8s] Best valid loss updated: from -92.378371 to -92.971026\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 49/100, Step 213003, ETA 7h 4m 42.1s] epoch time: 8m 19.82s; step time: 0.1004s (Â±0.001984s); train time: 7m 38.6s; valid time: 41.22s; loss: -92.4352 (Â±2.52306); valid loss: -92.971 (*)\n",
      "[Epoch 50/100, Step 217350, ETA 6h 56m 20.73s] Best valid loss updated: from -92.971026 to -93.668264\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 50/100, Step 217350, ETA 6h 56m 21.96s] epoch time: 8m 19.16s; step time: 0.1002s (Â±0.001828s); train time: 7m 37.98s; valid time: 41.18s; loss: -92.3745 (Â±2.54265); valid loss: -93.6683 (*)\n",
      "[Epoch 51/100, Step 221697, ETA 6h 48m 1.219s] epoch time: 8m 18.49s; step time: 0.1004s (Â±0.002052s); train time: 7m 38.56s; valid time: 39.93s; loss: -92.5853 (Â±2.37463); valid loss: -92.1139\n",
      "[Epoch 52/100, Step 226044, ETA 6h 39m 41.5s] epoch time: 8m 19.5s; step time: 0.1003s (Â±0.001859s); train time: 7m 39.67s; valid time: 39.83s; loss: -92.6437 (Â±2.33259); valid loss: -92.6848\n",
      "[Epoch 53/100, Step 230391, ETA 6h 31m 20.72s] epoch time: 8m 18.3s; step time: 0.1003s (Â±0.00198s); train time: 7m 38.43s; valid time: 39.87s; loss: -92.7682 (Â±2.24211); valid loss: -92.8878\n",
      "[Epoch 54/100, Step 234738, ETA 6h 23m 0.1196s] epoch time: 8m 18.4s; step time: 0.1003s (Â±0.001877s); train time: 7m 38.42s; valid time: 39.98s; loss: -92.7214 (Â±2.6519); valid loss: -92.7847\n",
      "[Epoch 55/100, Step 239085, ETA 6h 14m 39.86s] epoch time: 8m 18.72s; step time: 0.1004s (Â±0.001947s); train time: 7m 38.81s; valid time: 39.91s; loss: -92.6823 (Â±2.65293); valid loss: -91.0426\n",
      "[Epoch 56/100, Step 243432, ETA 6h 6m 19.94s] Best valid loss updated: from -93.668264 to -93.976551\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 56/100, Step 243432, ETA 6h 6m 20.94s] epoch time: 8m 20.36s; step time: 0.1004s (Â±0.001975s); train time: 7m 39.08s; valid time: 41.27s; loss: -93.0071 (Â±2.01184); valid loss: -93.9766 (*)\n",
      "[Epoch 57/100, Step 247779, ETA 5h 58m 0.6797s] epoch time: 8m 18.65s; step time: 0.1003s (Â±0.001888s); train time: 7m 38.73s; valid time: 39.92s; loss: -92.8578 (Â±2.68064); valid loss: -89.0266\n",
      "[Epoch 58/100, Step 252126, ETA 5h 49m 41.6s] epoch time: 8m 20.21s; step time: 0.1003s (Â±0.001922s); train time: 7m 40.18s; valid time: 40.03s; loss: -92.9264 (Â±2.58978); valid loss: -91.8004\n",
      "[Epoch 59/100, Step 256473, ETA 5h 41m 21.25s] epoch time: 8m 18.42s; step time: 0.1003s (Â±0.001876s); train time: 7m 38.49s; valid time: 39.93s; loss: -93.1971 (Â±2.12688); valid loss: -92.17\n",
      "[Epoch 60/100, Step 260820, ETA 5h 33m 1.178s] Best valid loss updated: from -93.976551 to -96.037989\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 60/100, Step 260820, ETA 5h 33m 2.056s] epoch time: 8m 20.06s; step time: 0.1004s (Â±0.001865s); train time: 7m 38.8s; valid time: 41.26s; loss: -93.1882 (Â±2.5213); valid loss: -96.038 (*)\n",
      "[Epoch 60/100, Step 260820, ETA 5h 33m 2.056s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 265167, ETA 5h 24m 41.98s] Best valid loss updated: from -96.037989 to -97.475663\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 61/100, Step 265167, ETA 5h 24m 42.83s] epoch time: 8m 20.06s; step time: 0.1004s (Â±0.001968s); train time: 7m 38.73s; valid time: 41.33s; loss: -97.0737 (Â±1.21269); valid loss: -97.4757 (*)\n",
      "[Epoch 62/100, Step 269514, ETA 5h 16m 22.75s] epoch time: 8m 18.72s; step time: 0.1004s (Â±0.001919s); train time: 7m 38.73s; valid time: 39.99s; loss: -97.2901 (Â±1.60143); valid loss: -96.4013\n",
      "[Epoch 63/100, Step 273861, ETA 5h 8m 3.548s] Best valid loss updated: from -97.475663 to -98.009421\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 63/100, Step 273861, ETA 5h 8m 4.526s] epoch time: 8m 21.79s; step time: 0.1005s (Â±0.001998s); train time: 7m 40.13s; valid time: 41.66s; loss: -97.75 (Â±1.39493); valid loss: -98.0094 (*)\n",
      "[Epoch 64/100, Step 278208, ETA 4h 59m 44.46s] epoch time: 8m 18.72s; step time: 0.1005s (Â±0.001952s); train time: 7m 38.76s; valid time: 39.96s; loss: -97.714 (Â±1.55963); valid loss: -97.5824\n",
      "[Epoch 65/100, Step 282555, ETA 4h 51m 24.3s] Best valid loss updated: from -98.009421 to -98.139221\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 65/100, Step 282555, ETA 4h 51m 25.04s] epoch time: 8m 19.85s; step time: 0.1004s (Â±0.001978s); train time: 7m 38.49s; valid time: 41.35s; loss: -97.9177 (Â±1.42723); valid loss: -98.1392 (*)\n",
      "[Epoch 66/100, Step 286902, ETA 4h 43m 4.964s] epoch time: 8m 18.59s; step time: 0.1004s (Â±0.001905s); train time: 7m 38.67s; valid time: 39.92s; loss: -97.9259 (Â±1.51931); valid loss: -97.2998\n",
      "[Epoch 67/100, Step 291249, ETA 4h 34m 44.94s] Best valid loss updated: from -98.139221 to -98.301777\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 67/100, Step 291249, ETA 4h 34m 45.88s] epoch time: 8m 20.52s; step time: 0.1004s (Â±0.001969s); train time: 7m 38.76s; valid time: 41.76s; loss: -98.0655 (Â±1.40064); valid loss: -98.3018 (*)\n",
      "[Epoch 68/100, Step 295596, ETA 4h 26m 26.23s] epoch time: 8m 19.4s; step time: 0.1003s (Â±0.001971s); train time: 7m 39.37s; valid time: 40.03s; loss: -98.225 (Â±1.15281); valid loss: -98.2216\n",
      "[Epoch 69/100, Step 299943, ETA 4h 18m 6.237s] Best valid loss updated: from -98.301777 to -98.801608\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 69/100, Step 299943, ETA 4h 18m 6.887s] epoch time: 8m 20.07s; step time: 0.1004s (Â±0.00187s); train time: 7m 38.71s; valid time: 41.35s; loss: -98.0941 (Â±1.55577); valid loss: -98.8016 (*)\n",
      "[Epoch 70/100, Step 304290, ETA 4h 9m 46.78s] epoch time: 8m 18.33s; step time: 0.1003s (Â±0.001903s); train time: 7m 38.45s; valid time: 39.88s; loss: -98.2638 (Â±1.18207); valid loss: -98.2371\n",
      "[Epoch 71/100, Step 308637, ETA 4h 1m 26.74s] epoch time: 8m 18.4s; step time: 0.1004s (Â±0.001929s); train time: 7m 38.51s; valid time: 39.89s; loss: -98.1389 (Â±1.63943); valid loss: -93.1204\n",
      "[Epoch 72/100, Step 312984, ETA 3h 53m 6.483s] Best valid loss updated: from -98.801608 to -98.824847\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 72/100, Step 312984, ETA 3h 53m 7.063s] epoch time: 8m 19.19s; step time: 0.1002s (Â±0.001871s); train time: 7m 37.82s; valid time: 41.37s; loss: -98.3039 (Â±1.24232); valid loss: -98.8248 (*)\n",
      "[Epoch 73/100, Step 317331, ETA 3h 44m 47.6s] Best valid loss updated: from -98.824847 to -98.953057\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 73/100, Step 317331, ETA 3h 44m 48.16s] epoch time: 8m 21.25s; step time: 0.1003s (Â±0.001909s); train time: 7m 39.83s; valid time: 41.42s; loss: -98.296 (Â±1.46051); valid loss: -98.9531 (*)\n",
      "[Epoch 74/100, Step 321678, ETA 3h 36m 28.04s] epoch time: 8m 17.98s; step time: 0.1003s (Â±0.001878s); train time: 7m 38.1s; valid time: 39.88s; loss: -98.4133 (Â±1.40104); valid loss: -98.6723\n",
      "[Epoch 75/100, Step 326025, ETA 3h 28m 8.363s] epoch time: 8m 19.12s; step time: 0.1003s (Â±0.00195s); train time: 7m 38.83s; valid time: 40.29s; loss: -98.4675 (Â±1.3721); valid loss: -96.9362\n",
      "[Epoch 76/100, Step 330372, ETA 3h 19m 48.53s] epoch time: 8m 18.57s; step time: 0.1003s (Â±0.001924s); train time: 7m 38.67s; valid time: 39.9s; loss: -98.5245 (Â±1.12205); valid loss: -98.9077\n",
      "[Epoch 77/100, Step 334719, ETA 3h 11m 28.69s] Best valid loss updated: from -98.953057 to -99.716677\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 77/100, Step 334719, ETA 3h 11m 29.15s] epoch time: 8m 20.02s; step time: 0.1003s (Â±0.001869s); train time: 7m 38.5s; valid time: 41.52s; loss: -98.4098 (Â±1.5575); valid loss: -99.7167 (*)\n",
      "[Epoch 78/100, Step 339066, ETA 3h 3m 9.349s] epoch time: 8m 18.55s; step time: 0.1004s (Â±0.001861s); train time: 7m 38.61s; valid time: 39.94s; loss: -98.4495 (Â±1.47412); valid loss: -98.8698\n",
      "[Epoch 79/100, Step 343413, ETA 2h 54m 49.89s] epoch time: 8m 19.73s; step time: 0.1004s (Â±0.001885s); train time: 7m 39.68s; valid time: 40.05s; loss: -98.5506 (Â±1.41479); valid loss: -98.2296\n",
      "[Epoch 80/100, Step 347760, ETA 2h 46m 30.53s] epoch time: 8m 20.15s; step time: 0.1004s (Â±0.00187s); train time: 7m 40.15s; valid time: 40s; loss: -98.5729 (Â±1.47772); valid loss: -98.3491\n",
      "[Epoch 80/100, Step 347760, ETA 2h 46m 30.53s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 352107, ETA 2h 38m 10.88s] Best valid loss updated: from -99.716677 to -100.023741\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 81/100, Step 352107, ETA 2h 38m 11.26s] epoch time: 8m 20.64s; step time: 0.1004s (Â±0.001848s); train time: 7m 39.05s; valid time: 41.59s; loss: -100.544 (Â±0.589663); valid loss: -100.024 (*)\n",
      "[Epoch 82/100, Step 356454, ETA 2h 29m 51.5s] Best valid loss updated: from -100.023741 to -100.622988\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 82/100, Step 356454, ETA 2h 29m 51.86s] epoch time: 8m 20.15s; step time: 0.1004s (Â±0.001859s); train time: 7m 38.62s; valid time: 41.53s; loss: -100.735 (Â±0.539658); valid loss: -100.623 (*)\n",
      "[Epoch 83/100, Step 360801, ETA 2h 21m 32.11s] epoch time: 8m 18.58s; step time: 0.1004s (Â±0.001946s); train time: 7m 38.66s; valid time: 39.92s; loss: -100.701 (Â±0.621456); valid loss: -100.231\n",
      "[Epoch 84/100, Step 365148, ETA 2h 13m 12.81s] epoch time: 8m 20.78s; step time: 0.1005s (Â±0.001873s); train time: 7m 40.77s; valid time: 40s; loss: -100.862 (Â±0.507505); valid loss: -100.381\n",
      "[Epoch 85/100, Step 369495, ETA 2h 4m 53.04s] epoch time: 8m 18.27s; step time: 0.1003s (Â±0.001943s); train time: 7m 38.33s; valid time: 39.94s; loss: -100.895 (Â±0.518273); valid loss: -100.218\n",
      "[Epoch 86/100, Step 373842, ETA 1h 56m 33.41s] epoch time: 8m 18.98s; step time: 0.1004s (Â±0.001883s); train time: 7m 38.99s; valid time: 39.99s; loss: -100.91 (Â±0.50886); valid loss: -100.549\n",
      "[Epoch 87/100, Step 378189, ETA 1h 48m 13.75s] epoch time: 8m 18.65s; step time: 0.1004s (Â±0.001816s); train time: 7m 38.75s; valid time: 39.9s; loss: -100.917 (Â±0.544263); valid loss: -100.409\n",
      "[Epoch 88/100, Step 382536, ETA 1h 39m 54.06s] epoch time: 8m 18.28s; step time: 0.1003s (Â±0.001883s); train time: 7m 38.34s; valid time: 39.94s; loss: -100.973 (Â±0.507984); valid loss: -100.231\n",
      "[Epoch 89/100, Step 386883, ETA 1h 31m 34.43s] epoch time: 8m 18.53s; step time: 0.1003s (Â±0.001939s); train time: 7m 38.51s; valid time: 40.03s; loss: -100.951 (Â±0.612107); valid loss: -100.377\n",
      "[Epoch 90/100, Step 391230, ETA 1h 23m 14.94s] epoch time: 8m 19.47s; step time: 0.1004s (Â±0.001881s); train time: 7m 39.48s; valid time: 39.99s; loss: -100.986 (Â±0.57554); valid loss: -100.452\n",
      "[Epoch 91/100, Step 395577, ETA 1h 14m 55.44s] epoch time: 8m 19.43s; step time: 0.1003s (Â±0.001877s); train time: 7m 39.6s; valid time: 39.83s; loss: -101.011 (Â±0.570123); valid loss: -100.404\n",
      "[Epoch 92/100, Step 399924, ETA 1h 6m 35.88s] epoch time: 8m 18.78s; step time: 0.1004s (Â±0.001888s); train time: 7m 38.8s; valid time: 39.98s; loss: -101.057 (Â±0.519345); valid loss: -100.563\n",
      "[Epoch 93/100, Step 404271, ETA 58m 16.34s] epoch time: 8m 18.68s; step time: 0.1004s (Â±0.001912s); train time: 7m 38.76s; valid time: 39.92s; loss: -101.061 (Â±0.528873); valid loss: -100.596\n",
      "[Epoch 94/100, Step 408618, ETA 49m 56.8s] Best valid loss updated: from -100.622988 to -101.056718\n",
      "Model saved at results/tuned_model_st8000_2023-12-09_20-34-52.\n",
      "[Epoch 94/100, Step 408618, ETA 49m 56.91s] epoch time: 8m 20.18s; step time: 0.1003s (Â±0.001947s); train time: 7m 38.61s; valid time: 41.57s; loss: -101.068 (Â±0.563271); valid loss: -101.057 (*)\n",
      "[Epoch 95/100, Step 412965, ETA 41m 37.43s] epoch time: 8m 19.74s; step time: 0.1004s (Â±0.00201s); train time: 7m 39.73s; valid time: 40.01s; loss: -101.087 (Â±0.55237); valid loss: -100.058\n",
      "[Epoch 96/100, Step 417312, ETA 33m 17.93s] epoch time: 8m 19.07s; step time: 0.1004s (Â±0.001913s); train time: 7m 39.18s; valid time: 39.89s; loss: -101.097 (Â±0.543386); valid loss: -100.445\n",
      "[Epoch 97/100, Step 421659, ETA 24m 58.41s] epoch time: 8m 18.27s; step time: 0.1003s (Â±0.001909s); train time: 7m 38.36s; valid time: 39.91s; loss: -101.134 (Â±0.536661); valid loss: -99.9363\n",
      "[Epoch 98/100, Step 426006, ETA 16m 38.92s] epoch time: 8m 18.62s; step time: 0.1004s (Â±0.001886s); train time: 7m 38.68s; valid time: 39.95s; loss: -101.167 (Â±0.537305); valid loss: -100.67\n",
      "[Epoch 99/100, Step 430353, ETA 8m 19.45s] epoch time: 8m 18.49s; step time: 0.1004s (Â±0.001891s); train time: 7m 38.62s; valid time: 39.87s; loss: -101.16 (Â±0.575135); valid loss: -101.012\n",
      "[Epoch 100/100, Step 434700, ETA 0s] epoch time: 8m 18.26s; step time: 0.1003s (Â±0.001878s); train time: 7m 38.34s; valid time: 39.93s; loss: -101.198 (Â±0.519204); valid loss: -100.327\n",
      "[Epoch 100/100, Step 434700, ETA 0s] Learning rate decreased to 1.5625e-06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp176pe6aa/variables.dat-408618\n",
      "2023-12-10 10:27:29,872 [INFO] tensorflow: Restoring parameters from /tmp/tmp176pe6aa/variables.dat-408618\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'best_valid_loss': -101.05671810036206,\n",
      " 'pred_time': 0.03277521057409571,\n",
      " 'pred_total_time': 60.038715839385986,\n",
      " 'train_time': 499.4479150104523,\n",
      " 'valid_time': 0.03292790045733834}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmppk111shmwandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpintlx7qlwandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpfyol6e8xwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpmfz_23dcwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 1 (No train)"
   ],
   "metadata": {
    "id": "gks3ghGKbDlM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp1 --max_epoch=0 --restore_dir=results/tuned_model_st8000_2 --scaler_path=results/tuned_model_st8000_2/results/scaler.pkl"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2VnOIWpzp3G",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702219253596,
     "user_tz": 300,
     "elapsed": 510890,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "bc04b4d4-d4f5-4745-fe21-3ac590604db8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "==================================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 0,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': 'results/tuned_model_st8000_2',\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'tuned_model_st8000_2_exp1',\n",
      " 'save_z': False,\n",
      " 'scaler_path': 'results/tuned_model_st8000_2/results/scaler.pkl',\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': None,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (5095382, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-10 14:32:39,109 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-10 14:32:43.780666: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-10 14:32:44.129494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-10 14:32:44.129744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-10 14:32:44.129779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-10 14:32:44.544545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-10 14:32:44.544593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-10 14:32:44.544607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-10 14:32:44.544714: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-10 14:32:44.544764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "2023-12-10 14:32:44,694 [INFO] tensorflow: Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "Variables restored from results/tuned_model_st8000_2.\n",
      "Start val loss: inf\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'pred_time': 0.03242189237668492, 'pred_total_time': 108.5304765701294}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpj9yugu8hwandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpg16arzxiwandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpics9kkzfwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpr9zuk1l6wandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 2b (10% data)"
   ],
   "metadata": {
    "id": "qElHCkhn17Ga"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --restore_dir=results/tuned_model_st8000_2 --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp2b --train_portion=0.1 --initial_lr=0.00005"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRqAfNXslyn2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702228411841,
     "user_tz": 300,
     "elapsed": 9157775,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "b9c40ab5-025c-49d1-a2de-53a9becaa7ab"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': 'results/tuned_model_st8000_2',\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'tuned_model_st8000_2_exp2b',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': 0.1,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (509538, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-10 14:41:17,947 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-10 14:41:22.331115: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-10 14:41:22.549785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-10 14:41:22.549974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-10 14:41:22.550002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-10 14:41:22.832736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-10 14:41:22.832787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-10 14:41:22.832800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-10 14:41:22.832891: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-10 14:41:22.832939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "2023-12-10 14:41:22,895 [INFO] tensorflow: Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "Variables restored from results/tuned_model_st8000_2.\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (407631, 16)\n",
      "[Epoch 1/100, Step 796] Best valid loss updated: from inf to -66.836673\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 1/100, Step 796, ETA 2h 35m 57.95s] epoch time: 1m 34.52s; step time: 0.1015s (Â±0.1058s); train time: 1m 25.25s; valid time: 9.27s; loss: -6.28547 (Â±863.733); valid loss: -66.8367 (*)\n",
      "[Epoch 2/100, Step 1592, ETA 2h 30m 31.69s] Best valid loss updated: from -66.836673 to -73.201515\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 2/100, Step 1592, ETA 2h 31m 18.63s] epoch time: 1m 30.75s; step time: 0.09786s (Â±0.002834s); train time: 1m 22.25s; valid time: 8.501s; loss: -69.7375 (Â±3.54184); valid loss: -73.2015 (*)\n",
      "[Epoch 3/100, Step 2388, ETA 2h 28m 2.13s] Best valid loss updated: from -73.201515 to -78.895177\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 3/100, Step 2388, ETA 2h 28m 32.37s] epoch time: 1m 30.36s; step time: 0.0977s (Â±0.001658s); train time: 1m 22.26s; valid time: 8.103s; loss: -73.1808 (Â±2.94308); valid loss: -78.8952 (*)\n",
      "[Epoch 4/100, Step 3184, ETA 2h 25m 59.95s] epoch time: 1m 29.36s; step time: 0.09769s (Â±0.001724s); train time: 1m 22.28s; valid time: 7.08s; loss: -74.9637 (Â±3.17808); valid loss: -74.4074\n",
      "[Epoch 5/100, Step 3980, ETA 2h 23m 56.38s] epoch time: 1m 29.55s; step time: 0.09774s (Â±0.001698s); train time: 1m 22.28s; valid time: 7.272s; loss: -76.0669 (Â±2.67699); valid loss: -78.5605\n",
      "[Epoch 6/100, Step 4776, ETA 2h 22m 14.05s] Best valid loss updated: from -78.895177 to -83.722312\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 6/100, Step 4776, ETA 2h 22m 29.08s] epoch time: 1m 31.14s; step time: 0.09769s (Â±0.001655s); train time: 1m 22.64s; valid time: 8.499s; loss: -77.4247 (Â±3.23978); valid loss: -83.7223 (*)\n",
      "[Epoch 7/100, Step 5572, ETA 2h 20m 40.43s] epoch time: 1m 29.62s; step time: 0.09768s (Â±0.001756s); train time: 1m 22.22s; valid time: 7.399s; loss: -77.4577 (Â±2.60622); valid loss: -68.9608\n",
      "[Epoch 8/100, Step 6368, ETA 2h 18m 55.17s] epoch time: 1m 29.5s; step time: 0.09776s (Â±0.001707s); train time: 1m 22.33s; valid time: 7.163s; loss: -78.0156 (Â±2.71935); valid loss: -77.8206\n",
      "[Epoch 9/100, Step 7164, ETA 2h 17m 11.51s] epoch time: 1m 29.31s; step time: 0.09765s (Â±0.001812s); train time: 1m 22.24s; valid time: 7.072s; loss: -79.0258 (Â±2.48612); valid loss: -79.1154\n",
      "[Epoch 10/100, Step 7960, ETA 2h 15m 33.09s] epoch time: 1m 29.57s; step time: 0.09784s (Â±0.001723s); train time: 1m 22.43s; valid time: 7.14s; loss: -78.9185 (Â±3.07198); valid loss: -79.8712\n",
      "[Epoch 11/100, Step 8756, ETA 2h 14m 0.6337s] epoch time: 1m 30.11s; step time: 0.09765s (Â±0.001676s); train time: 1m 22.72s; valid time: 7.387s; loss: -79.488 (Â±2.74843); valid loss: -80.6134\n",
      "[Epoch 12/100, Step 9552, ETA 2h 12m 28.9s] epoch time: 1m 30.15s; step time: 0.09773s (Â±0.001754s); train time: 1m 22.63s; valid time: 7.528s; loss: -79.748 (Â±2.41952); valid loss: -80.7975\n",
      "[Epoch 13/100, Step 10348, ETA 2h 10m 53.53s] epoch time: 1m 29.58s; step time: 0.09761s (Â±0.001813s); train time: 1m 22.16s; valid time: 7.412s; loss: -79.8621 (Â±2.49742); valid loss: -79.8002\n",
      "[Epoch 14/100, Step 11144, ETA 2h 9m 18.54s] epoch time: 1m 29.5s; step time: 0.09766s (Â±0.001722s); train time: 1m 22.26s; valid time: 7.237s; loss: -80.0673 (Â±2.92329); valid loss: -82.5851\n",
      "[Epoch 15/100, Step 11940, ETA 2h 7m 44.05s] Best valid loss updated: from -83.722312 to -84.157422\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 15/100, Step 11940, ETA 2h 7m 49.68s] epoch time: 1m 30.45s; step time: 0.09776s (Â±0.001668s); train time: 1m 22.38s; valid time: 8.075s; loss: -80.9707 (Â±2.7156); valid loss: -84.1574 (*)\n",
      "[Epoch 16/100, Step 12736, ETA 2h 6m 16.35s] epoch time: 1m 29.64s; step time: 0.09776s (Â±0.001715s); train time: 1m 22.4s; valid time: 7.24s; loss: -81.6518 (Â±3.69578); valid loss: -82.0909\n",
      "[Epoch 17/100, Step 13532, ETA 2h 4m 46.48s] epoch time: 1m 30.26s; step time: 0.09773s (Â±0.001684s); train time: 1m 22.74s; valid time: 7.523s; loss: -81.4195 (Â±2.50614); valid loss: -83.7585\n",
      "[Epoch 18/100, Step 14328, ETA 2h 3m 14.16s] epoch time: 1m 29.73s; step time: 0.09776s (Â±0.001679s); train time: 1m 22.22s; valid time: 7.508s; loss: -81.7528 (Â±3.20074); valid loss: -80.9018\n",
      "[Epoch 19/100, Step 15124, ETA 2h 1m 41.86s] epoch time: 1m 29.67s; step time: 0.0978s (Â±0.001689s); train time: 1m 22.39s; valid time: 7.283s; loss: -81.3056 (Â±2.68684); valid loss: -79.9059\n",
      "[Epoch 20/100, Step 15920, ETA 2h 9.358s] epoch time: 1m 29.56s; step time: 0.09784s (Â±0.001686s); train time: 1m 22.45s; valid time: 7.102s; loss: -81.6983 (Â±2.90847); valid loss: -83.3297\n",
      "[Epoch 20/100, Step 15920, ETA 2h 9.358s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 16716, ETA 1h 58m 36.66s] Best valid loss updated: from -84.157422 to -93.077991\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 21/100, Step 16716, ETA 1h 58m 41.69s] epoch time: 1m 30.77s; step time: 0.09768s (Â±0.001719s); train time: 1m 22.35s; valid time: 8.418s; loss: -89.2648 (Â±2.07611); valid loss: -93.078 (*)\n",
      "[Epoch 22/100, Step 17512, ETA 1h 57m 11.87s] epoch time: 1m 30.24s; step time: 0.09773s (Â±0.002652s); train time: 1m 22.76s; valid time: 7.48s; loss: -89.123 (Â±2.19101); valid loss: -90.2107\n",
      "[Epoch 23/100, Step 18308, ETA 1h 55m 40.72s] epoch time: 1m 29.85s; step time: 0.09753s (Â±0.001585s); train time: 1m 22.29s; valid time: 7.561s; loss: -89.5321 (Â±2.69659); valid loss: -90.0695\n",
      "[Epoch 24/100, Step 19104, ETA 1h 54m 8.87s] epoch time: 1m 29.6s; step time: 0.09777s (Â±0.001699s); train time: 1m 22.29s; valid time: 7.313s; loss: -89.7356 (Â±1.90333); valid loss: -90.5341\n",
      "[Epoch 25/100, Step 19900, ETA 1h 52m 35.08s] epoch time: 1m 28.89s; step time: 0.09746s (Â±0.001646s); train time: 1m 21.92s; valid time: 6.976s; loss: -89.0966 (Â±2.76398); valid loss: -86.6322\n",
      "[Epoch 26/100, Step 20696, ETA 1h 51m 2.204s] epoch time: 1m 29.08s; step time: 0.09756s (Â±0.00162s); train time: 1m 22.09s; valid time: 6.995s; loss: -90.1404 (Â±2.15856); valid loss: -90.9472\n",
      "[Epoch 27/100, Step 21492, ETA 1h 49m 30.02s] epoch time: 1m 29.23s; step time: 0.09769s (Â±0.00162s); train time: 1m 22.1s; valid time: 7.128s; loss: -89.7683 (Â±2.02331); valid loss: -91.149\n",
      "[Epoch 28/100, Step 22288, ETA 1h 47m 59.26s] epoch time: 1m 29.71s; step time: 0.09752s (Â±0.001624s); train time: 1m 22.32s; valid time: 7.388s; loss: -89.8472 (Â±3.40394); valid loss: -90.8943\n",
      "[Epoch 29/100, Step 23084, ETA 1h 46m 27.2s] epoch time: 1m 29.14s; step time: 0.0974s (Â±0.001481s); train time: 1m 21.75s; valid time: 7.397s; loss: -90.397 (Â±2.09703); valid loss: -91.0337\n",
      "[Epoch 30/100, Step 23880, ETA 1h 44m 55.25s] epoch time: 1m 29.1s; step time: 0.09753s (Â±0.001607s); train time: 1m 21.93s; valid time: 7.178s; loss: -89.9937 (Â±2.33062); valid loss: -91.2404\n",
      "[Epoch 31/100, Step 24676, ETA 1h 43m 23.39s] epoch time: 1m 29.07s; step time: 0.09765s (Â±0.001603s); train time: 1m 22.06s; valid time: 7.007s; loss: -89.8913 (Â±2.32483); valid loss: -90.4449\n",
      "[Epoch 32/100, Step 25472, ETA 1h 41m 51.43s] epoch time: 1m 28.94s; step time: 0.09746s (Â±0.001682s); train time: 1m 21.9s; valid time: 7.038s; loss: -90.5239 (Â±2.16638); valid loss: -88.287\n",
      "[Epoch 33/100, Step 26268, ETA 1h 40m 21.09s] epoch time: 1m 29.64s; step time: 0.09759s (Â±0.001554s); train time: 1m 22.4s; valid time: 7.245s; loss: -90.2999 (Â±2.44036); valid loss: -90.7748\n",
      "[Epoch 34/100, Step 27064, ETA 1h 38m 51.31s] epoch time: 1m 29.91s; step time: 0.09757s (Â±0.001623s); train time: 1m 22.42s; valid time: 7.49s; loss: -90.5083 (Â±2.14294); valid loss: -90.1521\n",
      "[Epoch 35/100, Step 27860, ETA 1h 37m 20.34s] epoch time: 1m 29.28s; step time: 0.09761s (Â±0.001511s); train time: 1m 21.95s; valid time: 7.323s; loss: -90.7465 (Â±2.25519); valid loss: -88.6223\n",
      "[Epoch 36/100, Step 28656, ETA 1h 35m 49.16s] epoch time: 1m 29.1s; step time: 0.09758s (Â±0.001662s); train time: 1m 22.04s; valid time: 7.064s; loss: -90.7087 (Â±2.58399); valid loss: -90.7907\n",
      "[Epoch 37/100, Step 29452, ETA 1h 34m 18.32s] epoch time: 1m 29.23s; step time: 0.0977s (Â±0.001673s); train time: 1m 22.13s; valid time: 7.099s; loss: -90.3504 (Â±2.64153); valid loss: -91.1239\n",
      "[Epoch 38/100, Step 30248, ETA 1h 32m 48.15s] epoch time: 1m 29.6s; step time: 0.09767s (Â±0.001694s); train time: 1m 22.25s; valid time: 7.349s; loss: -90.3635 (Â±2.88633); valid loss: -92.2524\n",
      "[Epoch 39/100, Step 31044, ETA 1h 31m 18.49s] epoch time: 1m 29.91s; step time: 0.09766s (Â±0.001737s); train time: 1m 22.54s; valid time: 7.364s; loss: -90.3787 (Â±3.34866); valid loss: -90.7604\n",
      "[Epoch 40/100, Step 31840, ETA 1h 29m 48.08s] epoch time: 1m 29.41s; step time: 0.09764s (Â±0.001662s); train time: 1m 22.13s; valid time: 7.286s; loss: -90.6461 (Â±2.30839); valid loss: -93.0048\n",
      "[Epoch 40/100, Step 31840, ETA 1h 29m 48.08s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 32636, ETA 1h 28m 17.43s] Best valid loss updated: from -93.077991 to -96.953194\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 41/100, Step 32636, ETA 1h 28m 18.92s] epoch time: 1m 30.25s; step time: 0.09764s (Â±0.001592s); train time: 1m 22.12s; valid time: 8.13s; loss: -95.858 (Â±1.49114); valid loss: -96.9532 (*)\n",
      "[Epoch 42/100, Step 33432, ETA 1h 26m 48.3s] epoch time: 1m 29.23s; step time: 0.09757s (Â±0.00164s); train time: 1m 22.1s; valid time: 7.124s; loss: -96.6262 (Â±1.22071); valid loss: -96.5647\n",
      "[Epoch 43/100, Step 34228, ETA 1h 25m 19.57s] Best valid loss updated: from -96.953194 to -97.079122\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 43/100, Step 34228, ETA 1h 25m 21.62s] epoch time: 1m 32.15s; step time: 0.09818s (Â±0.002034s); train time: 1m 23.14s; valid time: 9.008s; loss: -96.7563 (Â±1.31945); valid loss: -97.0791 (*)\n",
      "[Epoch 44/100, Step 35024, ETA 1h 23m 51.88s] epoch time: 1m 29.95s; step time: 0.09799s (Â±0.003077s); train time: 1m 22.52s; valid time: 7.429s; loss: -96.9068 (Â±2.16083); valid loss: -96.824\n",
      "[Epoch 45/100, Step 35820, ETA 1h 22m 21.53s] Best valid loss updated: from -97.079122 to -97.862583\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 45/100, Step 35820, ETA 1h 22m 22.71s] epoch time: 1m 30.41s; step time: 0.09771s (Â±0.001822s); train time: 1m 22.1s; valid time: 8.31s; loss: -96.7363 (Â±2.50044); valid loss: -97.8626 (*)\n",
      "[Epoch 46/100, Step 36616, ETA 1h 20m 52.2s] Best valid loss updated: from -97.862583 to -98.116925\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 46/100, Step 36616, ETA 1h 20m 53.38s] epoch time: 1m 30.33s; step time: 0.09772s (Â±0.00186s); train time: 1m 22.25s; valid time: 8.083s; loss: -96.7691 (Â±2.34159); valid loss: -98.1169 (*)\n",
      "[Epoch 47/100, Step 37412, ETA 1h 19m 22.88s] epoch time: 1m 29.32s; step time: 0.09778s (Â±0.001801s); train time: 1m 22.21s; valid time: 7.105s; loss: -97.2818 (Â±1.45992); valid loss: -96.7519\n",
      "[Epoch 48/100, Step 38208, ETA 1h 17m 52.84s] epoch time: 1m 29.7s; step time: 0.09752s (Â±0.001622s); train time: 1m 22.34s; valid time: 7.361s; loss: -97.1788 (Â±1.89342); valid loss: -98.0333\n",
      "[Epoch 49/100, Step 39004, ETA 1h 16m 22.59s] Best valid loss updated: from -98.116925 to -100.261068\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 49/100, Step 39004, ETA 1h 16m 23.68s] epoch time: 1m 30.55s; step time: 0.09746s (Â±0.001548s); train time: 1m 22.01s; valid time: 8.535s; loss: -97.2688 (Â±1.62275); valid loss: -100.261 (*)\n",
      "[Epoch 50/100, Step 39800, ETA 1h 14m 52.85s] epoch time: 1m 28.92s; step time: 0.09749s (Â±0.001602s); train time: 1m 21.82s; valid time: 7.095s; loss: -96.2978 (Â±3.53284); valid loss: -98.4208\n",
      "[Epoch 51/100, Step 40596, ETA 1h 13m 22.06s] epoch time: 1m 28.89s; step time: 0.0975s (Â±0.00156s); train time: 1m 21.88s; valid time: 7.003s; loss: -97.3532 (Â±2.38966); valid loss: -98.4837\n",
      "[Epoch 52/100, Step 41392, ETA 1h 11m 51.39s] epoch time: 1m 28.94s; step time: 0.0975s (Â±0.001564s); train time: 1m 21.86s; valid time: 7.073s; loss: -97.5673 (Â±2.20817); valid loss: -95.7718\n",
      "[Epoch 53/100, Step 42188, ETA 1h 10m 21.41s] epoch time: 1m 29.64s; step time: 0.09755s (Â±0.001601s); train time: 1m 22.26s; valid time: 7.381s; loss: -97.4213 (Â±1.51809); valid loss: -98.8055\n",
      "[Epoch 54/100, Step 42984, ETA 1h 8m 51.03s] epoch time: 1m 29.15s; step time: 0.09744s (Â±0.001517s); train time: 1m 21.81s; valid time: 7.341s; loss: -96.9112 (Â±3.11951); valid loss: -99.2339\n",
      "[Epoch 55/100, Step 43780, ETA 1h 7m 20.53s] epoch time: 1m 28.96s; step time: 0.09752s (Â±0.001559s); train time: 1m 21.76s; valid time: 7.192s; loss: -97.7972 (Â±1.66521); valid loss: -96.507\n",
      "[Epoch 56/100, Step 44576, ETA 1h 5m 50.08s] epoch time: 1m 28.95s; step time: 0.0976s (Â±0.001572s); train time: 1m 21.92s; valid time: 7.036s; loss: -97.4073 (Â±2.24162); valid loss: -99.1353\n",
      "[Epoch 57/100, Step 45372, ETA 1h 4m 19.84s] epoch time: 1m 29.16s; step time: 0.09754s (Â±0.001656s); train time: 1m 22s; valid time: 7.154s; loss: -96.8989 (Â±2.86775); valid loss: -98.8758\n",
      "[Epoch 58/100, Step 46168, ETA 1h 2m 50.15s] epoch time: 1m 29.87s; step time: 0.09757s (Â±0.001601s); train time: 1m 22.49s; valid time: 7.375s; loss: -96.8167 (Â±4.02593); valid loss: -97.8866\n",
      "[Epoch 59/100, Step 46964, ETA 1h 1m 20.12s] epoch time: 1m 29.38s; step time: 0.0974s (Â±0.001593s); train time: 1m 21.98s; valid time: 7.401s; loss: -97.4506 (Â±2.19248); valid loss: -98.7592\n",
      "[Epoch 60/100, Step 47760, ETA 59m 49.96s] epoch time: 1m 29.15s; step time: 0.09761s (Â±0.001708s); train time: 1m 21.98s; valid time: 7.173s; loss: -97.4811 (Â±2.06838); valid loss: -97.1312\n",
      "[Epoch 60/100, Step 47760, ETA 59m 49.96s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 48556, ETA 58m 19.74s] Best valid loss updated: from -100.261068 to -101.701473\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 61/100, Step 48556, ETA 58m 20.41s] epoch time: 1m 30.06s; step time: 0.09756s (Â±0.001574s); train time: 1m 22s; valid time: 8.06s; loss: -100.8 (Â±1.74872); valid loss: -101.701 (*)\n",
      "[Epoch 62/100, Step 49352, ETA 56m 50.33s] Best valid loss updated: from -101.701473 to -101.988925\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 62/100, Step 49352, ETA 56m 51.43s] epoch time: 1m 31.02s; step time: 0.09752s (Â±0.001597s); train time: 1m 22.11s; valid time: 8.919s; loss: -101.439 (Â±0.907957); valid loss: -101.989 (*)\n",
      "[Epoch 63/100, Step 50148, ETA 55m 21.72s] Best valid loss updated: from -101.988925 to -102.290149\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 63/100, Step 50148, ETA 55m 22.41s] epoch time: 1m 31.06s; step time: 0.0976s (Â±0.002779s); train time: 1m 22.38s; valid time: 8.675s; loss: -101.564 (Â±0.804572); valid loss: -102.29 (*)\n",
      "[Epoch 64/100, Step 50944, ETA 53m 52.28s] epoch time: 1m 29.2s; step time: 0.09764s (Â±0.00172s); train time: 1m 22.05s; valid time: 7.148s; loss: -101.728 (Â±0.692932); valid loss: -101.891\n",
      "[Epoch 65/100, Step 51740, ETA 52m 22.2s] Best valid loss updated: from -102.290149 to -103.029723\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 65/100, Step 51740, ETA 52m 22.83s] epoch time: 1m 30.41s; step time: 0.09771s (Â±0.001664s); train time: 1m 22.16s; valid time: 8.245s; loss: -101.685 (Â±0.964131); valid loss: -103.03 (*)\n",
      "[Epoch 66/100, Step 52536, ETA 50m 53.06s] epoch time: 1m 29.85s; step time: 0.0978s (Â±0.001863s); train time: 1m 22.59s; valid time: 7.255s; loss: -101.968 (Â±0.656951); valid loss: -102.072\n",
      "[Epoch 67/100, Step 53332, ETA 49m 23.27s] epoch time: 1m 29.81s; step time: 0.09764s (Â±0.001544s); train time: 1m 22.41s; valid time: 7.396s; loss: -101.785 (Â±0.924737); valid loss: -102.15\n",
      "[Epoch 68/100, Step 54128, ETA 47m 53.14s] epoch time: 1m 29.07s; step time: 0.09743s (Â±0.001505s); train time: 1m 21.73s; valid time: 7.344s; loss: -102.144 (Â±0.579935); valid loss: -100.824\n",
      "[Epoch 69/100, Step 54924, ETA 46m 22.97s] epoch time: 1m 28.93s; step time: 0.09757s (Â±0.001615s); train time: 1m 21.86s; valid time: 7.063s; loss: -101.917 (Â±0.758727); valid loss: -102.332\n",
      "[Epoch 70/100, Step 55720, ETA 44m 52.79s] epoch time: 1m 28.83s; step time: 0.0975s (Â±0.001637s); train time: 1m 21.83s; valid time: 6.996s; loss: -101.521 (Â±1.5315); valid loss: -102.654\n",
      "[Epoch 71/100, Step 56516, ETA 43m 22.72s] epoch time: 1m 29s; step time: 0.09765s (Â±0.0017s); train time: 1m 21.94s; valid time: 7.059s; loss: -102.107 (Â±0.863065); valid loss: -102.751\n",
      "[Epoch 72/100, Step 57312, ETA 41m 52.9s] epoch time: 1m 29.58s; step time: 0.09749s (Â±0.001511s); train time: 1m 22.23s; valid time: 7.35s; loss: -102.116 (Â±1.14828); valid loss: -93.815\n",
      "[Epoch 73/100, Step 58108, ETA 40m 23.02s] epoch time: 1m 29.36s; step time: 0.09754s (Â±0.001501s); train time: 1m 21.97s; valid time: 7.398s; loss: -101.69 (Â±1.57207); valid loss: -102.668\n",
      "[Epoch 74/100, Step 58904, ETA 38m 52.99s] epoch time: 1m 28.92s; step time: 0.09752s (Â±0.001614s); train time: 1m 21.78s; valid time: 7.143s; loss: -102.191 (Â±0.746676); valid loss: -102.425\n",
      "[Epoch 75/100, Step 59700, ETA 37m 22.96s] epoch time: 1m 28.83s; step time: 0.09751s (Â±0.001621s); train time: 1m 21.84s; valid time: 6.994s; loss: -102.166 (Â±0.786272); valid loss: -102.656\n",
      "[Epoch 76/100, Step 60496, ETA 35m 52.98s] epoch time: 1m 28.9s; step time: 0.09759s (Â±0.001552s); train time: 1m 21.9s; valid time: 6.995s; loss: -102.339 (Â±0.642002); valid loss: -102.815\n",
      "[Epoch 77/100, Step 61292, ETA 34m 23.18s] epoch time: 1m 29.4s; step time: 0.09749s (Â±0.001529s); train time: 1m 22.14s; valid time: 7.265s; loss: -102.328 (Â±0.725148); valid loss: -102.573\n",
      "[Epoch 78/100, Step 62088, ETA 32m 53.41s] epoch time: 1m 29.47s; step time: 0.09757s (Â±0.00156s); train time: 1m 22.11s; valid time: 7.356s; loss: -102.129 (Â±0.969238); valid loss: -102.435\n",
      "[Epoch 79/100, Step 62884, ETA 31m 23.55s] epoch time: 1m 29.07s; step time: 0.09755s (Â±0.001526s); train time: 1m 21.86s; valid time: 7.213s; loss: -102.221 (Â±0.913832); valid loss: -102.349\n",
      "[Epoch 80/100, Step 63680, ETA 29m 53.64s] Best valid loss updated: from -103.029723 to -103.161037\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 80/100, Step 63680, ETA 29m 53.92s] epoch time: 1m 29.97s; step time: 0.09763s (Â±0.001666s); train time: 1m 21.89s; valid time: 8.079s; loss: -102.347 (Â±0.721864); valid loss: -103.161 (*)\n",
      "[Epoch 80/100, Step 63680, ETA 29m 53.92s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 64476, ETA 28m 24.04s] Best valid loss updated: from -103.161037 to -104.110417\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 81/100, Step 64476, ETA 28m 24.48s] epoch time: 1m 30.78s; step time: 0.09763s (Â±0.001651s); train time: 1m 21.88s; valid time: 8.894s; loss: -103.792 (Â±0.601479); valid loss: -104.11 (*)\n",
      "[Epoch 82/100, Step 65272, ETA 26m 54.77s] epoch time: 1m 29.7s; step time: 0.0977s (Â±0.002656s); train time: 1m 22.32s; valid time: 7.38s; loss: -103.94 (Â±0.553715); valid loss: -104.025\n",
      "[Epoch 83/100, Step 66068, ETA 25m 24.94s] Best valid loss updated: from -104.110417 to -104.126863\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 83/100, Step 66068, ETA 25m 25.18s] epoch time: 1m 30.29s; step time: 0.09764s (Â±0.001641s); train time: 1m 21.91s; valid time: 8.38s; loss: -103.914 (Â±0.566023); valid loss: -104.127 (*)\n",
      "[Epoch 84/100, Step 66864, ETA 23m 55.32s] Best valid loss updated: from -104.126863 to -104.174239\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 84/100, Step 66864, ETA 23m 55.57s] epoch time: 1m 30.26s; step time: 0.09758s (Â±0.001649s); train time: 1m 21.88s; valid time: 8.374s; loss: -103.935 (Â±0.644547); valid loss: -104.174 (*)\n",
      "[Epoch 85/100, Step 67660, ETA 22m 25.78s] Best valid loss updated: from -104.174239 to -104.389872\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 85/100, Step 67660, ETA 22m 26.13s] epoch time: 1m 31.34s; step time: 0.09753s (Â±0.001668s); train time: 1m 22.07s; valid time: 9.267s; loss: -104.031 (Â±0.603635); valid loss: -104.39 (*)\n",
      "[Epoch 86/100, Step 68456, ETA 20m 56.35s] epoch time: 1m 29.5s; step time: 0.09768s (Â±0.002622s); train time: 1m 22.1s; valid time: 7.401s; loss: -104.073 (Â±0.612233); valid loss: -104.329\n",
      "[Epoch 87/100, Step 69252, ETA 19m 26.54s] epoch time: 1m 29.26s; step time: 0.09763s (Â±0.001629s); train time: 1m 22.11s; valid time: 7.146s; loss: -104.076 (Â±0.587977); valid loss: -104.338\n",
      "[Epoch 88/100, Step 70048, ETA 17m 56.73s] epoch time: 1m 29.17s; step time: 0.0976s (Â±0.001689s); train time: 1m 22.08s; valid time: 7.081s; loss: -104.068 (Â±0.644466); valid loss: -104.33\n",
      "[Epoch 89/100, Step 70844, ETA 16m 26.96s] Best valid loss updated: from -104.389872 to -104.405662\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 89/100, Step 70844, ETA 16m 27.22s] epoch time: 1m 31.53s; step time: 0.0976s (Â±0.001667s); train time: 1m 22.12s; valid time: 9.409s; loss: -104.061 (Â±0.641041); valid loss: -104.406 (*)\n",
      "[Epoch 90/100, Step 71640, ETA 14m 57.46s] epoch time: 1m 29.66s; step time: 0.09775s (Â±0.002722s); train time: 1m 22.19s; valid time: 7.472s; loss: -104.108 (Â±0.628241); valid loss: -104.169\n",
      "[Epoch 91/100, Step 72436, ETA 13m 27.67s] Best valid loss updated: from -104.405662 to -104.509377\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 91/100, Step 72436, ETA 13m 27.81s] epoch time: 1m 30.65s; step time: 0.09767s (Â±0.001673s); train time: 1m 22.12s; valid time: 8.528s; loss: -104.177 (Â±0.579279); valid loss: -104.509 (*)\n",
      "[Epoch 92/100, Step 73232, ETA 11m 58.01s] epoch time: 1m 29.23s; step time: 0.09757s (Â±0.001689s); train time: 1m 22.18s; valid time: 7.051s; loss: -104.202 (Â±0.586098); valid loss: -104.336\n",
      "[Epoch 93/100, Step 74028, ETA 10m 28.26s] Best valid loss updated: from -104.509377 to -104.550396\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 93/100, Step 74028, ETA 10m 28.4s] epoch time: 1m 31.72s; step time: 0.09766s (Â±0.001685s); train time: 1m 22.41s; valid time: 9.31s; loss: -104.186 (Â±0.636287); valid loss: -104.55 (*)\n",
      "[Epoch 94/100, Step 74824, ETA 8m 58.64s] epoch time: 1m 29.85s; step time: 0.09805s (Â±0.003238s); train time: 1m 22.48s; valid time: 7.374s; loss: -104.166 (Â±0.648645); valid loss: -104.535\n",
      "[Epoch 95/100, Step 75620, ETA 7m 28.83s] Best valid loss updated: from -104.550396 to -104.582736\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 95/100, Step 75620, ETA 7m 28.91s] epoch time: 1m 30.7s; step time: 0.09763s (Â±0.001687s); train time: 1m 22.11s; valid time: 8.586s; loss: -104.268 (Â±0.590488); valid loss: -104.583 (*)\n",
      "[Epoch 96/100, Step 76416, ETA 5m 59.11s] epoch time: 1m 29.34s; step time: 0.09767s (Â±0.002738s); train time: 1m 22.2s; valid time: 7.14s; loss: -104.269 (Â±0.588207); valid loss: -104.494\n",
      "[Epoch 97/100, Step 77212, ETA 4m 29.34s] Best valid loss updated: from -104.582736 to -104.629510\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 97/100, Step 77212, ETA 4m 29.38s] epoch time: 1m 31.38s; step time: 0.09754s (Â±0.001625s); train time: 1m 22.44s; valid time: 8.935s; loss: -104.25 (Â±0.57321); valid loss: -104.63 (*)\n",
      "[Epoch 98/100, Step 78008, ETA 2m 59.58s] epoch time: 1m 29.37s; step time: 0.09762s (Â±0.002807s); train time: 1m 22.07s; valid time: 7.303s; loss: -104.265 (Â±0.612184); valid loss: -104.412\n",
      "[Epoch 99/100, Step 78804, ETA 1m 29.78s] Best valid loss updated: from -104.629510 to -104.703930\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_2023-12-10_14-41-03.\n",
      "[Epoch 99/100, Step 78804, ETA 1m 29.8s] epoch time: 1m 30.7s; step time: 0.09771s (Â±0.001731s); train time: 1m 22.18s; valid time: 8.523s; loss: -104.304 (Â±0.613968); valid loss: -104.704 (*)\n",
      "[Epoch 100/100, Step 79600, ETA 0s] epoch time: 1m 29.44s; step time: 0.09773s (Â±0.003049s); train time: 1m 22.24s; valid time: 7.196s; loss: -104.308 (Â±0.60577); valid loss: -104.5\n",
      "[Epoch 100/100, Step 79600, ETA 0s] Learning rate decreased to 1.5625e-06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpynpajmtn/variables.dat-78804\n",
      "2023-12-10 17:11:03,076 [INFO] tensorflow: Restoring parameters from /tmp/tmpynpajmtn/variables.dat-78804\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'best_valid_loss': -104.70392955586364,\n",
      " 'pred_time': 0.032161406878947724,\n",
      " 'pred_total_time': 107.14135670661926,\n",
      " 'train_time': 89.80107468366623,\n",
      " 'valid_time': 0.03211203516428195}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpsl9ajdatwandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpkhm_0zvewandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpgjy8a_xxwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp90tz766vwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 2a (30 days per disk)"
   ],
   "metadata": {
    "id": "aFq68XhV_HhF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --restore_dir=results/tuned_model_st8000_2 --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp2a --train_days_per_disk=30 --initial_lr=0.00005"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXakQ3HL2S-B",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702233292400,
     "user_tz": 300,
     "elapsed": 2661183,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "e800dcc0-b9ed-4805-8317-ca7ae3fa8d1b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': 'results/tuned_model_st8000_2',\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'tuned_model_st8000_2_exp2a',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': 30,\n",
      " 'train_portion': None,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (424735, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-10 17:50:46,609 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-10 17:50:50.752913: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-10 17:50:50.977855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-10 17:50:50.978060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-10 17:50:50.978091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-10 17:50:51.251440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-10 17:50:51.251491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-10 17:50:51.251503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-10 17:50:51.251589: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-10 17:50:51.251637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "2023-12-10 17:50:51,305 [INFO] tensorflow: Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "Variables restored from results/tuned_model_st8000_2.\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (339788, 16)\n",
      "[Epoch 1/100, Step 663] Best valid loss updated: from inf to -70.676407\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 1/100, Step 663, ETA 45m 25.42s] epoch time: 27.53s; step time: 0.03139s (Â±0.09785s); train time: 24.1s; valid time: 3.423s; loss: 5.90642 (Â±901.828); valid loss: -70.6764 (*)\n",
      "[Epoch 2/100, Step 1326, ETA 41m 58.11s] epoch time: 23.86s; step time: 0.02713s (Â±0.002396s); train time: 21.14s; valid time: 2.723s; loss: -66.717 (Â±4.01365); valid loss: -64.9906\n",
      "[Epoch 3/100, Step 1989, ETA 40m 8.584s] Best valid loss updated: from -70.676407 to -76.835242\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 3/100, Step 1989, ETA 40m 36.54s] epoch time: 23.97s; step time: 0.027s (Â±0.002034s); train time: 20.97s; valid time: 2.998s; loss: -72.0963 (Â±3.50237); valid loss: -76.8352 (*)\n",
      "[Epoch 4/100, Step 2652, ETA 39m 47.92s] epoch time: 24.14s; step time: 0.02773s (Â±0.0023s); train time: 21.98s; valid time: 2.154s; loss: -74.6705 (Â±2.75411); valid loss: -76.5116\n",
      "[Epoch 5/100, Step 3315, ETA 39m 8.191s] Best valid loss updated: from -76.835242 to -77.549878\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 5/100, Step 3315, ETA 39m 24.92s] epoch time: 24.97s; step time: 0.02778s (Â±0.002213s); train time: 21.63s; valid time: 3.34s; loss: -76.2089 (Â±3.11442); valid loss: -77.5499 (*)\n",
      "[Epoch 6/100, Step 3978, ETA 38m 46.71s] epoch time: 24.04s; step time: 0.02766s (Â±0.002026s); train time: 21.37s; valid time: 2.674s; loss: -77.0748 (Â±2.68524); valid loss: -75.4728\n",
      "[Epoch 7/100, Step 4641, ETA 38m 15.16s] Best valid loss updated: from -77.549878 to -78.702271\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 7/100, Step 4641, ETA 38m 27.28s] epoch time: 25.15s; step time: 0.02803s (Â±0.00209s); train time: 22.09s; valid time: 3.066s; loss: -78.0631 (Â±2.64405); valid loss: -78.7023 (*)\n",
      "[Epoch 8/100, Step 5304, ETA 37m 58.9s] Best valid loss updated: from -78.702271 to -80.609337\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 8/100, Step 5304, ETA 38m 10.15s] epoch time: 25.48s; step time: 0.02857s (Â±0.002376s); train time: 22.28s; valid time: 3.197s; loss: -78.8698 (Â±2.71741); valid loss: -80.6093 (*)\n",
      "[Epoch 9/100, Step 5967, ETA 37m 47.33s] epoch time: 25.1s; step time: 0.02876s (Â±0.002532s); train time: 22.55s; valid time: 2.55s; loss: -79.4022 (Â±2.85552); valid loss: -77.8123\n",
      "[Epoch 10/100, Step 6630, ETA 37m 20.69s] Best valid loss updated: from -80.609337 to -82.468585\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 10/100, Step 6630, ETA 37m 35.56s] epoch time: 26.37s; step time: 0.02834s (Â±0.002034s); train time: 22.08s; valid time: 4.299s; loss: -79.7455 (Â±2.59091); valid loss: -82.4686 (*)\n",
      "[Epoch 11/100, Step 7293, ETA 37m 10.42s] epoch time: 25.05s; step time: 0.0287s (Â±0.00283s); train time: 22.75s; valid time: 2.299s; loss: -80.4784 (Â±2.86539); valid loss: -81.1755\n",
      "[Epoch 12/100, Step 7956, ETA 36m 51.8s] Best valid loss updated: from -82.468585 to -85.362832\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 12/100, Step 7956, ETA 36m 59.87s] epoch time: 27.04s; step time: 0.02996s (Â±0.003219s); train time: 23.62s; valid time: 3.423s; loss: -80.6419 (Â±2.54903); valid loss: -85.3628 (*)\n",
      "[Epoch 13/100, Step 8619, ETA 36m 37.32s] epoch time: 25.62s; step time: 0.02953s (Â±0.002819s); train time: 23.28s; valid time: 2.341s; loss: -81.257 (Â±2.16908); valid loss: -79.0799\n",
      "[Epoch 14/100, Step 9282, ETA 36m 14.73s] epoch time: 25.69s; step time: 0.02911s (Â±0.002822s); train time: 22.83s; valid time: 2.859s; loss: -81.5416 (Â±2.57107); valid loss: -79.2738\n",
      "[Epoch 15/100, Step 9945, ETA 35m 48.37s] epoch time: 25.1s; step time: 0.02873s (Â±0.002473s); train time: 22.78s; valid time: 2.314s; loss: -81.383 (Â±2.54837); valid loss: -78.8089\n",
      "[Epoch 16/100, Step 10608, ETA 35m 27.57s] epoch time: 26.13s; step time: 0.02992s (Â±0.00308s); train time: 23.82s; valid time: 2.305s; loss: -81.9682 (Â±2.39591); valid loss: -83.7973\n",
      "[Epoch 17/100, Step 11271, ETA 35m 5.704s] epoch time: 26.04s; step time: 0.03s (Â±0.003022s); train time: 23.76s; valid time: 2.28s; loss: -82.7394 (Â±2.79731); valid loss: -83.1035\n",
      "[Epoch 18/100, Step 11934, ETA 34m 41.1s] epoch time: 25.54s; step time: 0.02894s (Â±0.002626s); train time: 22.59s; valid time: 2.945s; loss: -82.3713 (Â±2.44289); valid loss: -83.7555\n",
      "[Epoch 19/100, Step 12597, ETA 34m 12.23s] epoch time: 24.56s; step time: 0.02834s (Â±0.001952s); train time: 22.3s; valid time: 2.258s; loss: -82.6616 (Â±2.46467); valid loss: -83.7667\n",
      "[Epoch 20/100, Step 13260, ETA 33m 45.47s] epoch time: 24.98s; step time: 0.02906s (Â±0.002409s); train time: 22.75s; valid time: 2.231s; loss: -82.802 (Â±2.37259); valid loss: -81.8415\n",
      "[Epoch 20/100, Step 13260, ETA 33m 45.47s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 13923, ETA 33m 19.45s] Best valid loss updated: from -85.362832 to -89.420468\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 21/100, Step 13923, ETA 33m 23.41s] epoch time: 26.18s; step time: 0.02914s (Â±0.002432s); train time: 22.84s; valid time: 3.345s; loss: -89.735 (Â±2.48003); valid loss: -89.4205 (*)\n",
      "[Epoch 22/100, Step 14586, ETA 32m 57.18s] Best valid loss updated: from -89.420468 to -90.359949\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 22/100, Step 14586, ETA 33m 1.593s] epoch time: 26.36s; step time: 0.02853s (Â±0.002121s); train time: 22.2s; valid time: 4.156s; loss: -90.2144 (Â±2.65712); valid loss: -90.3599 (*)\n",
      "[Epoch 23/100, Step 15249, ETA 32m 32.79s] Best valid loss updated: from -90.359949 to -90.679756\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 23/100, Step 15249, ETA 32m 38.69s] epoch time: 26.15s; step time: 0.02834s (Â±0.00202s); train time: 21.99s; valid time: 4.158s; loss: -90.2983 (Â±2.43444); valid loss: -90.6798 (*)\n",
      "[Epoch 24/100, Step 15912, ETA 32m 11.46s] epoch time: 24.87s; step time: 0.02871s (Â±0.002766s); train time: 22.66s; valid time: 2.214s; loss: -89.6445 (Â±3.15774); valid loss: -90.4518\n",
      "[Epoch 25/100, Step 16575, ETA 31m 44.48s] Best valid loss updated: from -90.679756 to -91.013555\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 25/100, Step 16575, ETA 31m 47.94s] epoch time: 26.04s; step time: 0.02905s (Â±0.002571s); train time: 22.69s; valid time: 3.354s; loss: -90.9134 (Â±2.56325); valid loss: -91.0136 (*)\n",
      "[Epoch 26/100, Step 17238, ETA 31m 20.85s] Best valid loss updated: from -91.013555 to -93.169787\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 26/100, Step 17238, ETA 31m 24.14s] epoch time: 26.01s; step time: 0.02895s (Â±0.002357s); train time: 22.63s; valid time: 3.383s; loss: -90.6375 (Â±1.94518); valid loss: -93.1698 (*)\n",
      "[Epoch 27/100, Step 17901, ETA 30m 57.26s] epoch time: 24.94s; step time: 0.02838s (Â±0.00198s); train time: 22.07s; valid time: 2.87s; loss: -90.3468 (Â±2.70106); valid loss: -89.3005\n",
      "[Epoch 28/100, Step 18564, ETA 30m 29.44s] epoch time: 24.51s; step time: 0.02831s (Â±0.002104s); train time: 22.3s; valid time: 2.215s; loss: -90.3334 (Â±2.52378); valid loss: -91.0506\n",
      "[Epoch 29/100, Step 19227, ETA 30m 2.727s] epoch time: 24.88s; step time: 0.02894s (Â±0.002424s); train time: 22.65s; valid time: 2.223s; loss: -90.8706 (Â±2.28854); valid loss: -91.7007\n",
      "[Epoch 30/100, Step 19890, ETA 29m 36.31s] epoch time: 24.95s; step time: 0.029s (Â±0.002585s); train time: 22.68s; valid time: 2.273s; loss: -90.9582 (Â±2.63062); valid loss: -91.8304\n",
      "[Epoch 31/100, Step 20553, ETA 29m 9.766s] epoch time: 24.85s; step time: 0.02841s (Â±0.002153s); train time: 22.05s; valid time: 2.8s; loss: -91.3526 (Â±2.09416); valid loss: -92.3307\n",
      "[Epoch 32/100, Step 21216, ETA 28m 43.18s] epoch time: 24.78s; step time: 0.02849s (Â±0.002362s); train time: 22.57s; valid time: 2.214s; loss: -90.7942 (Â±3.06568); valid loss: -92.1114\n",
      "[Epoch 33/100, Step 21879, ETA 28m 16.31s] epoch time: 24.59s; step time: 0.02869s (Â±0.002381s); train time: 22.42s; valid time: 2.166s; loss: -91.3317 (Â±2.41886); valid loss: -91.6231\n",
      "[Epoch 34/100, Step 22542, ETA 27m 50.38s] epoch time: 25s; step time: 0.02854s (Â±0.002254s); train time: 22.22s; valid time: 2.781s; loss: -90.6783 (Â±3.08301); valid loss: -89.2665\n",
      "[Epoch 35/100, Step 23205, ETA 27m 22.08s] epoch time: 23.7s; step time: 0.02782s (Â±0.001784s); train time: 21.53s; valid time: 2.169s; loss: -91.3102 (Â±2.16652); valid loss: -91.07\n",
      "[Epoch 36/100, Step 23868, ETA 26m 55.28s] epoch time: 24.4s; step time: 0.02842s (Â±0.002306s); train time: 22.2s; valid time: 2.196s; loss: -91.4895 (Â±2.07538); valid loss: -91.7871\n",
      "[Epoch 37/100, Step 24531, ETA 26m 28.72s] epoch time: 24.47s; step time: 0.02813s (Â±0.002064s); train time: 21.89s; valid time: 2.577s; loss: -91.3753 (Â±2.07364); valid loss: -92.0192\n",
      "[Epoch 38/100, Step 25194, ETA 26m 1.181s] epoch time: 23.79s; step time: 0.02784s (Â±0.001908s); train time: 21.54s; valid time: 2.25s; loss: -91.5475 (Â±1.98302); valid loss: -91.4037\n",
      "[Epoch 39/100, Step 25857, ETA 25m 35.15s] epoch time: 24.63s; step time: 0.02839s (Â±0.002201s); train time: 22.45s; valid time: 2.18s; loss: -90.9593 (Â±2.86653); valid loss: -92.7024\n",
      "[Epoch 40/100, Step 26520, ETA 25m 9.431s] Best valid loss updated: from -93.169787 to -93.925457\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 40/100, Step 26520, ETA 25m 11.11s] epoch time: 25.92s; step time: 0.02887s (Â±0.002363s); train time: 22.57s; valid time: 3.348s; loss: -91.7985 (Â±1.9263); valid loss: -93.9255 (*)\n",
      "[Epoch 40/100, Step 26520, ETA 25m 11.11s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 27183, ETA 24m 45.37s] Best valid loss updated: from -93.925457 to -97.374535\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 41/100, Step 27183, ETA 24m 47.47s] epoch time: 26.26s; step time: 0.02818s (Â±0.002009s); train time: 21.89s; valid time: 4.375s; loss: -96.5247 (Â±1.98678); valid loss: -97.3745 (*)\n",
      "[Epoch 42/100, Step 27846, ETA 24m 20.85s] Best valid loss updated: from -97.374535 to -97.485282\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 42/100, Step 27846, ETA 24m 23.46s] epoch time: 26.08s; step time: 0.0282s (Â±0.002378s); train time: 21.87s; valid time: 4.213s; loss: -97.5187 (Â±1.21035); valid loss: -97.4853 (*)\n",
      "[Epoch 43/100, Step 28509, ETA 23m 57.52s] epoch time: 24.7s; step time: 0.02839s (Â±0.002684s); train time: 22.47s; valid time: 2.227s; loss: -97.7022 (Â±1.68188); valid loss: -97.177\n",
      "[Epoch 44/100, Step 29172, ETA 23m 31.58s] Best valid loss updated: from -97.485282 to -98.065840\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 44/100, Step 29172, ETA 23m 33.03s] epoch time: 25.79s; step time: 0.0287s (Â±0.002503s); train time: 22.47s; valid time: 3.314s; loss: -97.0246 (Â±2.97522); valid loss: -98.0658 (*)\n",
      "[Epoch 45/100, Step 29835, ETA 23m 7.395s] epoch time: 24.9s; step time: 0.02861s (Â±0.002273s); train time: 22.37s; valid time: 2.536s; loss: -98.1041 (Â±1.51636); valid loss: -97.7985\n",
      "[Epoch 46/100, Step 30498, ETA 22m 40.89s] epoch time: 24.14s; step time: 0.02802s (Â±0.002057s); train time: 21.74s; valid time: 2.397s; loss: -98.1866 (Â±1.453); valid loss: -97.598\n",
      "[Epoch 47/100, Step 31161, ETA 22m 15.21s] Best valid loss updated: from -98.065840 to -100.405928\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 47/100, Step 31161, ETA 22m 16.62s] epoch time: 26.03s; step time: 0.02845s (Â±0.002192s); train time: 22.57s; valid time: 3.453s; loss: -98.5086 (Â±1.18017); valid loss: -100.406 (*)\n",
      "[Epoch 48/100, Step 31824, ETA 21m 50.74s] epoch time: 24.61s; step time: 0.02866s (Â±0.002319s); train time: 22.42s; valid time: 2.189s; loss: -97.4156 (Â±2.77114); valid loss: -98.6815\n",
      "[Epoch 49/100, Step 32487, ETA 21m 25.3s] epoch time: 24.98s; step time: 0.0283s (Â±0.002141s); train time: 22.03s; valid time: 2.943s; loss: -96.5007 (Â±4.22098); valid loss: -96.4841\n",
      "[Epoch 50/100, Step 33150, ETA 20m 58.89s] epoch time: 24s; step time: 0.02808s (Â±0.002044s); train time: 21.82s; valid time: 2.175s; loss: -98.1043 (Â±1.71619); valid loss: -98.8603\n",
      "[Epoch 51/100, Step 33813, ETA 20m 33.28s] epoch time: 24.72s; step time: 0.02884s (Â±0.002617s); train time: 22.55s; valid time: 2.173s; loss: -98.306 (Â±1.76708); valid loss: -98.9138\n",
      "[Epoch 52/100, Step 34476, ETA 20m 7.762s] epoch time: 24.79s; step time: 0.02864s (Â±0.002449s); train time: 22.34s; valid time: 2.452s; loss: -98.0974 (Â±1.66512); valid loss: -98.7925\n",
      "[Epoch 53/100, Step 35139, ETA 19m 41.78s] epoch time: 24.24s; step time: 0.02801s (Â±0.001828s); train time: 21.74s; valid time: 2.494s; loss: -98.2687 (Â±2.00911); valid loss: -98.4762\n",
      "[Epoch 54/100, Step 35802, ETA 19m 16.29s] epoch time: 24.74s; step time: 0.02848s (Â±0.002334s); train time: 22.56s; valid time: 2.178s; loss: -98.1724 (Â±2.27841); valid loss: -92.1939\n",
      "[Epoch 55/100, Step 36465, ETA 18m 50.71s] epoch time: 24.6s; step time: 0.02868s (Â±0.002301s); train time: 22.43s; valid time: 2.169s; loss: -96.8799 (Â±4.02745); valid loss: -89.3203\n",
      "[Epoch 56/100, Step 37128, ETA 18m 25.26s] epoch time: 24.71s; step time: 0.02809s (Â±0.002014s); train time: 21.83s; valid time: 2.876s; loss: -97.9603 (Â±2.54543); valid loss: -97.6894\n",
      "[Epoch 57/100, Step 37791, ETA 17m 59.69s] epoch time: 24.53s; step time: 0.02825s (Â±0.002176s); train time: 22.29s; valid time: 2.239s; loss: -98.0925 (Â±2.5279); valid loss: -99.0933\n",
      "[Epoch 58/100, Step 38454, ETA 17m 34.37s] epoch time: 24.82s; step time: 0.02884s (Â±0.002296s); train time: 22.63s; valid time: 2.188s; loss: -97.7469 (Â±3.39026); valid loss: -98.2619\n",
      "[Epoch 59/100, Step 39117, ETA 17m 9.046s] epoch time: 24.78s; step time: 0.02852s (Â±0.002318s); train time: 22.23s; valid time: 2.557s; loss: -98.1565 (Â±2.69955); valid loss: -97.7632\n",
      "[Epoch 60/100, Step 39780, ETA 16m 43.35s] epoch time: 24.2s; step time: 0.02803s (Â±0.001859s); train time: 21.77s; valid time: 2.429s; loss: -98.1991 (Â±2.65778); valid loss: -99.4316\n",
      "[Epoch 60/100, Step 39780, ETA 16m 43.35s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 40443, ETA 16m 17.99s] Best valid loss updated: from -100.405928 to -102.058706\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 61/100, Step 40443, ETA 16m 18.75s] epoch time: 25.84s; step time: 0.02835s (Â±0.00222s); train time: 22.46s; valid time: 3.376s; loss: -101.772 (Â±1.28784); valid loss: -102.059 (*)\n",
      "[Epoch 62/100, Step 41106, ETA 15m 53.32s] Best valid loss updated: from -102.058706 to -102.468590\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 62/100, Step 41106, ETA 15m 54.08s] epoch time: 25.79s; step time: 0.02867s (Â±0.002358s); train time: 22.38s; valid time: 3.406s; loss: -102.336 (Â±1.1523); valid loss: -102.469 (*)\n",
      "[Epoch 63/100, Step 41769, ETA 15m 28.72s] Best valid loss updated: from -102.468590 to -102.638783\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 63/100, Step 41769, ETA 15m 29.5s] epoch time: 26.01s; step time: 0.02835s (Â±0.002161s); train time: 22.07s; valid time: 3.943s; loss: -102.277 (Â±1.41087); valid loss: -102.639 (*)\n",
      "[Epoch 64/100, Step 42432, ETA 15m 3.935s] Best valid loss updated: from -102.638783 to -102.804901\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 64/100, Step 42432, ETA 15m 5.104s] epoch time: 26.41s; step time: 0.02793s (Â±0.001879s); train time: 21.63s; valid time: 4.777s; loss: -102.625 (Â±1.01168); valid loss: -102.805 (*)\n",
      "[Epoch 65/100, Step 43095, ETA 14m 39.34s] epoch time: 23.99s; step time: 0.02804s (Â±0.00239s); train time: 21.8s; valid time: 2.185s; loss: -102.64 (Â±1.13054); valid loss: -101.351\n",
      "[Epoch 66/100, Step 43758, ETA 14m 13.86s] epoch time: 24.43s; step time: 0.02851s (Â±0.002344s); train time: 22.24s; valid time: 2.188s; loss: -102.689 (Â±1.28193); valid loss: -102.346\n",
      "[Epoch 67/100, Step 44421, ETA 13m 48.5s] epoch time: 24.61s; step time: 0.02844s (Â±0.002276s); train time: 22.18s; valid time: 2.421s; loss: -102.846 (Â±1.10712); valid loss: -102.507\n",
      "[Epoch 68/100, Step 45084, ETA 13m 22.94s] Best valid loss updated: from -102.804901 to -103.026552\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 68/100, Step 45084, ETA 13m 23.98s] epoch time: 26.35s; step time: 0.02798s (Â±0.002125s); train time: 21.69s; valid time: 4.662s; loss: -102.89 (Â±1.11497); valid loss: -103.027 (*)\n",
      "[Epoch 69/100, Step 45747, ETA 12m 58.5s] epoch time: 24.35s; step time: 0.02812s (Â±0.002791s); train time: 22.15s; valid time: 2.204s; loss: -102.889 (Â±1.37199); valid loss: -98.7481\n",
      "[Epoch 70/100, Step 46410, ETA 12m 33.12s] Best valid loss updated: from -103.026552 to -103.146302\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 70/100, Step 46410, ETA 12m 33.68s] epoch time: 25.78s; step time: 0.02856s (Â±0.002216s); train time: 22.32s; valid time: 3.457s; loss: -102.887 (Â±1.31724); valid loss: -103.146 (*)\n",
      "[Epoch 71/100, Step 47073, ETA 12m 8.287s] epoch time: 24.47s; step time: 0.02842s (Â±0.00227s); train time: 22.19s; valid time: 2.277s; loss: -103.125 (Â±1.08207); valid loss: -102.355\n",
      "[Epoch 72/100, Step 47736, ETA 11m 42.85s] epoch time: 24.29s; step time: 0.02801s (Â±0.001992s); train time: 21.68s; valid time: 2.605s; loss: -102.988 (Â±1.26361); valid loss: -103.074\n",
      "[Epoch 73/100, Step 48399, ETA 11m 17.42s] epoch time: 24.22s; step time: 0.02798s (Â±0.001982s); train time: 22.06s; valid time: 2.163s; loss: -102.986 (Â±1.44717); valid loss: -102.75\n",
      "[Epoch 74/100, Step 49062, ETA 10m 52.01s] epoch time: 24.16s; step time: 0.02825s (Â±0.0022s); train time: 21.98s; valid time: 2.177s; loss: -103.105 (Â±1.17893); valid loss: -102.11\n",
      "[Epoch 75/100, Step 49725, ETA 10m 26.74s] Best valid loss updated: from -103.146302 to -103.155312\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 75/100, Step 49725, ETA 10m 27.37s] epoch time: 26.39s; step time: 0.02794s (Â±0.001936s); train time: 21.64s; valid time: 4.75s; loss: -103.062 (Â±1.22203); valid loss: -103.155 (*)\n",
      "[Epoch 76/100, Step 50388, ETA 10m 1.951s] Best valid loss updated: from -103.155312 to -103.564528\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 76/100, Step 50388, ETA 10m 2.692s] epoch time: 26.42s; step time: 0.02815s (Â±0.002507s); train time: 21.84s; valid time: 4.574s; loss: -103.179 (Â±1.19295); valid loss: -103.565 (*)\n",
      "[Epoch 77/100, Step 51051, ETA 9m 37.38s] epoch time: 24.43s; step time: 0.02817s (Â±0.002577s); train time: 22.25s; valid time: 2.188s; loss: -103.127 (Â±1.37972); valid loss: -102.8\n",
      "[Epoch 78/100, Step 51714, ETA 9m 12.1s] epoch time: 24.48s; step time: 0.02856s (Â±0.002246s); train time: 22.3s; valid time: 2.18s; loss: -103.162 (Â±1.2926); valid loss: -102.14\n",
      "[Epoch 79/100, Step 52377, ETA 8m 46.91s] epoch time: 24.73s; step time: 0.02827s (Â±0.002104s); train time: 22s; valid time: 2.735s; loss: -103.173 (Â±1.1634); valid loss: -102.396\n",
      "[Epoch 80/100, Step 53040, ETA 8m 21.52s] Best valid loss updated: from -103.564528 to -104.104391\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 80/100, Step 53040, ETA 8m 22.08s] epoch time: 26.15s; step time: 0.02801s (Â±0.002093s); train time: 21.72s; valid time: 4.426s; loss: -103.299 (Â±1.19578); valid loss: -104.104 (*)\n",
      "[Epoch 80/100, Step 53040, ETA 8m 22.08s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 53703, ETA 7m 56.84s] Best valid loss updated: from -104.104391 to -104.481267\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 81/100, Step 53703, ETA 7m 57.2s] epoch time: 26.05s; step time: 0.02833s (Â±0.002927s); train time: 22.36s; valid time: 3.687s; loss: -104.765 (Â±1.0885); valid loss: -104.481 (*)\n",
      "[Epoch 82/100, Step 54366, ETA 7m 31.97s] Best valid loss updated: from -104.481267 to -104.742788\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 82/100, Step 54366, ETA 7m 32.31s] epoch time: 26.17s; step time: 0.0287s (Â±0.002732s); train time: 22.44s; valid time: 3.725s; loss: -104.959 (Â±1.04279); valid loss: -104.743 (*)\n",
      "[Epoch 83/100, Step 55029, ETA 7m 7.099s] epoch time: 24.7s; step time: 0.02886s (Â±0.002904s); train time: 22.5s; valid time: 2.196s; loss: -105.022 (Â±1.06554); valid loss: -104.616\n",
      "[Epoch 84/100, Step 55692, ETA 6m 41.88s] Best valid loss updated: from -104.742788 to -104.781880\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 84/100, Step 55692, ETA 6m 42.23s] epoch time: 26.46s; step time: 0.02807s (Â±0.002081s); train time: 21.76s; valid time: 4.699s; loss: -105.035 (Â±1.15857); valid loss: -104.782 (*)\n",
      "[Epoch 85/100, Step 56355, ETA 6m 16.92s] epoch time: 24.17s; step time: 0.02814s (Â±0.002663s); train time: 21.8s; valid time: 2.367s; loss: -105.098 (Â±1.07027); valid loss: -104.752\n",
      "[Epoch 86/100, Step 57018, ETA 5m 51.73s] Best valid loss updated: from -104.781880 to -104.906681\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 86/100, Step 57018, ETA 5m 51.99s] epoch time: 26.33s; step time: 0.02846s (Â±0.00239s); train time: 22.55s; valid time: 3.777s; loss: -105.09 (Â±1.10282); valid loss: -104.907 (*)\n",
      "[Epoch 87/100, Step 57681, ETA 5m 26.77s] Best valid loss updated: from -104.906681 to -105.034947\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 87/100, Step 57681, ETA 5m 27.03s] epoch time: 26.36s; step time: 0.02875s (Â±0.002764s); train time: 22.46s; valid time: 3.9s; loss: -105.129 (Â±1.15802); valid loss: -105.035 (*)\n",
      "[Epoch 88/100, Step 58344, ETA 5m 1.809s] epoch time: 24.69s; step time: 0.02877s (Â±0.002605s); train time: 22.52s; valid time: 2.171s; loss: -105.167 (Â±1.10021); valid loss: -104.728\n",
      "[Epoch 89/100, Step 59007, ETA 4m 36.57s] epoch time: 24.48s; step time: 0.02798s (Â±0.002031s); train time: 21.71s; valid time: 2.768s; loss: -105.24 (Â±1.11192); valid loss: -104.681\n",
      "[Epoch 90/100, Step 59670, ETA 4m 11.35s] epoch time: 24.42s; step time: 0.02815s (Â±0.002159s); train time: 22.24s; valid time: 2.184s; loss: -105.227 (Â±1.17891); valid loss: -104.931\n",
      "[Epoch 91/100, Step 60333, ETA 3m 46.16s] Best valid loss updated: from -105.034947 to -105.185699\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 91/100, Step 60333, ETA 3m 46.32s] epoch time: 26.22s; step time: 0.02857s (Â±0.002145s); train time: 22.36s; valid time: 3.859s; loss: -105.199 (Â±1.14397); valid loss: -105.186 (*)\n",
      "[Epoch 92/100, Step 60996, ETA 3m 21.14s] epoch time: 24.77s; step time: 0.02871s (Â±0.002918s); train time: 22.42s; valid time: 2.354s; loss: -105.278 (Â±1.10914); valid loss: -104.787\n",
      "[Epoch 93/100, Step 61659, ETA 2m 55.94s] Best valid loss updated: from -105.185699 to -105.278106\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 93/100, Step 61659, ETA 2m 56.12s] epoch time: 26.7s; step time: 0.028s (Â±0.002036s); train time: 21.73s; valid time: 4.967s; loss: -105.309 (Â±1.1283); valid loss: -105.278 (*)\n",
      "[Epoch 94/100, Step 62322, ETA 2m 30.89s] epoch time: 24.14s; step time: 0.02817s (Â±0.002499s); train time: 21.97s; valid time: 2.173s; loss: -105.298 (Â±1.05701); valid loss: -105.194\n",
      "[Epoch 95/100, Step 62985, ETA 2m 5.724s] Best valid loss updated: from -105.278106 to -105.338716\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 95/100, Step 62985, ETA 2m 5.818s] epoch time: 26.53s; step time: 0.02882s (Â±0.002453s); train time: 22.55s; valid time: 3.98s; loss: -105.317 (Â±1.16483); valid loss: -105.339 (*)\n",
      "[Epoch 96/100, Step 63648, ETA 1m 40.64s] epoch time: 24.92s; step time: 0.02901s (Â±0.002972s); train time: 22.7s; valid time: 2.223s; loss: -105.298 (Â±1.1449); valid loss: -105.338\n",
      "[Epoch 97/100, Step 64311, ETA 1m 15.48s] epoch time: 24.97s; step time: 0.02827s (Â±0.002121s); train time: 22s; valid time: 2.962s; loss: -105.291 (Â±1.10885); valid loss: -104.762\n",
      "[Epoch 98/100, Step 64974, ETA 50.3s] epoch time: 24.18s; step time: 0.02803s (Â±0.001972s); train time: 21.96s; valid time: 2.22s; loss: -105.413 (Â±1.022); valid loss: -105.308\n",
      "[Epoch 99/100, Step 65637, ETA 25.14s] Best valid loss updated: from -105.338716 to -105.402459\n",
      "Model saved at results/tuned_model_st8000_2_exp2a_2023-12-10_17-50-38.\n",
      "[Epoch 99/100, Step 65637, ETA 25.16s] epoch time: 26.71s; step time: 0.02878s (Â±0.002508s); train time: 22.53s; valid time: 4.178s; loss: -105.414 (Â±1.07965); valid loss: -105.402 (*)\n",
      "[Epoch 100/100, Step 66300, ETA 0s] epoch time: 24.74s; step time: 0.02884s (Â±0.002712s); train time: 22.55s; valid time: 2.193s; loss: -105.339 (Â±1.14012); valid loss: -104.586\n",
      "[Epoch 100/100, Step 66300, ETA 0s] Learning rate decreased to 1.5625e-06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4hp65iib/variables.dat-65637\n",
      "2023-12-10 18:32:47,942 [INFO] tensorflow: Restoring parameters from /tmp/tmp4hp65iib/variables.dat-65637\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'best_valid_loss': -105.40245929482944,\n",
      " 'pred_time': 0.032197619203757785,\n",
      " 'pred_total_time': 107.2877995967865,\n",
      " 'train_time': 25.165686757564544,\n",
      " 'valid_time': 0.010515471208526427}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpm23h0528wandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpfjed2focwandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpeqrrsi4zwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpauqklhlhwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 3 (full target domain data)"
   ],
   "metadata": {
    "id": "BsqH8jdM_Mks"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --restore_dir=results/tuned_model_st8000_2 --dataset_folder=/content/processed_st12000 --save_dir=/content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3 --initial_lr=0.00005"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_WYdWvtBVp1",
    "outputId": "df03989e-9eb2-4781-fcee-0e21bcd1c81d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/csc2233-2023/omni_anomaly/vae.py:378: DeprecationWarning: invalid escape sequence \\*\n",
      "  \"\"\"\n",
      "/content/csc2233-2023/omni_anomaly/vae.py:419: DeprecationWarning: invalid escape sequence \\*\n",
      "  \"\"\"\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "========================================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': 'results/tuned_model_st8000_2',\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': '/content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': None,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (5095382, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-11 14:50:26,769 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-11 14:50:31.139028: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2023-12-11 14:50:31.291672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-11 14:50:31.291936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-11 14:50:31.291971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-11 14:50:31.585376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-11 14:50:31.585430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-11 14:50:31.585441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-11 14:50:31.585523: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-11 14:50:31.585567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "2023-12-11 14:50:31,653 [INFO] tensorflow: Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "Variables restored from results/tuned_model_st8000_2.\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (4076306, 16)\n",
      "[Epoch 1/100, Step 7961] Best valid loss updated: from inf to -81.728712\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 1/100, Step 7961, ETA 1d 1h 38m 9.85s] epoch time: 15m 32.22s; step time: 0.1013s (Â±0.1008s); train time: 14m 14.83s; valid time: 1m 17.39s; loss: -67.6216 (Â±262.198); valid loss: -81.7287 (*)\n",
      "[Epoch 2/100, Step 15922, ETA 1d 1h 17m 51.33s] Best valid loss updated: from -81.728712 to -83.275704\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 2/100, Step 15922, ETA 1d 1h 18m 36.98s] epoch time: 15m 27.31s; step time: 0.1008s (Â±0.001904s); train time: 14m 11.76s; valid time: 1m 15.55s; loss: -82.0204 (Â±2.81545); valid loss: -83.2757 (*)\n",
      "[Epoch 3/100, Step 23883, ETA 1d 1h 1m 35.35s] Best valid loss updated: from -83.275704 to -84.439477\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 3/100, Step 23883, ETA 1d 1h 2m 16.43s] epoch time: 15m 28.19s; step time: 0.1008s (Â±0.001861s); train time: 14m 11.79s; valid time: 1m 16.4s; loss: -84.1102 (Â±2.7112); valid loss: -84.4395 (*)\n",
      "[Epoch 4/100, Step 31844, ETA 1d 47m 0.8011s] Best valid loss updated: from -84.439477 to -87.005170\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 4/100, Step 31844, ETA 1d 47m 38.45s] epoch time: 15m 31.38s; step time: 0.1008s (Â±0.001889s); train time: 14m 14.6s; valid time: 1m 16.78s; loss: -85.5134 (Â±2.57078); valid loss: -87.0052 (*)\n",
      "[Epoch 5/100, Step 39805, ETA 1d 31m 6.701s] epoch time: 15m 26.51s; step time: 0.1007s (Â±0.00188s); train time: 14m 11.44s; valid time: 1m 15.08s; loss: -86.42 (Â±2.58111); valid loss: -78.8013\n",
      "[Epoch 6/100, Step 47766, ETA 1d 14m 51.94s] epoch time: 15m 26.21s; step time: 0.1008s (Â±0.001869s); train time: 14m 11.24s; valid time: 1m 14.97s; loss: -87.0978 (Â±2.43255); valid loss: -84.2724\n",
      "[Epoch 7/100, Step 55727, ETA 23h 58m 52.05s] Best valid loss updated: from -87.005170 to -88.564039\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 7/100, Step 55727, ETA 23h 59m 5.367s] epoch time: 15m 27.29s; step time: 0.1008s (Â±0.001885s); train time: 14m 11.34s; valid time: 1m 15.95s; loss: -87.5141 (Â±2.5646); valid loss: -88.564 (*)\n",
      "[Epoch 8/100, Step 63688, ETA 23h 43m 21.66s] Best valid loss updated: from -88.564039 to -89.359635\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 8/100, Step 63688, ETA 23h 43m 33.05s] epoch time: 15m 28.11s; step time: 0.1008s (Â±0.001921s); train time: 14m 12.47s; valid time: 1m 15.63s; loss: -88.1274 (Â±2.46345); valid loss: -89.3596 (*)\n",
      "[Epoch 9/100, Step 71649, ETA 23h 28m 21.52s] Best valid loss updated: from -89.359635 to -89.683985\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 9/100, Step 71649, ETA 23h 28m 38.33s] epoch time: 15m 31.73s; step time: 0.1007s (Â±0.001927s); train time: 14m 14.79s; valid time: 1m 16.94s; loss: -88.6457 (Â±2.48201); valid loss: -89.684 (*)\n",
      "[Epoch 10/100, Step 79610, ETA 23h 13m 1.456s] epoch time: 15m 27.87s; step time: 0.1008s (Â±0.001872s); train time: 14m 12.89s; valid time: 1m 14.98s; loss: -89.0911 (Â±2.42601); valid loss: -87.4506\n",
      "[Epoch 11/100, Step 87571, ETA 22h 57m 2.438s] Best valid loss updated: from -89.683985 to -91.194456\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 11/100, Step 87571, ETA 22h 57m 14.54s] epoch time: 15m 26.43s; step time: 0.1008s (Â±0.001842s); train time: 14m 10.63s; valid time: 1m 15.8s; loss: -89.5161 (Â±2.31766); valid loss: -91.1945 (*)\n",
      "[Epoch 12/100, Step 95532, ETA 22h 41m 54.78s] Best valid loss updated: from -91.194456 to -91.819051\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 12/100, Step 95532, ETA 22h 42m 2.786s] epoch time: 15m 30.76s; step time: 0.1009s (Â±0.001917s); train time: 14m 14.6s; valid time: 1m 16.16s; loss: -90.0656 (Â±2.45227); valid loss: -91.8191 (*)\n",
      "[Epoch 13/100, Step 103493, ETA 22h 26m 39.12s] Best valid loss updated: from -91.819051 to -92.631894\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 13/100, Step 103493, ETA 22h 26m 46.36s] epoch time: 15m 30.5s; step time: 0.1008s (Â±0.001918s); train time: 14m 13.82s; valid time: 1m 16.67s; loss: -90.5552 (Â±2.37955); valid loss: -92.6319 (*)\n",
      "[Epoch 14/100, Step 111454, ETA 22h 11m 5.407s] epoch time: 15m 26.83s; step time: 0.101s (Â±0.001863s); train time: 14m 11.86s; valid time: 1m 14.97s; loss: -91.1222 (Â±2.29741); valid loss: -91.7972\n",
      "[Epoch 15/100, Step 119415, ETA 21h 55m 42.15s] epoch time: 15m 29.62s; step time: 0.101s (Â±0.001848s); train time: 14m 13.89s; valid time: 1m 15.74s; loss: -91.2505 (Â±2.36947); valid loss: -91.89\n",
      "[Epoch 16/100, Step 127376, ETA 21h 40m 15.43s] Best valid loss updated: from -92.631894 to -93.842932\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 16/100, Step 127376, ETA 21h 40m 21.54s] epoch time: 15m 30.28s; step time: 0.101s (Â±0.001832s); train time: 14m 13.72s; valid time: 1m 16.56s; loss: -91.8241 (Â±2.24385); valid loss: -93.8429 (*)\n",
      "[Epoch 17/100, Step 135337, ETA 21h 24m 55.28s] Best valid loss updated: from -93.842932 to -94.800898\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 17/100, Step 135337, ETA 21h 25m 1.136s] epoch time: 15m 30.55s; step time: 0.1011s (Â±0.001865s); train time: 14m 13.88s; valid time: 1m 16.67s; loss: -91.9956 (Â±2.41447); valid loss: -94.8009 (*)\n",
      "[Epoch 18/100, Step 143298, ETA 21h 9m 32.29s] epoch time: 15m 28.95s; step time: 0.1011s (Â±0.001917s); train time: 14m 13.32s; valid time: 1m 15.62s; loss: -92.0724 (Â±2.40923); valid loss: -92.2504\n",
      "[Epoch 19/100, Step 151259, ETA 20h 54m 8.993s] epoch time: 15m 30.25s; step time: 0.101s (Â±0.0019s); train time: 14m 14.72s; valid time: 1m 15.54s; loss: -92.6482 (Â±2.30811); valid loss: -91.0412\n",
      "[Epoch 20/100, Step 159220, ETA 20h 38m 32.25s] epoch time: 15m 27.06s; step time: 0.101s (Â±0.001872s); train time: 14m 12.24s; valid time: 1m 14.82s; loss: -93.2279 (Â±2.21956); valid loss: -92.3016\n",
      "[Epoch 20/100, Step 159220, ETA 20h 38m 32.25s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 167181, ETA 20h 23m 6.432s] Best valid loss updated: from -94.800898 to -100.866348\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 21/100, Step 167181, ETA 20h 23m 10.85s] epoch time: 15m 30.9s; step time: 0.101s (Â±0.001944s); train time: 14m 14.89s; valid time: 1m 16s; loss: -100.389 (Â±1.93518); valid loss: -100.866 (*)\n",
      "[Epoch 22/100, Step 175142, ETA 20h 7m 39.01s] Best valid loss updated: from -100.866348 to -102.496782\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 22/100, Step 175142, ETA 20h 7m 44.71s] epoch time: 15m 29.8s; step time: 0.101s (Â±0.001853s); train time: 14m 13.12s; valid time: 1m 16.68s; loss: -100.963 (Â±2.01662); valid loss: -102.497 (*)\n",
      "[Epoch 23/100, Step 183103, ETA 19h 52m 7.437s] epoch time: 15m 26.57s; step time: 0.1009s (Â±0.001899s); train time: 14m 11.79s; valid time: 1m 14.79s; loss: -100.895 (Â±2.60024); valid loss: -101.492\n",
      "[Epoch 24/100, Step 191064, ETA 19h 36m 44.09s] epoch time: 15m 30.69s; step time: 0.101s (Â±0.00184s); train time: 14m 15.64s; valid time: 1m 15.05s; loss: -100.974 (Â±2.14748); valid loss: -101.46\n",
      "[Epoch 25/100, Step 199025, ETA 19h 21m 9.52s] epoch time: 15m 27.14s; step time: 0.101s (Â±0.001868s); train time: 14m 12.28s; valid time: 1m 14.87s; loss: -100.987 (Â±2.32339); valid loss: -100.197\n",
      "[Epoch 26/100, Step 206986, ETA 19h 5m 34.36s] Best valid loss updated: from -102.496782 to -102.731751\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 26/100, Step 206986, ETA 19h 5m 37.73s] epoch time: 15m 27.92s; step time: 0.1008s (Â±0.001818s); train time: 14m 12.3s; valid time: 1m 15.62s; loss: -101.149 (Â±2.02472); valid loss: -102.732 (*)\n",
      "[Epoch 27/100, Step 214947, ETA 18h 49m 54.14s] epoch time: 15m 23.45s; step time: 0.1008s (Â±0.001844s); train time: 14m 9.101s; valid time: 1m 14.35s; loss: -100.943 (Â±2.49599); valid loss: -100.781\n",
      "[Epoch 28/100, Step 222908, ETA 18h 34m 15.65s] epoch time: 15m 24.88s; step time: 0.1009s (Â±0.001854s); train time: 14m 10.19s; valid time: 1m 14.68s; loss: -101.005 (Â±2.81617); valid loss: -100.624\n",
      "[Epoch 29/100, Step 230869, ETA 18h 18m 45.55s] epoch time: 15m 27.92s; step time: 0.1008s (Â±0.001841s); train time: 14m 12.99s; valid time: 1m 14.92s; loss: -101.096 (Â±2.22012); valid loss: -102.17\n",
      "[Epoch 30/100, Step 238830, ETA 18h 3m 10.29s] epoch time: 15m 25.65s; step time: 0.1009s (Â±0.001821s); train time: 14m 10.86s; valid time: 1m 14.79s; loss: -101.1 (Â±2.12654); valid loss: -101.015\n",
      "[Epoch 31/100, Step 246791, ETA 17h 47m 33.52s] epoch time: 15m 24.68s; step time: 0.1008s (Â±0.001847s); train time: 14m 10.03s; valid time: 1m 14.65s; loss: -100.854 (Â±2.49285); valid loss: -101.862\n",
      "[Epoch 32/100, Step 254752, ETA 17h 32m 2.229s] epoch time: 15m 26.91s; step time: 0.1009s (Â±0.001861s); train time: 14m 12.61s; valid time: 1m 14.31s; loss: -101.016 (Â±2.23845); valid loss: -96.9661\n",
      "[Epoch 33/100, Step 262713, ETA 17h 16m 24.04s] epoch time: 15m 23.38s; step time: 0.1008s (Â±0.001831s); train time: 14m 9.233s; valid time: 1m 14.15s; loss: -101.039 (Â±2.23212); valid loss: -98.7836\n",
      "[Epoch 34/100, Step 270674, ETA 17h 44.73s] epoch time: 15m 22.36s; step time: 0.1007s (Â±0.001792s); train time: 14m 8.24s; valid time: 1m 14.12s; loss: -101.15 (Â±2.62242); valid loss: -100.98\n",
      "[Epoch 35/100, Step 278635, ETA 16h 45m 5.983s] epoch time: 15m 22.14s; step time: 0.1007s (Â±0.001833s); train time: 14m 7.593s; valid time: 1m 14.54s; loss: -101.276 (Â±1.97605); valid loss: -101.452\n",
      "[Epoch 36/100, Step 286596, ETA 16h 29m 32.47s] epoch time: 15m 24.56s; step time: 0.1007s (Â±0.001861s); train time: 14m 10.59s; valid time: 1m 13.97s; loss: -101.327 (Â±2.2618); valid loss: -96.8546\n",
      "[Epoch 37/100, Step 294557, ETA 16h 13m 58.05s] epoch time: 15m 23.75s; step time: 0.1008s (Â±0.001866s); train time: 14m 9.781s; valid time: 1m 13.96s; loss: -101.317 (Â±2.1863); valid loss: -101.263\n",
      "[Epoch 38/100, Step 302518, ETA 15h 58m 21.15s] epoch time: 15m 21.88s; step time: 0.1007s (Â±0.001842s); train time: 14m 7.75s; valid time: 1m 14.13s; loss: -101.219 (Â±2.79018); valid loss: -94.2123\n",
      "[Epoch 39/100, Step 310479, ETA 15h 42m 49.65s] epoch time: 15m 24.84s; step time: 0.1007s (Â±0.001819s); train time: 14m 10.49s; valid time: 1m 14.35s; loss: -101.29 (Â±2.38987); valid loss: -100.531\n",
      "[Epoch 40/100, Step 318440, ETA 15h 27m 23.42s] epoch time: 15m 28.13s; step time: 0.1009s (Â±0.001856s); train time: 14m 13.46s; valid time: 1m 14.67s; loss: -101.481 (Â±1.93244); valid loss: -99.4504\n",
      "[Epoch 40/100, Step 318440, ETA 15h 27m 23.42s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 326401, ETA 15h 11m 50.81s] Best valid loss updated: from -102.731751 to -107.169622\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 41/100, Step 326401, ETA 15h 11m 53.65s] epoch time: 15m 25.74s; step time: 0.1008s (Â±0.001835s); train time: 14m 9.397s; valid time: 1m 16.34s; loss: -107.737 (Â±1.36208); valid loss: -107.17 (*)\n",
      "[Epoch 42/100, Step 334362, ETA 14h 56m 22.24s] epoch time: 15m 24.41s; step time: 0.1009s (Â±0.001898s); train time: 14m 10.42s; valid time: 1m 13.99s; loss: -108.292 (Â±1.04826); valid loss: -105.378\n",
      "[Epoch 43/100, Step 342323, ETA 14h 40m 53.47s] Best valid loss updated: from -107.169622 to -107.682792\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 43/100, Step 342323, ETA 14h 40m 55.12s] epoch time: 15m 27.4s; step time: 0.1009s (Â±0.001914s); train time: 14m 11.69s; valid time: 1m 15.71s; loss: -108.487 (Â±1.33399); valid loss: -107.683 (*)\n",
      "[Epoch 44/100, Step 350284, ETA 14h 25m 20.93s] epoch time: 15m 21.86s; step time: 0.1007s (Â±0.001877s); train time: 14m 8.04s; valid time: 1m 13.82s; loss: -108.429 (Â±1.63022); valid loss: -106.698\n",
      "[Epoch 45/100, Step 358245, ETA 14h 9m 52.4s] epoch time: 15m 26.04s; step time: 0.1008s (Â±0.001897s); train time: 14m 11.72s; valid time: 1m 14.32s; loss: -108.663 (Â±1.26632); valid loss: -107.05\n",
      "[Epoch 46/100, Step 366206, ETA 13h 54m 24.35s] epoch time: 15m 26.35s; step time: 0.1009s (Â±0.001819s); train time: 14m 11.91s; valid time: 1m 14.44s; loss: -108.675 (Â±1.1108); valid loss: -106.578\n",
      "[Epoch 47/100, Step 374167, ETA 13h 38m 54.69s] Best valid loss updated: from -107.682792 to -108.469614\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 47/100, Step 374167, ETA 13h 38m 56.08s] epoch time: 15m 26.09s; step time: 0.1009s (Â±0.001835s); train time: 14m 10.63s; valid time: 1m 15.46s; loss: -108.651 (Â±1.20887); valid loss: -108.47 (*)\n",
      "[Epoch 48/100, Step 382128, ETA 13h 23m 24.55s] epoch time: 15m 23s; step time: 0.1007s (Â±0.001852s); train time: 14m 8.633s; valid time: 1m 14.37s; loss: -108.507 (Â±2.00744); valid loss: -108.133\n",
      "[Epoch 49/100, Step 390089, ETA 13h 7m 54.1s] epoch time: 15m 23.71s; step time: 0.1007s (Â±0.001852s); train time: 14m 9.016s; valid time: 1m 14.7s; loss: -108.701 (Â±1.49478); valid loss: -107.024\n",
      "[Epoch 50/100, Step 398050, ETA 12h 52m 23.85s] epoch time: 15m 23.63s; step time: 0.1008s (Â±0.001872s); train time: 14m 9.41s; valid time: 1m 14.22s; loss: -108.711 (Â±1.22418); valid loss: -108.345\n",
      "[Epoch 51/100, Step 406011, ETA 12h 36m 54.3s] epoch time: 15m 24.09s; step time: 0.1008s (Â±0.001873s); train time: 14m 9.901s; valid time: 1m 14.19s; loss: -108.788 (Â±1.32108); valid loss: -107.608\n",
      "[Epoch 52/100, Step 413972, ETA 12h 21m 24.25s] epoch time: 15m 23.33s; step time: 0.1008s (Â±0.001905s); train time: 14m 8.559s; valid time: 1m 14.77s; loss: -108.697 (Â±1.82972); valid loss: -107.781\n",
      "[Epoch 53/100, Step 421933, ETA 12h 5m 54.8s] epoch time: 15m 23.71s; step time: 0.1008s (Â±0.001807s); train time: 14m 9.469s; valid time: 1m 14.25s; loss: -108.723 (Â±2.18754); valid loss: -108.269\n",
      "[Epoch 54/100, Step 429894, ETA 11h 50m 26.07s] epoch time: 15m 24.32s; step time: 0.1008s (Â±0.001829s); train time: 14m 9.924s; valid time: 1m 14.4s; loss: -108.775 (Â±1.59575); valid loss: -107.064\n",
      "[Epoch 55/100, Step 437855, ETA 11h 34m 59.03s] epoch time: 15m 26.17s; step time: 0.1008s (Â±0.001847s); train time: 14m 12.05s; valid time: 1m 14.12s; loss: -108.907 (Â±1.54422); valid loss: -107.147\n",
      "[Epoch 56/100, Step 445816, ETA 11h 19m 31.89s] epoch time: 15m 26.01s; step time: 0.1008s (Â±0.001919s); train time: 14m 11.74s; valid time: 1m 14.27s; loss: -108.889 (Â±1.70376); valid loss: -108.293\n",
      "[Epoch 57/100, Step 453777, ETA 11h 4m 2.601s] epoch time: 15m 23.12s; step time: 0.1008s (Â±0.001887s); train time: 14m 8.897s; valid time: 1m 14.22s; loss: -108.915 (Â±1.47659); valid loss: -105.769\n",
      "[Epoch 58/100, Step 461738, ETA 10h 48m 33.99s] epoch time: 15m 23.76s; step time: 0.1008s (Â±0.001875s); train time: 14m 9.555s; valid time: 1m 14.21s; loss: -108.735 (Â±1.94989); valid loss: -107.962\n",
      "[Epoch 59/100, Step 469699, ETA 10h 33m 5.643s] epoch time: 15m 23.89s; step time: 0.1009s (Â±0.001846s); train time: 14m 9.565s; valid time: 1m 14.33s; loss: -108.971 (Â±1.67543); valid loss: -107.835\n",
      "[Epoch 60/100, Step 477660, ETA 10h 17m 38.83s] epoch time: 15m 25.97s; step time: 0.1008s (Â±0.001846s); train time: 14m 11.76s; valid time: 1m 14.21s; loss: -108.917 (Â±1.70358); valid loss: -103.828\n",
      "[Epoch 60/100, Step 477660, ETA 10h 17m 38.83s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 485621, ETA 10h 2m 11.44s] Best valid loss updated: from -108.469614 to -110.193215\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 61/100, Step 485621, ETA 10h 2m 12.26s] epoch time: 15m 26.32s; step time: 0.1008s (Â±0.001915s); train time: 14m 10.68s; valid time: 1m 15.64s; loss: -112.602 (Â±0.631176); valid loss: -110.193 (*)\n",
      "[Epoch 62/100, Step 493582, ETA 9h 46m 43.95s] epoch time: 15m 23.47s; step time: 0.1008s (Â±0.001866s); train time: 14m 9.032s; valid time: 1m 14.44s; loss: -112.751 (Â±0.60066); valid loss: -109.879\n",
      "[Epoch 63/100, Step 501543, ETA 9h 31m 15.61s] epoch time: 15m 23.15s; step time: 0.1007s (Â±0.001818s); train time: 14m 8.453s; valid time: 1m 14.69s; loss: -112.817 (Â±0.581281); valid loss: -110.069\n",
      "[Epoch 64/100, Step 509504, ETA 9h 15m 46.96s] epoch time: 15m 22.31s; step time: 0.1007s (Â±0.001803s); train time: 14m 7.998s; valid time: 1m 14.32s; loss: -112.841 (Â±0.577328); valid loss: -110.117\n",
      "[Epoch 65/100, Step 517465, ETA 9h 19.42s] Best valid loss updated: from -110.193215 to -110.750159\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 65/100, Step 517465, ETA 9h 20.15s] epoch time: 15m 25.36s; step time: 0.1007s (Â±0.001842s); train time: 14m 9.626s; valid time: 1m 15.74s; loss: -112.883 (Â±0.580153); valid loss: -110.75 (*)\n",
      "[Epoch 66/100, Step 525426, ETA 8h 44m 53.9s] epoch time: 15m 26.37s; step time: 0.1007s (Â±0.001874s); train time: 14m 11.91s; valid time: 1m 14.46s; loss: -112.906 (Â±0.608259); valid loss: -110.357\n",
      "[Epoch 67/100, Step 533387, ETA 8h 29m 26.38s] epoch time: 15m 23.79s; step time: 0.1007s (Â±0.001903s); train time: 14m 9.168s; valid time: 1m 14.62s; loss: -112.939 (Â±0.583116); valid loss: -110.137\n",
      "[Epoch 68/100, Step 541348, ETA 8h 13m 57.82s] epoch time: 15m 21.35s; step time: 0.1006s (Â±0.001856s); train time: 14m 7.445s; valid time: 1m 13.91s; loss: -112.978 (Â±0.563564); valid loss: -110.106\n",
      "[Epoch 69/100, Step 549309, ETA 7h 58m 29.36s] epoch time: 15m 21.1s; step time: 0.1005s (Â±0.001881s); train time: 14m 6.955s; valid time: 1m 14.15s; loss: -112.946 (Â±0.617574); valid loss: -110.169\n",
      "[Epoch 70/100, Step 557270, ETA 7h 43m 0.9679s] epoch time: 15m 20.79s; step time: 0.1006s (Â±0.001868s); train time: 14m 6.691s; valid time: 1m 14.1s; loss: -112.967 (Â±0.724907); valid loss: -108.98\n",
      "[Epoch 71/100, Step 565231, ETA 7h 27m 33.64s] epoch time: 15m 22.87s; step time: 0.1006s (Â±0.001822s); train time: 14m 8.987s; valid time: 1m 13.88s; loss: -113.02 (Â±0.588861); valid loss: -109.845\n",
      "[Epoch 72/100, Step 573192, ETA 7h 12m 6.054s] Best valid loss updated: from -110.750159 to -111.026143\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 72/100, Step 573192, ETA 7h 12m 6.559s] epoch time: 15m 23.17s; step time: 0.1006s (Â±0.001879s); train time: 14m 7.546s; valid time: 1m 15.62s; loss: -113.022 (Â±0.606853); valid loss: -111.026 (*)\n",
      "[Epoch 73/100, Step 581153, ETA 6h 56m 38.68s] epoch time: 15m 20.74s; step time: 0.1006s (Â±0.00183s); train time: 14m 6.753s; valid time: 1m 13.98s; loss: -113.038 (Â±0.58378); valid loss: -110.301\n",
      "[Epoch 74/100, Step 589114, ETA 6h 41m 12.34s] epoch time: 15m 24.55s; step time: 0.1007s (Â±0.001847s); train time: 14m 10.49s; valid time: 1m 14.06s; loss: -113.067 (Â±0.582249); valid loss: -110.04\n",
      "[Epoch 75/100, Step 597075, ETA 6h 25m 45.05s] epoch time: 15m 21.58s; step time: 0.1006s (Â±0.001811s); train time: 14m 7.644s; valid time: 1m 13.93s; loss: -113.078 (Â±0.577673); valid loss: -110.096\n",
      "[Epoch 76/100, Step 605036, ETA 6h 10m 17.61s] epoch time: 15m 20.61s; step time: 0.1006s (Â±0.001829s); train time: 14m 6.66s; valid time: 1m 13.95s; loss: -113.111 (Â±0.589893); valid loss: -109.26\n",
      "[Epoch 77/100, Step 612997, ETA 5h 54m 51.53s] epoch time: 15m 24.58s; step time: 0.1007s (Â±0.001845s); train time: 14m 10.5s; valid time: 1m 14.08s; loss: -113.126 (Â±0.597453); valid loss: -110.37\n",
      "[Epoch 78/100, Step 620958, ETA 5h 39m 24.78s] epoch time: 15m 22.06s; step time: 0.1007s (Â±0.001822s); train time: 14m 8.007s; valid time: 1m 14.05s; loss: -113.132 (Â±0.616722); valid loss: -109.968\n",
      "[Epoch 79/100, Step 628919, ETA 5h 23m 57.86s] epoch time: 15m 20.98s; step time: 0.1007s (Â±0.001801s); train time: 14m 7.124s; valid time: 1m 13.86s; loss: -113.12 (Â±0.566376); valid loss: -110.527\n",
      "[Epoch 80/100, Step 636880, ETA 5h 8m 31.87s] epoch time: 15m 24.11s; step time: 0.1006s (Â±0.001887s); train time: 14m 9.335s; valid time: 1m 14.77s; loss: -113.125 (Â±0.59223); valid loss: -109.78\n",
      "[Epoch 80/100, Step 636880, ETA 5h 8m 31.87s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 644841, ETA 4h 53m 5.76s] Best valid loss updated: from -111.026143 to -111.191392\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 81/100, Step 644841, ETA 4h 53m 6.077s] epoch time: 15m 24.72s; step time: 0.1008s (Â±0.00184s); train time: 14m 9.107s; valid time: 1m 15.61s; loss: -114.916 (Â±0.481951); valid loss: -111.191 (*)\n",
      "[Epoch 82/100, Step 652802, ETA 4h 37m 41.03s] Best valid loss updated: from -111.191392 to -111.868024\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 82/100, Step 652802, ETA 4h 37m 41.53s] epoch time: 15m 30.32s; step time: 0.1009s (Â±0.001888s); train time: 14m 13.45s; valid time: 1m 16.87s; loss: -115.016 (Â±0.468019); valid loss: -111.868 (*)\n",
      "[Epoch 83/100, Step 660763, ETA 4h 22m 15.71s] epoch time: 15m 24.77s; step time: 0.1008s (Â±0.001827s); train time: 14m 10.43s; valid time: 1m 14.34s; loss: -115.038 (Â±0.565549); valid loss: -111.489\n",
      "[Epoch 84/100, Step 668724, ETA 4h 6m 50.09s] epoch time: 15m 25.66s; step time: 0.1007s (Â±0.001868s); train time: 14m 11.47s; valid time: 1m 14.19s; loss: -115.09 (Â±0.505971); valid loss: -111.057\n",
      "[Epoch 85/100, Step 676685, ETA 3h 51m 24.64s] epoch time: 15m 26.65s; step time: 0.1008s (Â±0.00191s); train time: 14m 12.39s; valid time: 1m 14.26s; loss: -115.125 (Â±0.519605); valid loss: -111.455\n",
      "[Epoch 86/100, Step 684646, ETA 3h 35m 58.6s] epoch time: 15m 23.23s; step time: 0.1007s (Â±0.001869s); train time: 14m 8.96s; valid time: 1m 14.27s; loss: -115.16 (Â±0.501276); valid loss: -111.159\n",
      "[Epoch 87/100, Step 692607, ETA 3h 20m 33.3s] epoch time: 15m 27.7s; step time: 0.1008s (Â±0.001869s); train time: 14m 12.94s; valid time: 1m 14.76s; loss: -115.177 (Â±0.507327); valid loss: -111.513\n",
      "[Epoch 88/100, Step 700568, ETA 3h 5m 7.899s] epoch time: 15m 27.36s; step time: 0.101s (Â±0.001891s); train time: 14m 12.71s; valid time: 1m 14.65s; loss: -115.193 (Â±0.544057); valid loss: -111.448\n",
      "[Epoch 89/100, Step 708529, ETA 2h 49m 42.4s] Best valid loss updated: from -111.868024 to -112.113590\n",
      "Model saved at /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13.\n",
      "[Epoch 89/100, Step 708529, ETA 2h 49m 42.68s] epoch time: 15m 29.23s; step time: 0.1009s (Â±0.001916s); train time: 14m 12.53s; valid time: 1m 16.7s; loss: -115.205 (Â±0.563653); valid loss: -112.114 (*)\n",
      "[Epoch 90/100, Step 716490, ETA 2h 34m 16.74s] epoch time: 15m 23.52s; step time: 0.1007s (Â±0.001862s); train time: 14m 8.895s; valid time: 1m 14.62s; loss: -115.245 (Â±0.51705); valid loss: -111.544\n",
      "[Epoch 91/100, Step 724451, ETA 2h 18m 51.02s] epoch time: 15m 25.19s; step time: 0.1008s (Â±0.001877s); train time: 14m 10.09s; valid time: 1m 15.11s; loss: -115.229 (Â±0.669481); valid loss: -111.879\n",
      "[Epoch 92/100, Step 732412, ETA 2h 3m 25.56s] epoch time: 15m 28.11s; step time: 0.1009s (Â±0.00191s); train time: 14m 13.48s; valid time: 1m 14.63s; loss: -115.291 (Â±0.512876); valid loss: -111.674\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 4 (10% train data, no transfer)"
   ],
   "metadata": {
    "id": "4nOkr1_T_UaT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp4 --train_portion=0.1 --initial_lr=0.00005"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkLMI6kh_XWz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702410191863,
     "user_tz": 300,
     "elapsed": 9395974,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "77014f57-e30d-4717-e5a0-4aa1ace0fdad"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "=================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': None,\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'results/tuned_model_st8000_2_exp4',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': 0.1,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (509538, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 17:06:50,898 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 17:06:55.011593: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-12 17:06:55.209871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-12 17:06:55.210060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-12 17:06:55.210088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-12 17:06:55.477509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-12 17:06:55.477564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-12 17:06:55.477574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-12 17:06:55.477658: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-12 17:06:55.477704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (407631, 16)\n",
      "[Epoch 1/100, Step 796] Best valid loss updated: from inf to -37.770945\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 1/100, Step 796, ETA 2h 27m 44.55s] epoch time: 1m 29.54s; step time: 0.0955s (Â±0.1168s); train time: 1m 20.47s; valid time: 9.067s; loss: -28.6409 (Â±9.17884); valid loss: -37.7709 (*)\n",
      "[Epoch 2/100, Step 1592, ETA 2h 24m 33.08s] Best valid loss updated: from -37.770945 to -39.838168\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 2/100, Step 1592, ETA 2h 25m 15.35s] epoch time: 1m 28.32s; step time: 0.09544s (Â±0.003141s); train time: 1m 20.43s; valid time: 7.891s; loss: -38.2751 (Â±2.57251); valid loss: -39.8382 (*)\n",
      "[Epoch 3/100, Step 2388, ETA 2h 24m 8.532s] Best valid loss updated: from -39.838168 to -45.285443\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 3/100, Step 2388, ETA 2h 24m 53.44s] epoch time: 1m 31s; step time: 0.09758s (Â±0.001511s); train time: 1m 22.13s; valid time: 8.874s; loss: -41.4723 (Â±2.25271); valid loss: -45.2854 (*)\n",
      "[Epoch 4/100, Step 3184, ETA 2h 23m 44.43s] epoch time: 1m 30.48s; step time: 0.09881s (Â±0.001735s); train time: 1m 23.28s; valid time: 7.205s; loss: -43.5618 (Â±2.21152); valid loss: -41.4339\n",
      "[Epoch 5/100, Step 3980, ETA 2h 22m 38.09s] Best valid loss updated: from -45.285443 to -45.584679\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 5/100, Step 3980, ETA 2h 23m 0.7316s] epoch time: 1m 32.27s; step time: 0.09931s (Â±0.001615s); train time: 1m 23.47s; valid time: 8.799s; loss: -44.8937 (Â±2.45605); valid loss: -45.5847 (*)\n",
      "[Epoch 6/100, Step 4776, ETA 2h 21m 37.32s] Best valid loss updated: from -45.584679 to -46.519351\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 6/100, Step 4776, ETA 2h 21m 59.49s] epoch time: 1m 32.18s; step time: 0.09947s (Â±0.00159s); train time: 1m 23.61s; valid time: 8.565s; loss: -46.5093 (Â±2.20542); valid loss: -46.5194 (*)\n",
      "[Epoch 7/100, Step 5572, ETA 2h 20m 41.71s] Best valid loss updated: from -46.519351 to -47.600263\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 7/100, Step 5572, ETA 2h 20m 53.74s] epoch time: 1m 32.5s; step time: 0.09971s (Â±0.002785s); train time: 1m 24.25s; valid time: 8.253s; loss: -47.7274 (Â±2.21419); valid loss: -47.6003 (*)\n",
      "[Epoch 8/100, Step 6368, ETA 2h 19m 33.86s] Best valid loss updated: from -47.600263 to -49.216670\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 8/100, Step 6368, ETA 2h 19m 45.34s] epoch time: 1m 32.86s; step time: 0.09983s (Â±0.001592s); train time: 1m 24.06s; valid time: 8.798s; loss: -48.615 (Â±2.60632); valid loss: -49.2167 (*)\n",
      "[Epoch 9/100, Step 7164, ETA 2h 18m 13.2s] Best valid loss updated: from -49.216670 to -52.208582\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 9/100, Step 7164, ETA 2h 18m 29s] epoch time: 1m 32.61s; step time: 0.09978s (Â±0.001576s); train time: 1m 23.88s; valid time: 8.727s; loss: -49.4012 (Â±2.44521); valid loss: -52.2086 (*)\n",
      "[Epoch 10/100, Step 7960, ETA 2h 16m 59.81s] epoch time: 1m 31.54s; step time: 0.09974s (Â±0.002587s); train time: 1m 24.25s; valid time: 7.288s; loss: -50.2508 (Â±2.34516); valid loss: -50.8966\n",
      "[Epoch 11/100, Step 8756, ETA 2h 15m 28.67s] epoch time: 1m 31.35s; step time: 0.09967s (Â±0.001579s); train time: 1m 23.76s; valid time: 7.592s; loss: -51.11 (Â±2.67606); valid loss: -52.0504\n",
      "[Epoch 12/100, Step 9552, ETA 2h 13m 58.7s] Best valid loss updated: from -52.208582 to -53.896865\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 12/100, Step 9552, ETA 2h 14m 5.967s] epoch time: 1m 32.51s; step time: 0.0998s (Â±0.001584s); train time: 1m 24.36s; valid time: 8.145s; loss: -52.2164 (Â±2.06131); valid loss: -53.8969 (*)\n",
      "[Epoch 13/100, Step 10348, ETA 2h 12m 38.06s] Best valid loss updated: from -53.896865 to -55.090309\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 13/100, Step 10348, ETA 2h 12m 44.9s] epoch time: 1m 32.98s; step time: 0.09973s (Â±0.001617s); train time: 1m 24.39s; valid time: 8.594s; loss: -52.675 (Â±2.37729); valid loss: -55.0903 (*)\n",
      "[Epoch 14/100, Step 11144, ETA 2h 11m 12.5s] Best valid loss updated: from -55.090309 to -56.659069\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 14/100, Step 11144, ETA 2h 11m 22.55s] epoch time: 1m 33.05s; step time: 0.09984s (Â±0.001636s); train time: 1m 23.97s; valid time: 9.071s; loss: -53.6547 (Â±2.02071); valid loss: -56.6591 (*)\n",
      "[Epoch 15/100, Step 11940, ETA 2h 9m 51.78s] Best valid loss updated: from -56.659069 to -56.671839\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 15/100, Step 11940, ETA 2h 9m 57.79s] epoch time: 1m 32.87s; step time: 0.1001s (Â±0.002612s); train time: 1m 24.62s; valid time: 8.256s; loss: -54.8717 (Â±2.05373); valid loss: -56.6718 (*)\n",
      "[Epoch 16/100, Step 12736, ETA 2h 8m 28.08s] Best valid loss updated: from -56.671839 to -56.993333\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 16/100, Step 12736, ETA 2h 8m 33.82s] epoch time: 1m 33.22s; step time: 0.1001s (Â±0.002514s); train time: 1m 24.68s; valid time: 8.535s; loss: -55.3886 (Â±1.91725); valid loss: -56.9933 (*)\n",
      "[Epoch 17/100, Step 13532, ETA 2h 7m 2.076s] epoch time: 1m 31.85s; step time: 0.09979s (Â±0.001669s); train time: 1m 24.2s; valid time: 7.647s; loss: -56.0173 (Â±2.2942); valid loss: -52.3828\n",
      "[Epoch 18/100, Step 14328, ETA 2h 5m 28.9s] Best valid loss updated: from -56.993333 to -59.441163\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 18/100, Step 14328, ETA 2h 5m 35.37s] epoch time: 1m 32.96s; step time: 0.09977s (Â±0.00158s); train time: 1m 24.38s; valid time: 8.575s; loss: -56.4689 (Â±2.11738); valid loss: -59.4412 (*)\n",
      "[Epoch 19/100, Step 15124, ETA 2h 4m 3.64s] epoch time: 1m 31.93s; step time: 0.0999s (Â±0.002645s); train time: 1m 24.56s; valid time: 7.368s; loss: -57.2441 (Â±2.36865); valid loss: -58.2188\n",
      "[Epoch 20/100, Step 15920, ETA 2h 2m 30.05s] Best valid loss updated: from -59.441163 to -59.484710\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 20/100, Step 15920, ETA 2h 2m 36.5s] epoch time: 1m 33.08s; step time: 0.09981s (Â±0.001608s); train time: 1m 23.94s; valid time: 9.142s; loss: -58.2384 (Â±2.21655); valid loss: -59.4847 (*)\n",
      "[Epoch 20/100, Step 15920, ETA 2h 2m 36.5s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 16716, ETA 2h 1m 1.927s] Best valid loss updated: from -59.484710 to -62.955707\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 21/100, Step 16716, ETA 2h 1m 6.131s] epoch time: 1m 32.38s; step time: 0.09985s (Â±0.002572s); train time: 1m 24.12s; valid time: 8.259s; loss: -63.6306 (Â±1.60099); valid loss: -62.9557 (*)\n",
      "[Epoch 22/100, Step 17512, ETA 1h 59m 32.46s] Best valid loss updated: from -62.955707 to -64.298285\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 22/100, Step 17512, ETA 1h 59m 36.66s] epoch time: 1m 32.68s; step time: 0.09975s (Â±0.001522s); train time: 1m 23.87s; valid time: 8.81s; loss: -63.9435 (Â±1.89381); valid loss: -64.2983 (*)\n",
      "[Epoch 23/100, Step 18308, ETA 1h 58m 1.842s] epoch time: 1m 31.17s; step time: 0.09973s (Â±0.001507s); train time: 1m 23.79s; valid time: 7.379s; loss: -64.1938 (Â±1.7059); valid loss: -64.2894\n",
      "[Epoch 24/100, Step 19104, ETA 1h 56m 28.32s] Best valid loss updated: from -64.298285 to -66.502067\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 24/100, Step 19104, ETA 1h 56m 32.01s] epoch time: 1m 32.65s; step time: 0.09981s (Â±0.001626s); train time: 1m 24.3s; valid time: 8.352s; loss: -64.3226 (Â±1.76119); valid loss: -66.5021 (*)\n",
      "[Epoch 25/100, Step 19900, ETA 1h 54m 59.11s] epoch time: 1m 31.7s; step time: 0.09982s (Â±0.001788s); train time: 1m 24.06s; valid time: 7.641s; loss: -65.0193 (Â±1.9333); valid loss: -64.6578\n",
      "[Epoch 26/100, Step 20696, ETA 1h 53m 25s] epoch time: 1m 31.24s; step time: 0.0998s (Â±0.001635s); train time: 1m 24.12s; valid time: 7.126s; loss: -64.5173 (Â±2.06106); valid loss: -65.3588\n",
      "[Epoch 27/100, Step 21492, ETA 1h 51m 51.78s] Best valid loss updated: from -66.502067 to -66.518707\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 27/100, Step 21492, ETA 1h 51m 54.97s] epoch time: 1m 32.67s; step time: 0.09995s (Â±0.001613s); train time: 1m 24.01s; valid time: 8.659s; loss: -65.2332 (Â±2.32683); valid loss: -66.5187 (*)\n",
      "[Epoch 28/100, Step 22288, ETA 1h 50m 21.17s] Best valid loss updated: from -66.518707 to -66.695064\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 28/100, Step 22288, ETA 1h 50m 25.88s] epoch time: 1m 33.11s; step time: 0.09974s (Â±0.001521s); train time: 1m 23.79s; valid time: 9.326s; loss: -65.2434 (Â±1.91688); valid loss: -66.6951 (*)\n",
      "[Epoch 29/100, Step 23084, ETA 1h 48m 51.34s] epoch time: 1m 31s; step time: 0.09991s (Â±0.002636s); train time: 1m 23.88s; valid time: 7.122s; loss: -65.2347 (Â±2.06814); valid loss: -66.1801\n",
      "[Epoch 30/100, Step 23880, ETA 1h 47m 18.43s] epoch time: 1m 31.6s; step time: 0.09993s (Â±0.001532s); train time: 1m 24.15s; valid time: 7.45s; loss: -65.7324 (Â±2.12188); valid loss: -64.4132\n",
      "[Epoch 31/100, Step 24676, ETA 1h 45m 44.65s] epoch time: 1m 31.17s; step time: 0.09985s (Â±0.001645s); train time: 1m 23.77s; valid time: 7.395s; loss: -65.9588 (Â±2.11309); valid loss: -66.5917\n",
      "[Epoch 32/100, Step 25472, ETA 1h 44m 12.18s] epoch time: 1m 31.71s; step time: 0.09999s (Â±0.001614s); train time: 1m 24.51s; valid time: 7.201s; loss: -65.7367 (Â±1.9366); valid loss: -66.3103\n",
      "[Epoch 33/100, Step 26268, ETA 1h 42m 39.79s] Best valid loss updated: from -66.695064 to -67.719692\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 33/100, Step 26268, ETA 1h 42m 42.35s] epoch time: 1m 32.98s; step time: 0.09992s (Â±0.001633s); train time: 1m 24.05s; valid time: 8.935s; loss: -66.0822 (Â±1.96355); valid loss: -67.7197 (*)\n",
      "[Epoch 34/100, Step 27064, ETA 1h 41m 9.162s] epoch time: 1m 31.35s; step time: 0.09991s (Â±0.001676s); train time: 1m 24.04s; valid time: 7.313s; loss: -66.2774 (Â±1.98081); valid loss: -67.0671\n",
      "[Epoch 35/100, Step 27860, ETA 1h 39m 37.33s] epoch time: 1m 32.03s; step time: 0.1001s (Â±0.001534s); train time: 1m 24.76s; valid time: 7.268s; loss: -66.4027 (Â±1.96313); valid loss: -66.6969\n",
      "[Epoch 36/100, Step 28656, ETA 1h 38m 5.483s] epoch time: 1m 32.02s; step time: 0.1001s (Â±0.001611s); train time: 1m 24.3s; valid time: 7.717s; loss: -66.5404 (Â±1.78594); valid loss: -66.9026\n",
      "[Epoch 37/100, Step 29452, ETA 1h 36m 32.6s] Best valid loss updated: from -67.719692 to -68.098761\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 37/100, Step 29452, ETA 1h 36m 36.25s] epoch time: 1m 33.56s; step time: 0.09996s (Â±0.001561s); train time: 1m 24.21s; valid time: 9.353s; loss: -66.4841 (Â±2.00922); valid loss: -68.0988 (*)\n",
      "[Epoch 38/100, Step 30248, ETA 1h 35m 4.36s] Best valid loss updated: from -68.098761 to -68.299776\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 38/100, Step 30248, ETA 1h 35m 6.606s] epoch time: 1m 33.45s; step time: 0.1002s (Â±0.002684s); train time: 1m 24.89s; valid time: 8.564s; loss: -66.9814 (Â±1.76632); valid loss: -68.2998 (*)\n",
      "[Epoch 39/100, Step 31044, ETA 1h 33m 34.86s] Best valid loss updated: from -68.299776 to -68.306832\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 39/100, Step 31044, ETA 1h 33m 37.19s] epoch time: 1m 33.72s; step time: 0.1002s (Â±0.00265s); train time: 1m 24.4s; valid time: 9.32s; loss: -66.869 (Â±1.92032); valid loss: -68.3068 (*)\n",
      "[Epoch 40/100, Step 31840, ETA 1h 32m 4.538s] Best valid loss updated: from -68.306832 to -68.337824\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 40/100, Step 31840, ETA 1h 32m 7.883s] epoch time: 1m 33.94s; step time: 0.1001s (Â±0.002559s); train time: 1m 24.29s; valid time: 9.646s; loss: -66.9608 (Â±1.76155); valid loss: -68.3378 (*)\n",
      "[Epoch 40/100, Step 31840, ETA 1h 32m 7.883s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 32636, ETA 1h 30m 34.96s] Best valid loss updated: from -68.337824 to -71.993678\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 41/100, Step 32636, ETA 1h 30m 37.85s] epoch time: 1m 33.58s; step time: 0.09995s (Â±0.002675s); train time: 1m 24.43s; valid time: 9.155s; loss: -72.3892 (Â±1.21499); valid loss: -71.9937 (*)\n",
      "[Epoch 42/100, Step 33432, ETA 1h 29m 5.333s] Best valid loss updated: from -71.993678 to -72.347980\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 42/100, Step 33432, ETA 1h 29m 7.304s] epoch time: 1m 33.34s; step time: 0.1s (Â±0.003039s); train time: 1m 24.57s; valid time: 8.767s; loss: -72.5558 (Â±1.77822); valid loss: -72.348 (*)\n",
      "[Epoch 43/100, Step 34228, ETA 1h 27m 34.42s] Best valid loss updated: from -72.347980 to -74.122820\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 43/100, Step 34228, ETA 1h 27m 36.37s] epoch time: 1m 33.15s; step time: 0.09993s (Â±0.002648s); train time: 1m 24.03s; valid time: 9.118s; loss: -72.7471 (Â±1.66266); valid loss: -74.1228 (*)\n",
      "[Epoch 44/100, Step 35024, ETA 1h 26m 3.231s] epoch time: 1m 31.49s; step time: 0.1s (Â±0.003195s); train time: 1m 24.17s; valid time: 7.319s; loss: -72.8677 (Â±1.70016); valid loss: -72.2575\n",
      "[Epoch 45/100, Step 35820, ETA 1h 24m 30.48s] epoch time: 1m 31.75s; step time: 0.09999s (Â±0.00165s); train time: 1m 24.5s; valid time: 7.251s; loss: -72.8724 (Â±1.78074); valid loss: -69.0444\n",
      "[Epoch 46/100, Step 36616, ETA 1h 22m 57.58s] epoch time: 1m 31.59s; step time: 0.09985s (Â±0.001533s); train time: 1m 23.91s; valid time: 7.68s; loss: -72.8539 (Â±1.83018); valid loss: -73.8624\n",
      "[Epoch 47/100, Step 37412, ETA 1h 21m 24.22s] epoch time: 1m 31.12s; step time: 0.09996s (Â±0.001608s); train time: 1m 24s; valid time: 7.127s; loss: -73.0721 (Â±1.93727); valid loss: -73.1379\n",
      "[Epoch 48/100, Step 38208, ETA 1h 19m 51.71s] epoch time: 1m 31.83s; step time: 0.09995s (Â±0.001658s); train time: 1m 24.39s; valid time: 7.44s; loss: -73.4781 (Â±1.76276); valid loss: -74.1164\n",
      "[Epoch 49/100, Step 39004, ETA 1h 18m 18.81s] epoch time: 1m 31.43s; step time: 0.09992s (Â±0.00161s); train time: 1m 23.98s; valid time: 7.45s; loss: -72.9901 (Â±2.13449); valid loss: -72.8036\n",
      "[Epoch 50/100, Step 39800, ETA 1h 16m 46.04s] epoch time: 1m 31.5s; step time: 0.09991s (Â±0.001606s); train time: 1m 24.37s; valid time: 7.13s; loss: -73.3956 (Â±1.77021); valid loss: -73.0741\n",
      "[Epoch 51/100, Step 40596, ETA 1h 15m 13.45s] Best valid loss updated: from -74.122820 to -74.589190\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 51/100, Step 40596, ETA 1h 15m 14.88s] epoch time: 1m 33.11s; step time: 0.09999s (Â±0.001595s); train time: 1m 23.99s; valid time: 9.125s; loss: -73.4186 (Â±1.52662); valid loss: -74.5892 (*)\n",
      "[Epoch 52/100, Step 41392, ETA 1h 13m 41.96s] epoch time: 1m 31.3s; step time: 0.09984s (Â±0.002579s); train time: 1m 23.96s; valid time: 7.343s; loss: -73.4298 (Â±1.73403); valid loss: -74.581\n",
      "[Epoch 53/100, Step 42188, ETA 1h 12m 9.351s] Best valid loss updated: from -74.589190 to -75.705563\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 53/100, Step 42188, ETA 1h 12m 10.71s] epoch time: 1m 33.1s; step time: 0.09983s (Â±0.001501s); train time: 1m 24.37s; valid time: 8.725s; loss: -73.4718 (Â±1.6793); valid loss: -75.7056 (*)\n",
      "[Epoch 54/100, Step 42984, ETA 1h 10m 38.12s] Best valid loss updated: from -75.705563 to -75.727380\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 54/100, Step 42984, ETA 1h 10m 39.43s] epoch time: 1m 33.15s; step time: 0.09992s (Â±0.00303s); train time: 1m 24.01s; valid time: 9.146s; loss: -73.6679 (Â±1.66343); valid loss: -75.7274 (*)\n",
      "[Epoch 55/100, Step 43780, ETA 1h 9m 6.551s] epoch time: 1m 31.29s; step time: 0.09984s (Â±0.002762s); train time: 1m 23.9s; valid time: 7.388s; loss: -73.5051 (Â±2.01534); valid loss: -75.0849\n",
      "[Epoch 56/100, Step 44576, ETA 1h 7m 33.88s] epoch time: 1m 31.48s; step time: 0.0998s (Â±0.001571s); train time: 1m 24.32s; valid time: 7.157s; loss: -73.7473 (Â±1.65624); valid loss: -73.859\n",
      "[Epoch 57/100, Step 45372, ETA 1h 6m 1.351s] epoch time: 1m 31.61s; step time: 0.0999s (Â±0.001622s); train time: 1m 23.94s; valid time: 7.669s; loss: -73.8013 (Â±1.63885); valid loss: -74.9706\n",
      "[Epoch 58/100, Step 46168, ETA 1h 4m 28.62s] epoch time: 1m 31.29s; step time: 0.09999s (Â±0.002115s); train time: 1m 24.1s; valid time: 7.182s; loss: -73.7425 (Â±1.51342); valid loss: -74.6964\n",
      "[Epoch 59/100, Step 46964, ETA 1h 2m 56.33s] epoch time: 1m 31.85s; step time: 0.0999s (Â±0.001615s); train time: 1m 24.5s; valid time: 7.346s; loss: -73.7007 (Â±2.22544); valid loss: -73.9299\n",
      "[Epoch 60/100, Step 47760, ETA 1h 1m 23.78s] epoch time: 1m 31.44s; step time: 0.09988s (Â±0.001676s); train time: 1m 23.91s; valid time: 7.524s; loss: -73.8526 (Â±2.16674); valid loss: -74.6683\n",
      "[Epoch 60/100, Step 47760, ETA 1h 1m 23.78s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 48556, ETA 59m 51.38s] Best valid loss updated: from -75.727380 to -79.017370\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 61/100, Step 48556, ETA 59m 52.37s] epoch time: 1m 33.16s; step time: 0.09998s (Â±0.001567s); train time: 1m 24.46s; valid time: 8.7s; loss: -77.9364 (Â±1.33606); valid loss: -79.0174 (*)\n",
      "[Epoch 62/100, Step 49352, ETA 58m 20.14s] Best valid loss updated: from -79.017370 to -80.002330\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 62/100, Step 49352, ETA 58m 21.11s] epoch time: 1m 33.5s; step time: 0.1001s (Â±0.003097s); train time: 1m 24.48s; valid time: 9.017s; loss: -79.1235 (Â±0.929748); valid loss: -80.0023 (*)\n",
      "[Epoch 63/100, Step 50148, ETA 56m 48.66s] epoch time: 1m 31.6s; step time: 0.1s (Â±0.002837s); train time: 1m 23.99s; valid time: 7.605s; loss: -78.9906 (Â±1.29042); valid loss: -79.2517\n",
      "[Epoch 64/100, Step 50944, ETA 55m 16.18s] epoch time: 1m 31.5s; step time: 0.1001s (Â±0.001567s); train time: 1m 24.37s; valid time: 7.124s; loss: -79.1293 (Â±1.88525); valid loss: -79.9825\n",
      "[Epoch 65/100, Step 51740, ETA 53m 43.8s] epoch time: 1m 31.63s; step time: 0.1001s (Â±0.001626s); train time: 1m 24.11s; valid time: 7.522s; loss: -79.1916 (Â±1.52861); valid loss: -79.0708\n",
      "[Epoch 66/100, Step 52536, ETA 52m 11.24s] epoch time: 1m 31.23s; step time: 0.09991s (Â±0.001741s); train time: 1m 23.9s; valid time: 7.329s; loss: -79.1332 (Â±2.06634); valid loss: -79.5214\n",
      "[Epoch 67/100, Step 53332, ETA 50m 38.78s] epoch time: 1m 31.35s; step time: 0.0998s (Â±0.001606s); train time: 1m 24.21s; valid time: 7.138s; loss: -79.1989 (Â±1.69512); valid loss: -79.7904\n",
      "[Epoch 68/100, Step 54128, ETA 49m 6.523s] Best valid loss updated: from -80.002330 to -81.002690\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 68/100, Step 54128, ETA 49m 7.294s] epoch time: 1m 33.35s; step time: 0.09988s (Â±0.0016s); train time: 1m 23.99s; valid time: 9.364s; loss: -79.4871 (Â±1.22902); valid loss: -81.0027 (*)\n",
      "[Epoch 69/100, Step 54924, ETA 47m 34.83s] epoch time: 1m 31.3s; step time: 0.1s (Â±0.002735s); train time: 1m 24.06s; valid time: 7.237s; loss: -79.4377 (Â±1.61306); valid loss: -80.3374\n",
      "[Epoch 70/100, Step 55720, ETA 46m 2.526s] epoch time: 1m 31.59s; step time: 0.09987s (Â±0.001563s); train time: 1m 24.3s; valid time: 7.298s; loss: -79.6325 (Â±1.39528); valid loss: -79.1866\n",
      "[Epoch 71/100, Step 56516, ETA 44m 30.28s] epoch time: 1m 31.69s; step time: 0.09988s (Â±0.001553s); train time: 1m 23.99s; valid time: 7.698s; loss: -79.3625 (Â±2.26523); valid loss: -80.3171\n",
      "[Epoch 72/100, Step 57312, ETA 42m 57.93s] epoch time: 1m 31.38s; step time: 0.1001s (Â±0.001659s); train time: 1m 24.24s; valid time: 7.145s; loss: -79.4037 (Â±2.04395); valid loss: -80.45\n",
      "[Epoch 73/100, Step 58108, ETA 41m 25.84s] Best valid loss updated: from -81.002690 to -81.052007\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 73/100, Step 58108, ETA 41m 26.52s] epoch time: 1m 33.85s; step time: 0.1s (Â±0.001668s); train time: 1m 24.54s; valid time: 9.309s; loss: -79.7407 (Â±1.89316); valid loss: -81.052 (*)\n",
      "[Epoch 74/100, Step 58904, ETA 39m 54.4s] epoch time: 1m 32s; step time: 0.1001s (Â±0.002765s); train time: 1m 24.21s; valid time: 7.794s; loss: -79.6702 (Â±1.53093); valid loss: -80.0703\n",
      "[Epoch 75/100, Step 59700, ETA 38m 22.09s] epoch time: 1m 31.44s; step time: 0.1001s (Â±0.001724s); train time: 1m 24.2s; valid time: 7.239s; loss: -79.5385 (Â±2.02591); valid loss: -79.3732\n",
      "[Epoch 76/100, Step 60496, ETA 36m 49.99s] epoch time: 1m 32.04s; step time: 0.1001s (Â±0.001595s); train time: 1m 24.68s; valid time: 7.361s; loss: -79.9849 (Â±1.10304); valid loss: -80.5211\n",
      "[Epoch 77/100, Step 61292, ETA 35m 17.71s] Best valid loss updated: from -81.052007 to -81.080535\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 77/100, Step 61292, ETA 35m 18.37s] epoch time: 1m 33.63s; step time: 0.09987s (Â±0.001643s); train time: 1m 23.91s; valid time: 9.714s; loss: -79.9148 (Â±1.28096); valid loss: -81.0805 (*)\n",
      "[Epoch 78/100, Step 62088, ETA 33m 46.05s] epoch time: 1m 31.32s; step time: 0.09996s (Â±0.002665s); train time: 1m 24.12s; valid time: 7.202s; loss: -79.5461 (Â±1.90457); valid loss: -79.4867\n",
      "[Epoch 79/100, Step 62884, ETA 32m 13.9s] epoch time: 1m 31.87s; step time: 0.09992s (Â±0.001621s); train time: 1m 24.54s; valid time: 7.337s; loss: -79.7075 (Â±2.27717); valid loss: -80.8246\n",
      "[Epoch 80/100, Step 63680, ETA 30m 41.64s] epoch time: 1m 31.42s; step time: 0.0998s (Â±0.001607s); train time: 1m 23.88s; valid time: 7.546s; loss: -79.7789 (Â±1.9663); valid loss: -80.7826\n",
      "[Epoch 80/100, Step 63680, ETA 30m 41.64s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 64476, ETA 29m 9.473s] Best valid loss updated: from -81.080535 to -84.009183\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 81/100, Step 64476, ETA 29m 9.899s] epoch time: 1m 33.53s; step time: 0.09999s (Â±0.001599s); train time: 1m 24.56s; valid time: 8.963s; loss: -83.2346 (Â±0.685768); valid loss: -84.0092 (*)\n",
      "[Epoch 82/100, Step 65272, ETA 27m 37.8s] Best valid loss updated: from -84.009183 to -84.348044\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 82/100, Step 65272, ETA 27m 38.2s] epoch time: 1m 33.93s; step time: 0.1s (Â±0.002692s); train time: 1m 24.66s; valid time: 9.276s; loss: -83.6722 (Â±0.70747); valid loss: -84.348 (*)\n",
      "[Epoch 83/100, Step 66068, ETA 26m 6.021s] epoch time: 1m 31.83s; step time: 0.09994s (Â±0.002653s); train time: 1m 24.1s; valid time: 7.733s; loss: -83.8103 (Â±0.870128); valid loss: -84.1165\n",
      "[Epoch 84/100, Step 66864, ETA 24m 33.68s] epoch time: 1m 30.93s; step time: 0.09965s (Â±0.001545s); train time: 1m 23.81s; valid time: 7.127s; loss: -83.9283 (Â±1.42444); valid loss: -83.9125\n",
      "[Epoch 85/100, Step 67660, ETA 23m 1.509s] epoch time: 1m 31.75s; step time: 0.09991s (Â±0.00156s); train time: 1m 24.36s; valid time: 7.387s; loss: -84.1906 (Â±0.983931); valid loss: -84.2874\n",
      "[Epoch 86/100, Step 68456, ETA 21m 29.3s] Best valid loss updated: from -84.348044 to -84.731488\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 86/100, Step 68456, ETA 21m 29.71s] epoch time: 1m 33.93s; step time: 0.09978s (Â±0.001679s); train time: 1m 23.91s; valid time: 10.03s; loss: -84.205 (Â±1.11303); valid loss: -84.7315 (*)\n",
      "[Epoch 87/100, Step 69252, ETA 19m 57.44s] epoch time: 1m 31.14s; step time: 0.09979s (Â±0.003031s); train time: 1m 23.98s; valid time: 7.163s; loss: -84.1143 (Â±1.86068); valid loss: -84.0576\n",
      "[Epoch 88/100, Step 70048, ETA 18m 25.29s] Best valid loss updated: from -84.731488 to -85.315747\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 88/100, Step 70048, ETA 18m 25.54s] epoch time: 1m 33.68s; step time: 0.09973s (Â±0.001716s); train time: 1m 24.36s; valid time: 9.316s; loss: -84.5291 (Â±0.894139); valid loss: -85.3157 (*)\n",
      "[Epoch 89/100, Step 70844, ETA 16m 53.35s] epoch time: 1m 31.59s; step time: 0.0997s (Â±0.002724s); train time: 1m 23.94s; valid time: 7.656s; loss: -84.5694 (Â±0.953289); valid loss: -84.9532\n",
      "[Epoch 90/100, Step 71640, ETA 15m 21.14s] epoch time: 1m 31.32s; step time: 0.09967s (Â±0.00162s); train time: 1m 24s; valid time: 7.316s; loss: -84.5437 (Â±1.60776); valid loss: -83.8152\n",
      "[Epoch 91/100, Step 72436, ETA 13m 49.04s] Best valid loss updated: from -85.315747 to -85.501776\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 91/100, Step 72436, ETA 13m 49.25s] epoch time: 1m 34.38s; step time: 0.1001s (Â±0.001779s); train time: 1m 24.65s; valid time: 9.728s; loss: -84.5201 (Â±1.35841); valid loss: -85.5018 (*)\n",
      "[Epoch 92/100, Step 73232, ETA 12m 17.1s] Best valid loss updated: from -85.501776 to -85.528392\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 92/100, Step 73232, ETA 12m 17.33s] epoch time: 1m 34.68s; step time: 0.1s (Â±0.003001s); train time: 1m 24.46s; valid time: 10.22s; loss: -84.749 (Â±1.04872); valid loss: -85.5284 (*)\n",
      "[Epoch 93/100, Step 74028, ETA 10m 45.13s] Best valid loss updated: from -85.528392 to -85.597249\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 93/100, Step 74028, ETA 10m 45.35s] epoch time: 1m 34.66s; step time: 0.1001s (Â±0.002781s); train time: 1m 24.49s; valid time: 10.17s; loss: -84.8708 (Â±0.988335); valid loss: -85.5972 (*)\n",
      "[Epoch 94/100, Step 74824, ETA 9m 13.16s] epoch time: 1m 32.22s; step time: 0.1s (Â±0.003089s); train time: 1m 24.82s; valid time: 7.396s; loss: -84.5269 (Â±1.58528); valid loss: -83.9035\n",
      "[Epoch 95/100, Step 75620, ETA 7m 40.97s] Best valid loss updated: from -85.597249 to -86.211722\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 95/100, Step 75620, ETA 7m 41.1s] epoch time: 1m 34.63s; step time: 0.1002s (Â±0.001732s); train time: 1m 24.56s; valid time: 10.07s; loss: -84.7807 (Â±1.56452); valid loss: -86.2117 (*)\n",
      "[Epoch 96/100, Step 76416, ETA 6m 8.854s] Best valid loss updated: from -86.211722 to -86.599633\n",
      "Model saved at results/tuned_model_st8000_2_exp4_2023-12-12_17-06-45.\n",
      "[Epoch 96/100, Step 76416, ETA 6m 8.993s] epoch time: 1m 35s; step time: 0.1s (Â±0.002856s); train time: 1m 24.4s; valid time: 10.6s; loss: -85 (Â±1.01186); valid loss: -86.5996 (*)\n",
      "[Epoch 97/100, Step 77212, ETA 4m 36.73s] epoch time: 1m 31.62s; step time: 0.09976s (Â±0.002865s); train time: 1m 24.45s; valid time: 7.174s; loss: -84.7982 (Â±1.89934); valid loss: -78.33\n",
      "[Epoch 98/100, Step 78008, ETA 3m 4.473s] epoch time: 1m 31.72s; step time: 0.0998s (Â±0.001621s); train time: 1m 24.07s; valid time: 7.648s; loss: -84.7498 (Â±1.90078); valid loss: -85.5549\n",
      "[Epoch 99/100, Step 78804, ETA 1m 32.23s] epoch time: 1m 31.34s; step time: 0.09981s (Â±0.001643s); train time: 1m 24.02s; valid time: 7.323s; loss: -84.9433 (Â±1.27019); valid loss: -85.2528\n",
      "[Epoch 100/100, Step 79600, ETA 0s] epoch time: 1m 31.91s; step time: 0.1s (Â±0.001661s); train time: 1m 24.61s; valid time: 7.305s; loss: -85.2244 (Â±0.909794); valid loss: -85.617\n",
      "[Epoch 100/100, Step 79600, ETA 0s] Learning rate decreased to 1.5625e-06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpotc65vtz/variables.dat-76416\n",
      "2023-12-12 19:40:38,598 [INFO] tensorflow: Restoring parameters from /tmp/tmpotc65vtz/variables.dat-76416\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'best_valid_loss': -86.59963267633995,\n",
      " 'pred_time': 0.03268298074567322,\n",
      " 'pred_total_time': 109.00401139259338,\n",
      " 'train_time': 92.23287836074829,\n",
      " 'valid_time': 0.03273701678568394}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpo8ivej3twandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpl_omif9ywandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpxngp9qhqwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp5maoo52ywandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 4 with 1%/0.1% train data, no transfer"
   ],
   "metadata": {
    "id": "YrRGA6CWlq-V"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp4_1p --train_portion=0.01 --initial_lr=0.00005"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xjLNG-plmdF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702412486967,
     "user_tz": 300,
     "elapsed": 1084499,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "cbff203d-c2ea-491c-c771-eeaab51f8548"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "====================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': None,\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'results/tuned_model_st8000_2_exp4_1p',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': 0.01,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (50953, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 20:03:33,209 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 20:03:37.457059: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-12 20:03:37.671746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-12 20:03:37.671940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-12 20:03:37.671969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-12 20:03:37.964923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-12 20:03:37.964978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-12 20:03:37.964990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-12 20:03:37.965091: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-12 20:03:37.965136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (40763, 16)\n",
      "[Epoch 1/100, Step 79] Best valid loss updated: from inf to -17.254645\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 1/100, Step 79, ETA 21m 47.06s] epoch time: 13.2s; step time: 0.1334s (Â±0.3066s); train time: 11.06s; valid time: 2.142s; loss: -5.70127 (Â±8.76486); valid loss: -17.2546 (*)\n",
      "[Epoch 2/100, Step 158, ETA 18m 8.544s] Best valid loss updated: from -17.254645 to -25.155475\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 2/100, Step 158, ETA 19m 18.91s] epoch time: 10.45s; step time: 0.09888s (Â±0.002021s); train time: 8.217s; valid time: 2.231s; loss: -21.1637 (Â±2.66316); valid loss: -25.1555 (*)\n",
      "[Epoch 3/100, Step 237, ETA 17m 36.82s] Best valid loss updated: from -25.155475 to -25.667619\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 3/100, Step 237, ETA 18m 5.582s] epoch time: 9.923s; step time: 0.09948s (Â±0.001711s); train time: 8.315s; valid time: 1.607s; loss: -25.1929 (Â±1.67398); valid loss: -25.6676 (*)\n",
      "[Epoch 4/100, Step 316, ETA 17m 3.593s] Best valid loss updated: from -25.667619 to -27.831186\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 4/100, Step 316, ETA 17m 25.43s] epoch time: 9.985s; step time: 0.09937s (Â±0.00205s); train time: 8.359s; valid time: 1.625s; loss: -28.7398 (Â±1.5944); valid loss: -27.8312 (*)\n",
      "[Epoch 5/100, Step 395, ETA 16m 35.95s] Best valid loss updated: from -27.831186 to -31.041331\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 5/100, Step 395, ETA 17m 5.175s] epoch time: 10.4s; step time: 0.09803s (Â±0.001782s); train time: 8.098s; valid time: 2.297s; loss: -30.3679 (Â±1.93981); valid loss: -31.0413 (*)\n",
      "[Epoch 6/100, Step 474, ETA 16m 25.67s] Best valid loss updated: from -31.041331 to -33.447892\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 6/100, Step 474, ETA 16m 40.22s] epoch time: 9.886s; step time: 0.09804s (Â±0.001861s); train time: 8.251s; valid time: 1.635s; loss: -32.6714 (Â±1.4544); valid loss: -33.4479 (*)\n",
      "[Epoch 7/100, Step 553, ETA 16m 7.376s] epoch time: 8.969s; step time: 0.09804s (Â±0.002106s); train time: 8.195s; valid time: 0.7742s; loss: -32.5383 (Â±2.53638); valid loss: -30.7194\n",
      "[Epoch 8/100, Step 632, ETA 15m 39.48s] epoch time: 8.88s; step time: 0.09791s (Â±0.00159s); train time: 8.174s; valid time: 0.7063s; loss: -33.5343 (Â±1.66801); valid loss: -32.0001\n",
      "[Epoch 9/100, Step 711, ETA 15m 17.81s] Best valid loss updated: from -33.447892 to -33.870444\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 9/100, Step 711, ETA 15m 27.48s] epoch time: 10.03s; step time: 0.09893s (Â±0.001895s); train time: 8.307s; valid time: 1.727s; loss: -35.0477 (Â±1.36118); valid loss: -33.8704 (*)\n",
      "[Epoch 10/100, Step 790, ETA 15m 5.29s] epoch time: 8.859s; step time: 0.09849s (Â±0.002022s); train time: 8.143s; valid time: 0.7161s; loss: -35.4253 (Â±2.81317); valid loss: -32.2884\n",
      "[Epoch 11/100, Step 869, ETA 14m 47.44s] Best valid loss updated: from -33.870444 to -37.008799\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 11/100, Step 869, ETA 14m 55.57s] epoch time: 10.1s; step time: 0.09969s (Â±0.002409s); train time: 8.382s; valid time: 1.718s; loss: -35.4298 (Â±1.57152); valid loss: -37.0088 (*)\n",
      "[Epoch 12/100, Step 948, ETA 14m 38.16s] epoch time: 9.061s; step time: 0.09927s (Â±0.001854s); train time: 8.25s; valid time: 0.8108s; loss: -36.5216 (Â±1.67202); valid loss: -33.6661\n",
      "[Epoch 13/100, Step 1027, ETA 14m 22.3s] epoch time: 9.1s; step time: 0.09964s (Â±0.001838s); train time: 8.381s; valid time: 0.718s; loss: -36.791 (Â±1.78754); valid loss: -36.5909\n",
      "[Epoch 14/100, Step 1106, ETA 14m 7.191s] Best valid loss updated: from -37.008799 to -37.614733\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 14/100, Step 1106, ETA 14m 17.16s] epoch time: 10.69s; step time: 0.09937s (Â±0.001982s); train time: 8.285s; valid time: 2.402s; loss: -37.7049 (Â±1.24969); valid loss: -37.6147 (*)\n",
      "[Epoch 15/100, Step 1185, ETA 14m 1.305s] Best valid loss updated: from -37.614733 to -38.156484\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 15/100, Step 1185, ETA 14m 7.076s] epoch time: 9.945s; step time: 0.09891s (Â±0.001686s); train time: 8.215s; valid time: 1.73s; loss: -37.271 (Â±2.18276); valid loss: -38.1565 (*)\n",
      "[Epoch 16/100, Step 1264, ETA 13m 52.5s] Best valid loss updated: from -38.156484 to -39.900209\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 16/100, Step 1264, ETA 13m 58.05s] epoch time: 10.14s; step time: 0.09941s (Â±0.001751s); train time: 8.379s; valid time: 1.765s; loss: -38.2128 (Â±1.59852); valid loss: -39.9002 (*)\n",
      "[Epoch 17/100, Step 1343, ETA 13m 43.13s] epoch time: 8.964s; step time: 0.09855s (Â±0.002035s); train time: 8.178s; valid time: 0.7861s; loss: -38.6844 (Â±1.72202); valid loss: -36.9189\n",
      "[Epoch 18/100, Step 1422, ETA 13m 29.16s] epoch time: 9.028s; step time: 0.09889s (Â±0.001775s); train time: 8.311s; valid time: 0.7169s; loss: -37.1077 (Â±2.7002); valid loss: -38.3584\n",
      "[Epoch 19/100, Step 1501, ETA 13m 15.89s] epoch time: 9.068s; step time: 0.09936s (Â±0.001968s); train time: 8.291s; valid time: 0.7767s; loss: -38.6513 (Â±1.93323); valid loss: -38.411\n",
      "[Epoch 20/100, Step 1580, ETA 13m 2.786s] epoch time: 9.006s; step time: 0.09911s (Â±0.001712s); train time: 8.291s; valid time: 0.7156s; loss: -40.1428 (Â±1.74945); valid loss: -38.4596\n",
      "[Epoch 20/100, Step 1580, ETA 13m 2.787s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 1659, ETA 12m 50.53s] Best valid loss updated: from -39.900209 to -45.436623\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 21/100, Step 1659, ETA 12m 54.86s] epoch time: 10.28s; step time: 0.09953s (Â±0.002029s); train time: 8.345s; valid time: 1.934s; loss: -43.4108 (Â±1.55511); valid loss: -45.4366 (*)\n",
      "[Epoch 22/100, Step 1738, ETA 12m 41.9s] epoch time: 8.917s; step time: 0.0991s (Â±0.00175s); train time: 8.2s; valid time: 0.7172s; loss: -43.9432 (Â±1.95183); valid loss: -43.3927\n",
      "[Epoch 23/100, Step 1817, ETA 12m 29.85s] epoch time: 9.088s; step time: 0.09952s (Â±0.001559s); train time: 8.368s; valid time: 0.7195s; loss: -44.1762 (Â±2.05006); valid loss: -44.1855\n",
      "[Epoch 24/100, Step 1896, ETA 12m 17.82s] epoch time: 9.014s; step time: 0.09914s (Â±0.001674s); train time: 8.226s; valid time: 0.7882s; loss: -45.4455 (Â±0.881009); valid loss: -44.9304\n",
      "[Epoch 25/100, Step 1975, ETA 12m 6.29s] epoch time: 9.1s; step time: 0.0997s (Â±0.001736s); train time: 8.381s; valid time: 0.7184s; loss: -46.084 (Â±1.56381); valid loss: -42.8487\n",
      "[Epoch 26/100, Step 2054, ETA 11m 54.94s] epoch time: 9.099s; step time: 0.09963s (Â±0.00201s); train time: 8.298s; valid time: 0.8002s; loss: -44.7373 (Â±1.70611); valid loss: -44.9668\n",
      "[Epoch 27/100, Step 2133, ETA 11m 43.68s] Best valid loss updated: from -45.436623 to -46.007680\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 27/100, Step 2133, ETA 11m 46.56s] epoch time: 10.13s; step time: 0.09979s (Â±0.00189s); train time: 8.354s; valid time: 1.779s; loss: -46.0562 (Â±1.30333); valid loss: -46.0077 (*)\n",
      "[Epoch 28/100, Step 2212, ETA 11m 35.44s] epoch time: 9.118s; step time: 0.09961s (Â±0.002064s); train time: 8.355s; valid time: 0.7625s; loss: -43.9947 (Â±3.4463); valid loss: -43.4029\n",
      "[Epoch 29/100, Step 2291, ETA 11m 23.79s] epoch time: 8.846s; step time: 0.09876s (Â±0.001623s); train time: 8.14s; valid time: 0.706s; loss: -45.2745 (Â±1.80145); valid loss: -42.8254\n",
      "[Epoch 30/100, Step 2370, ETA 11m 12.89s] epoch time: 9.088s; step time: 0.0998s (Â±0.001851s); train time: 8.376s; valid time: 0.7125s; loss: -45.1299 (Â±2.83333); valid loss: -45.5055\n",
      "[Epoch 31/100, Step 2449, ETA 11m 1.794s] epoch time: 8.945s; step time: 0.09882s (Â±0.001833s); train time: 8.155s; valid time: 0.7893s; loss: -43.9102 (Â±4.11623); valid loss: -44.6525\n",
      "[Epoch 32/100, Step 2528, ETA 10m 51.1s] epoch time: 9.071s; step time: 0.0993s (Â±0.001551s); train time: 8.359s; valid time: 0.712s; loss: -45.1335 (Â±1.78704); valid loss: -45.4458\n",
      "[Epoch 33/100, Step 2607, ETA 10m 40.38s] Best valid loss updated: from -46.007680 to -47.889223\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 33/100, Step 2607, ETA 10m 43.86s] epoch time: 10.73s; step time: 0.09916s (Â±0.001954s); train time: 8.233s; valid time: 2.492s; loss: -45.9461 (Â±1.43839); valid loss: -47.8892 (*)\n",
      "[Epoch 34/100, Step 2686, ETA 10m 33.09s] epoch time: 9.014s; step time: 0.09966s (Â±0.005573s); train time: 8.3s; valid time: 0.7139s; loss: -45.6848 (Â±1.86799); valid loss: -46.9394\n",
      "[Epoch 35/100, Step 2765, ETA 10m 22.67s] epoch time: 9.145s; step time: 0.09965s (Â±0.001809s); train time: 8.346s; valid time: 0.7984s; loss: -45.6597 (Â±1.7599); valid loss: -46.4522\n",
      "[Epoch 36/100, Step 2844, ETA 10m 11.83s] epoch time: 8.869s; step time: 0.09889s (Â±0.001666s); train time: 8.155s; valid time: 0.7139s; loss: -46.4938 (Â±1.63252); valid loss: -45.1878\n",
      "[Epoch 37/100, Step 2923, ETA 10m 1.441s] epoch time: 9.074s; step time: 0.09968s (Â±0.001971s); train time: 8.363s; valid time: 0.7099s; loss: -47.3858 (Â±1.43023); valid loss: -46.893\n",
      "[Epoch 38/100, Step 3002, ETA 9m 50.97s] Best valid loss updated: from -47.889223 to -48.800169\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 38/100, Step 3002, ETA 9m 53.91s] epoch time: 10.78s; step time: 0.09935s (Â±0.001948s); train time: 8.197s; valid time: 2.582s; loss: -45.6921 (Â±2.07897); valid loss: -48.8002 (*)\n",
      "[Epoch 39/100, Step 3081, ETA 9m 43.66s] epoch time: 9.153s; step time: 0.1008s (Â±0.00886s); train time: 8.443s; valid time: 0.7097s; loss: -46.5269 (Â±2.09113); valid loss: -47.1048\n",
      "[Epoch 40/100, Step 3160, ETA 9m 33.33s] epoch time: 9.059s; step time: 0.09951s (Â±0.001522s); train time: 8.283s; valid time: 0.7758s; loss: -46.4783 (Â±2.06662); valid loss: -46.8168\n",
      "[Epoch 40/100, Step 3160, ETA 9m 33.33s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 3239, ETA 9m 22.94s] Best valid loss updated: from -48.800169 to -51.124426\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 41/100, Step 3239, ETA 9m 24.52s] epoch time: 10.07s; step time: 0.09917s (Â±0.001818s); train time: 8.263s; valid time: 1.805s; loss: -50.1326 (Â±1.13257); valid loss: -51.1244 (*)\n",
      "[Epoch 42/100, Step 3318, ETA 9m 14.31s] epoch time: 9.105s; step time: 0.09979s (Â±0.001709s); train time: 8.39s; valid time: 0.7151s; loss: -51.6625 (Â±0.953034); valid loss: -47.3827\n",
      "[Epoch 43/100, Step 3397, ETA 9m 3.857s] epoch time: 8.882s; step time: 0.099s (Â±0.00188s); train time: 8.164s; valid time: 0.7176s; loss: -50.2573 (Â±1.79645); valid loss: -49.9872\n",
      "[Epoch 44/100, Step 3476, ETA 8m 53.73s] Best valid loss updated: from -51.124426 to -52.475277\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 44/100, Step 3476, ETA 8m 55.18s] epoch time: 10.22s; step time: 0.09973s (Â±0.00195s); train time: 8.369s; valid time: 1.85s; loss: -51.7784 (Â±0.726687); valid loss: -52.4753 (*)\n",
      "[Epoch 45/100, Step 3555, ETA 8m 45s] epoch time: 9.044s; step time: 0.09934s (Â±0.002113s); train time: 8.249s; valid time: 0.7948s; loss: -50.8961 (Â±1.83814); valid loss: -48.7157\n",
      "[Epoch 46/100, Step 3634, ETA 8m 34.89s] epoch time: 9.064s; step time: 0.09956s (Â±0.001942s); train time: 8.351s; valid time: 0.7134s; loss: -51.0982 (Â±1.55744); valid loss: -48.2898\n",
      "[Epoch 47/100, Step 3713, ETA 8m 24.84s] epoch time: 9.079s; step time: 0.09939s (Â±0.001865s); train time: 8.301s; valid time: 0.7771s; loss: -50.6724 (Â±1.72242); valid loss: -49.3022\n",
      "[Epoch 48/100, Step 3792, ETA 8m 14.73s] Best valid loss updated: from -52.475277 to -53.340423\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 48/100, Step 3792, ETA 8m 16.04s] epoch time: 10.2s; step time: 0.09907s (Â±0.00162s); train time: 8.265s; valid time: 1.93s; loss: -51.3089 (Â±0.917433); valid loss: -53.3404 (*)\n",
      "[Epoch 49/100, Step 3871, ETA 8m 6.012s] epoch time: 9.067s; step time: 0.09959s (Â±0.002436s); train time: 8.36s; valid time: 0.7073s; loss: -50.2753 (Â±3.40421); valid loss: -51.5309\n",
      "[Epoch 50/100, Step 3950, ETA 7m 55.88s] epoch time: 8.924s; step time: 0.09914s (Â±0.001954s); train time: 8.184s; valid time: 0.7403s; loss: -52.7386 (Â±1.11541); valid loss: -51.8361\n",
      "[Epoch 51/100, Step 4029, ETA 7m 45.97s] epoch time: 9.113s; step time: 0.09966s (Â±0.001886s); train time: 8.394s; valid time: 0.7187s; loss: -50.6288 (Â±2.96619); valid loss: -52.1342\n",
      "[Epoch 52/100, Step 4108, ETA 7m 36s] epoch time: 9.015s; step time: 0.09917s (Â±0.001724s); train time: 8.23s; valid time: 0.7842s; loss: -52.0755 (Â±1.86198); valid loss: -49.8446\n",
      "[Epoch 53/100, Step 4187, ETA 7m 26.1s] epoch time: 9.049s; step time: 0.09931s (Â±0.001622s); train time: 8.336s; valid time: 0.7124s; loss: -51.3521 (Â±0.701237); valid loss: -51.3281\n",
      "[Epoch 54/100, Step 4266, ETA 7m 16.24s] epoch time: 9.055s; step time: 0.09941s (Â±0.001976s); train time: 8.283s; valid time: 0.7717s; loss: -52.4515 (Â±0.60206); valid loss: -53.2834\n",
      "[Epoch 55/100, Step 4345, ETA 7m 6.365s] epoch time: 9.003s; step time: 0.09915s (Â±0.00145s); train time: 8.28s; valid time: 0.7235s; loss: -51.2002 (Â±1.58655); valid loss: -52.5608\n",
      "[Epoch 56/100, Step 4424, ETA 6m 56.61s] epoch time: 9.118s; step time: 0.09976s (Â±0.002157s); train time: 8.352s; valid time: 0.7666s; loss: -51.8831 (Â±1.67079); valid loss: -51.9099\n",
      "[Epoch 57/100, Step 4503, ETA 6m 46.75s] epoch time: 8.945s; step time: 0.0991s (Â±0.001657s); train time: 8.231s; valid time: 0.7136s; loss: -50.6871 (Â±1.71431); valid loss: -50.6924\n",
      "[Epoch 58/100, Step 4582, ETA 6m 37.02s] epoch time: 9.092s; step time: 0.09975s (Â±0.001941s); train time: 8.385s; valid time: 0.7066s; loss: -50.5932 (Â±3.15658); valid loss: -48.6282\n",
      "[Epoch 59/100, Step 4661, ETA 6m 27.21s] epoch time: 8.931s; step time: 0.09912s (Â±0.001982s); train time: 8.178s; valid time: 0.7534s; loss: -50.7942 (Â±2.18953); valid loss: -49.2141\n",
      "[Epoch 60/100, Step 4740, ETA 6m 17.56s] epoch time: 9.135s; step time: 0.09996s (Â±0.001808s); train time: 8.419s; valid time: 0.7166s; loss: -51.5438 (Â±2.21668); valid loss: -50.4993\n",
      "[Epoch 60/100, Step 4740, ETA 6m 17.56s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 4819, ETA 6m 7.835s] Best valid loss updated: from -53.340423 to -55.009524\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 61/100, Step 4819, ETA 6m 9.103s] epoch time: 10.98s; step time: 0.09926s (Â±0.001768s); train time: 8.216s; valid time: 2.76s; loss: -54.2788 (Â±1.37814); valid loss: -55.0095 (*)\n",
      "[Epoch 62/100, Step 4898, ETA 5m 59.41s] epoch time: 9.09s; step time: 0.1003s (Â±0.008397s); train time: 8.377s; valid time: 0.7125s; loss: -54.9462 (Â±0.913887); valid loss: -54.6449\n",
      "[Epoch 63/100, Step 4977, ETA 5m 49.74s] Best valid loss updated: from -55.009524 to -55.634263\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 63/100, Step 4977, ETA 5m 50.5s] epoch time: 10.38s; step time: 0.09941s (Â±0.001795s); train time: 8.32s; valid time: 2.063s; loss: -55.5146 (Â±0.605167); valid loss: -55.6343 (*)\n",
      "[Epoch 64/100, Step 5056, ETA 5m 40.68s] Best valid loss updated: from -55.634263 to -56.121901\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 64/100, Step 5056, ETA 5m 41.81s] epoch time: 10.87s; step time: 0.09889s (Â±0.001858s); train time: 8.149s; valid time: 2.718s; loss: -56.1283 (Â±0.633883); valid loss: -56.1219 (*)\n",
      "[Epoch 65/100, Step 5135, ETA 5m 32.12s] Best valid loss updated: from -56.121901 to -56.440130\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 65/100, Step 5135, ETA 5m 32.81s] epoch time: 10.41s; step time: 0.1004s (Â±0.008028s); train time: 8.425s; valid time: 1.986s; loss: -54.6196 (Â±2.50538); valid loss: -56.4401 (*)\n",
      "[Epoch 66/100, Step 5214, ETA 5m 23.06s] epoch time: 9.053s; step time: 0.09919s (Â±0.002102s); train time: 8.275s; valid time: 0.7777s; loss: -55.5609 (Â±1.53874); valid loss: -55.5536\n",
      "[Epoch 67/100, Step 5293, ETA 5m 13.28s] epoch time: 8.927s; step time: 0.09881s (Â±0.001625s); train time: 8.223s; valid time: 0.7045s; loss: -55.6122 (Â±0.838118); valid loss: -56.0149\n",
      "[Epoch 68/100, Step 5372, ETA 5m 3.594s] epoch time: 9.085s; step time: 0.09945s (Â±0.001769s); train time: 8.337s; valid time: 0.7477s; loss: -56.3635 (Â±0.617979); valid loss: -55.9438\n",
      "[Epoch 69/100, Step 5451, ETA 4m 53.82s] epoch time: 8.838s; step time: 0.09868s (Â±0.001672s); train time: 8.129s; valid time: 0.7089s; loss: -55.5533 (Â±1.69187); valid loss: -54.6096\n",
      "[Epoch 70/100, Step 5530, ETA 4m 44.16s] epoch time: 9.064s; step time: 0.09956s (Â±0.001893s); train time: 8.358s; valid time: 0.7062s; loss: -56.1053 (Â±0.974567); valid loss: -56.2429\n",
      "[Epoch 71/100, Step 5609, ETA 4m 34.47s] epoch time: 8.943s; step time: 0.09888s (Â±0.001944s); train time: 8.155s; valid time: 0.7877s; loss: -56.5605 (Â±0.709808); valid loss: -56.1003\n",
      "[Epoch 72/100, Step 5688, ETA 4m 24.85s] epoch time: 9.062s; step time: 0.09949s (Â±0.001765s); train time: 8.352s; valid time: 0.7103s; loss: -56.7291 (Â±2.1035); valid loss: -42.6645\n",
      "[Epoch 73/100, Step 5767, ETA 4m 15.22s] epoch time: 9.003s; step time: 0.09905s (Â±0.001792s); train time: 8.213s; valid time: 0.7897s; loss: -51.5417 (Â±4.17214); valid loss: -54.3941\n",
      "[Epoch 74/100, Step 5846, ETA 4m 5.626s] epoch time: 9.04s; step time: 0.09934s (Â±0.001607s); train time: 8.319s; valid time: 0.7212s; loss: -52.8678 (Â±4.98291); valid loss: -53.1073\n",
      "[Epoch 75/100, Step 5925, ETA 3m 56.05s] epoch time: 9.062s; step time: 0.09922s (Â±0.001682s); train time: 8.295s; valid time: 0.7674s; loss: -55.3341 (Â±1.97206); valid loss: -55.0785\n",
      "[Epoch 76/100, Step 6004, ETA 3m 46.47s] epoch time: 8.993s; step time: 0.09944s (Â±0.001583s); train time: 8.279s; valid time: 0.7135s; loss: -56.2546 (Â±0.684015); valid loss: -56.2865\n",
      "[Epoch 77/100, Step 6083, ETA 3m 36.93s] Best valid loss updated: from -56.440130 to -56.806716\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 77/100, Step 6083, ETA 3m 37.32s] epoch time: 10.41s; step time: 0.09976s (Â±0.002116s); train time: 8.357s; valid time: 2.056s; loss: -57.0528 (Â±0.713508); valid loss: -56.8067 (*)\n",
      "[Epoch 78/100, Step 6162, ETA 3m 27.72s] epoch time: 8.909s; step time: 0.09916s (Â±0.001691s); train time: 8.177s; valid time: 0.7326s; loss: -56.1031 (Â±1.22796); valid loss: -56.1389\n",
      "[Epoch 79/100, Step 6241, ETA 3m 18.19s] epoch time: 9.092s; step time: 0.09967s (Â±0.00217s); train time: 8.381s; valid time: 0.7111s; loss: -56.4709 (Â±0.71725); valid loss: -56.0246\n",
      "[Epoch 80/100, Step 6320, ETA 3m 8.634s] epoch time: 8.974s; step time: 0.09899s (Â±0.001789s); train time: 8.188s; valid time: 0.7851s; loss: -55.4235 (Â±4.1299); valid loss: -47.8738\n",
      "[Epoch 80/100, Step 6320, ETA 3m 8.634s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 6399, ETA 2m 59.12s] Best valid loss updated: from -56.806716 to -57.880271\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 81/100, Step 6399, ETA 2m 59.43s] epoch time: 10.42s; step time: 0.09958s (Â±0.002184s); train time: 8.347s; valid time: 2.072s; loss: -56.9768 (Â±2.24174); valid loss: -57.8803 (*)\n",
      "[Epoch 82/100, Step 6478, ETA 2m 49.91s] Best valid loss updated: from -57.880271 to -58.086528\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 82/100, Step 6478, ETA 2m 50.28s] epoch time: 10.75s; step time: 0.09921s (Â±0.002245s); train time: 8.284s; valid time: 2.471s; loss: -58.659 (Â±0.737528); valid loss: -58.0865 (*)\n",
      "[Epoch 83/100, Step 6557, ETA 2m 40.71s] Best valid loss updated: from -58.086528 to -58.536102\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 83/100, Step 6557, ETA 2m 41.12s] epoch time: 10.92s; step time: 0.09981s (Â±0.006996s); train time: 8.216s; valid time: 2.708s; loss: -59.0026 (Â±0.66463); valid loss: -58.5361 (*)\n",
      "[Epoch 84/100, Step 6636, ETA 2m 31.57s] epoch time: 9.097s; step time: 0.09991s (Â±0.006883s); train time: 8.386s; valid time: 0.7115s; loss: -59.3611 (Â±0.783368); valid loss: -58.3121\n",
      "[Epoch 85/100, Step 6715, ETA 2m 22.01s] Best valid loss updated: from -58.536102 to -59.031984\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 85/100, Step 6715, ETA 2m 22.39s] epoch time: 11.16s; step time: 0.09904s (Â±0.00191s); train time: 8.219s; valid time: 2.943s; loss: -58.9793 (Â±1.26131); valid loss: -59.032 (*)\n",
      "[Epoch 86/100, Step 6794, ETA 2m 12.82s] epoch time: 8.976s; step time: 0.0998s (Â±0.00893s); train time: 8.266s; valid time: 0.7095s; loss: -58.9561 (Â±1.18765); valid loss: -57.5284\n",
      "[Epoch 87/100, Step 6873, ETA 2m 3.268s] Best valid loss updated: from -59.031984 to -59.033743\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 87/100, Step 6873, ETA 2m 3.481s] epoch time: 10.49s; step time: 0.09943s (Â±0.002001s); train time: 8.362s; valid time: 2.129s; loss: -59.4225 (Â±1.08704); valid loss: -59.0337 (*)\n",
      "[Epoch 88/100, Step 6952, ETA 1m 53.9s] epoch time: 8.9s; step time: 0.09834s (Â±0.001714s); train time: 8.124s; valid time: 0.7766s; loss: -59.1849 (Â±0.795937); valid loss: -58.5617\n",
      "[Epoch 89/100, Step 7031, ETA 1m 44.35s] epoch time: 9.035s; step time: 0.09904s (Â±0.001939s); train time: 8.325s; valid time: 0.7105s; loss: -59.5396 (Â±0.699982); valid loss: -58.669\n",
      "[Epoch 90/100, Step 7110, ETA 1m 34.82s] epoch time: 9.037s; step time: 0.09891s (Â±0.001839s); train time: 8.243s; valid time: 0.794s; loss: -59.7539 (Â±0.760775); valid loss: -59.0111\n",
      "[Epoch 91/100, Step 7189, ETA 1m 25.29s] epoch time: 9.036s; step time: 0.09915s (Â±0.001727s); train time: 8.324s; valid time: 0.7116s; loss: -60.0017 (Â±0.891954); valid loss: -58.795\n",
      "[Epoch 92/100, Step 7268, ETA 1m 15.78s] Best valid loss updated: from -59.033743 to -59.515533\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 92/100, Step 7268, ETA 1m 15.95s] epoch time: 11.01s; step time: 0.09928s (Â±0.001753s); train time: 8.292s; valid time: 2.717s; loss: -60.1761 (Â±0.732244); valid loss: -59.5155 (*)\n",
      "[Epoch 93/100, Step 7347, ETA 1m 6.411s] epoch time: 8.922s; step time: 0.09939s (Â±0.007496s); train time: 8.208s; valid time: 0.713s; loss: -59.7101 (Â±0.938165); valid loss: -58.8703\n",
      "[Epoch 94/100, Step 7426, ETA 56.9s] epoch time: 9.091s; step time: 0.09967s (Â±0.001894s); train time: 8.377s; valid time: 0.7136s; loss: -60.0217 (Â±0.847064); valid loss: -59.1364\n",
      "[Epoch 95/100, Step 7505, ETA 47.39s] Best valid loss updated: from -59.515533 to -59.536459\n",
      "Model saved at results/tuned_model_st8000_2_exp4_1p_2023-12-12_20-03-30.\n",
      "[Epoch 95/100, Step 7505, ETA 47.51s] epoch time: 11.3s; step time: 0.09893s (Â±0.001794s); train time: 8.183s; valid time: 3.121s; loss: -60.3606 (Â±0.842106); valid loss: -59.5365 (*)\n",
      "[Epoch 96/100, Step 7584, ETA 37.99s] epoch time: 9.023s; step time: 0.09936s (Â±0.007244s); train time: 8.303s; valid time: 0.7201s; loss: -59.8324 (Â±1.37459); valid loss: -57.7845\n",
      "[Epoch 97/100, Step 7663, ETA 28.48s] epoch time: 9.112s; step time: 0.09934s (Â±0.001998s); train time: 8.324s; valid time: 0.7884s; loss: -59.3606 (Â±0.90328); valid loss: -58.4018\n",
      "[Epoch 98/100, Step 7742, ETA 18.97s] epoch time: 8.918s; step time: 0.09886s (Â±0.00164s); train time: 8.21s; valid time: 0.7079s; loss: -59.8614 (Â±0.812938); valid loss: -59.1503\n",
      "[Epoch 99/100, Step 7821, ETA 9.484s] epoch time: 9.104s; step time: 0.09975s (Â±0.002022s); train time: 8.393s; valid time: 0.7111s; loss: -60.1888 (Â±0.765593); valid loss: -59.1029\n",
      "[Epoch 100/100, Step 7900, ETA 0s] epoch time: 8.92s; step time: 0.09905s (Â±0.001767s); train time: 8.196s; valid time: 0.7235s; loss: -59.8978 (Â±1.44669); valid loss: -57.4604\n",
      "[Epoch 100/100, Step 7900, ETA 0s] Learning rate decreased to 1.5625e-06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpiixq6f4q/variables.dat-7505\n",
      "2023-12-12 20:19:26,441 [INFO] tensorflow: Restoring parameters from /tmp/tmpiixq6f4q/variables.dat-7505\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'best_valid_loss': -59.53645886263899,\n",
      " 'pred_time': 0.03277240054510128,\n",
      " 'pred_total_time': 109.41518473625183,\n",
      " 'train_time': 9.485841386318207,\n",
      " 'valid_time': 0.03272076570987702}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp5zb_th0swandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmprs2t8ip0wandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpg0nv34olwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpprnsv8l4wandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp4_0_1p --train_portion=0.001 --initial_lr=0.00005"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlXRM8mqtkiq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702413320634,
     "user_tz": 300,
     "elapsed": 290661,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "7a5c2f99-a068-4035-d48a-3d3121a38f4d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "======================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': None,\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'results/tuned_model_st8000_2_exp4_0_1p',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': 0.001,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (5095, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 20:30:41,153 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 20:30:45.272899: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-12 20:30:45.480534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-12 20:30:45.480713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-12 20:30:45.480740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-12 20:30:45.759000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-12 20:30:45.759052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-12 20:30:45.759063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-12 20:30:45.759153: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-12 20:30:45.759198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (4076, 16)\n",
      "[Epoch 1/100, Step 7] Best valid loss updated: from inf to 6.657096\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 1/100, Step 7, ETA 10m 58.7s] epoch time: 6.652s; step time: 0.695s (Â±1.462s); train time: 4.916s; valid time: 1.736s; loss: 7.29636 (Â±0.243795); valid loss: 6.6571 (*)\n",
      "[Epoch 2/100, Step 14, ETA 6m 2.869s] Best valid loss updated: from 6.657096 to 4.920872\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 2/100, Step 14, ETA 6m 46.65s] epoch time: 1.645s; step time: 0.0932s (Â±0.002504s); train time: 0.6812s; valid time: 0.9634s; loss: 6.16309 (Â±0.439063); valid loss: 4.92087 (*)\n",
      "[Epoch 3/100, Step 21, ETA 4m 52.4s] Best valid loss updated: from 4.920872 to 1.591800\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 3/100, Step 21, ETA 5m 22.3s] epoch time: 1.668s; step time: 0.09245s (Â±0.002275s); train time: 0.6769s; valid time: 0.9912s; loss: 3.7991 (Â±0.917026); valid loss: 1.5918 (*)\n",
      "[Epoch 4/100, Step 28, ETA 4m 17.21s] Best valid loss updated: from 1.591800 to -1.942248\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 4/100, Step 28, ETA 4m 39.78s] epoch time: 1.689s; step time: 0.0933s (Â±0.003241s); train time: 0.6817s; valid time: 1.007s; loss: 0.670536 (Â±0.842849); valid loss: -1.94225 (*)\n",
      "[Epoch 5/100, Step 35, ETA 3m 55.81s] Best valid loss updated: from -1.942248 to -8.080824\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 5/100, Step 35, ETA 4m 13.77s] epoch time: 1.698s; step time: 0.09357s (Â±0.002121s); train time: 0.686s; valid time: 1.012s; loss: -3.57997 (Â±1.47305); valid loss: -8.08082 (*)\n",
      "[Epoch 6/100, Step 42, ETA 3m 40.94s] epoch time: 0.7459s; step time: 0.0927s (Â±0.002066s); train time: 0.6779s; valid time: 0.06794s; loss: -7.93795 (Â±1.02536); valid loss: -6.47818\n",
      "[Epoch 7/100, Step 49, ETA 3m 17.51s] Best valid loss updated: from -8.080824 to -10.299120\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 7/100, Step 49, ETA 3m 33.78s] epoch time: 1.988s; step time: 0.09494s (Â±0.003453s); train time: 0.6931s; valid time: 1.294s; loss: -6.43503 (Â±2.53616); valid loss: -10.2991 (*)\n",
      "[Epoch 8/100, Step 56, ETA 3m 14.21s] Best valid loss updated: from -10.299120 to -13.690332\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 8/100, Step 56, ETA 3m 33.2s] epoch time: 2.447s; step time: 0.09534s (Â±0.002648s); train time: 0.7183s; valid time: 1.729s; loss: -10.077 (Â±0.8025); valid loss: -13.6903 (*)\n",
      "[Epoch 9/100, Step 63, ETA 3m 15.43s] Best valid loss updated: from -13.690332 to -16.446836\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 9/100, Step 63, ETA 3m 32.03s] epoch time: 2.43s; step time: 0.09359s (Â±0.00183s); train time: 0.7109s; valid time: 1.718s; loss: -12.8245 (Â±0.684134); valid loss: -16.4468 (*)\n",
      "[Epoch 10/100, Step 70, ETA 3m 15.8s] Best valid loss updated: from -16.446836 to -17.553227\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 10/100, Step 70, ETA 3m 24.65s] epoch time: 1.768s; step time: 0.09524s (Â±0.002661s); train time: 0.7136s; valid time: 1.054s; loss: -14.9349 (Â±0.726187); valid loss: -17.5532 (*)\n",
      "[Epoch 11/100, Step 77, ETA 3m 10.05s] Best valid loss updated: from -17.553227 to -19.810547\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 11/100, Step 77, ETA 3m 18.47s] epoch time: 1.791s; step time: 0.09297s (Â±0.001575s); train time: 0.6799s; valid time: 1.111s; loss: -17.2971 (Â±0.958979); valid loss: -19.8105 (*)\n",
      "[Epoch 12/100, Step 84, ETA 3m 5.392s] Best valid loss updated: from -19.810547 to -22.052296\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 12/100, Step 84, ETA 3m 13.29s] epoch time: 1.827s; step time: 0.09293s (Â±0.002528s); train time: 0.6789s; valid time: 1.147s; loss: -19.5633 (Â±0.470608); valid loss: -22.0523 (*)\n",
      "[Epoch 13/100, Step 91, ETA 3m 1.442s] epoch time: 0.7539s; step time: 0.09357s (Â±0.002598s); train time: 0.6837s; valid time: 0.07008s; loss: -20.6358 (Â±0.796355); valid loss: -20.7474\n",
      "[Epoch 14/100, Step 98, ETA 2m 51.21s] Best valid loss updated: from -22.052296 to -22.926879\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 14/100, Step 98, ETA 2m 57.64s] epoch time: 1.806s; step time: 0.09466s (Â±0.002772s); train time: 0.6906s; valid time: 1.115s; loss: -21.5709 (Â±0.945212); valid loss: -22.9269 (*)\n",
      "[Epoch 15/100, Step 105, ETA 2m 48.14s] Best valid loss updated: from -22.926879 to -24.971941\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 15/100, Step 105, ETA 2m 54.56s] epoch time: 1.886s; step time: 0.09346s (Â±0.002763s); train time: 0.6842s; valid time: 1.201s; loss: -22.6825 (Â±0.504929); valid loss: -24.9719 (*)\n",
      "[Epoch 16/100, Step 112, ETA 2m 45.69s] Best valid loss updated: from -24.971941 to -26.873792\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 16/100, Step 112, ETA 2m 54.79s] epoch time: 2.488s; step time: 0.09366s (Â±0.002275s); train time: 0.686s; valid time: 1.801s; loss: -23.9968 (Â±0.584916); valid loss: -26.8738 (*)\n",
      "[Epoch 17/100, Step 119, ETA 2m 46.5s] epoch time: 0.8084s; step time: 0.09662s (Â±0.003834s); train time: 0.7266s; valid time: 0.0817s; loss: -24.8876 (Â±1.11866); valid loss: -22.5152\n",
      "[Epoch 18/100, Step 126, ETA 2m 38.95s] epoch time: 0.7897s; step time: 0.09474s (Â±0.001667s); train time: 0.7105s; valid time: 0.07905s; loss: -21.2991 (Â±4.04189); valid loss: -22.8359\n",
      "[Epoch 19/100, Step 133, ETA 2m 32.12s] epoch time: 0.79s; step time: 0.09468s (Â±0.001707s); train time: 0.7113s; valid time: 0.07858s; loss: -23.2771 (Â±0.887587); valid loss: -24.53\n",
      "[Epoch 20/100, Step 140, ETA 2m 25.92s] epoch time: 0.7966s; step time: 0.0954s (Â±0.001535s); train time: 0.721s; valid time: 0.07548s; loss: -23.8616 (Â±0.798574); valid loss: -25.228\n",
      "[Epoch 20/100, Step 140, ETA 2m 25.92s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 147, ETA 2m 20.21s] Best valid loss updated: from -26.873792 to -27.480520\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 21/100, Step 147, ETA 2m 25.51s] epoch time: 2.199s; step time: 0.09399s (Â±0.002057s); train time: 0.7153s; valid time: 1.484s; loss: -24.9117 (Â±0.748698); valid loss: -27.4805 (*)\n",
      "[Epoch 22/100, Step 154, ETA 2m 19.82s] epoch time: 0.7566s; step time: 0.09365s (Â±0.002332s); train time: 0.6842s; valid time: 0.07235s; loss: -25.7852 (Â±0.731654); valid loss: -27.0086\n",
      "[Epoch 23/100, Step 161, ETA 2m 14.6s] epoch time: 0.7668s; step time: 0.09463s (Â±0.002596s); train time: 0.6951s; valid time: 0.07158s; loss: -25.8684 (Â±1.07803); valid loss: -24.0856\n",
      "[Epoch 24/100, Step 168, ETA 2m 9.73s] Best valid loss updated: from -27.480520 to -29.431832\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 24/100, Step 168, ETA 2m 13.42s] epoch time: 1.927s; step time: 0.09508s (Â±0.00199s); train time: 0.6934s; valid time: 1.233s; loss: -26.2999 (Â±1.20452); valid loss: -29.4318 (*)\n",
      "[Epoch 25/100, Step 175, ETA 2m 8.668s] epoch time: 0.7567s; step time: 0.09368s (Â±0.002867s); train time: 0.6865s; valid time: 0.06997s; loss: -27.2264 (Â±1.07536); valid loss: -28.7108\n",
      "[Epoch 26/100, Step 182, ETA 2m 4.248s] epoch time: 0.7651s; step time: 0.095s (Â±0.002787s); train time: 0.6942s; valid time: 0.07075s; loss: -27.5831 (Â±0.873163); valid loss: -29.2529\n",
      "[Epoch 27/100, Step 189, ETA 2m 0.1073s] Best valid loss updated: from -29.431832 to -31.369578\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 27/100, Step 189, ETA 2m 3.306s] epoch time: 1.951s; step time: 0.09546s (Â±0.002788s); train time: 0.6979s; valid time: 1.252s; loss: -28.6446 (Â±0.415611); valid loss: -31.3696 (*)\n",
      "[Epoch 28/100, Step 196, ETA 1m 59.25s] epoch time: 0.7696s; step time: 0.09398s (Â±0.002776s); train time: 0.6886s; valid time: 0.08088s; loss: -29.9272 (Â±0.494509); valid loss: -31.1054\n",
      "[Epoch 29/100, Step 203, ETA 1m 55.41s] epoch time: 0.7633s; step time: 0.09512s (Â±0.002828s); train time: 0.695s; valid time: 0.06817s; loss: -30.2151 (Â±0.662907); valid loss: -30.3595\n",
      "[Epoch 30/100, Step 210, ETA 1m 51.79s] Best valid loss updated: from -31.369578 to -31.436688\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 30/100, Step 210, ETA 1m 56.42s] epoch time: 2.751s; step time: 0.09503s (Â±0.001986s); train time: 0.6979s; valid time: 2.053s; loss: -29.6671 (Â±0.737914); valid loss: -31.4367 (*)\n",
      "[Epoch 31/100, Step 217, ETA 1m 53.05s] epoch time: 0.8967s; step time: 0.1091s (Â±0.02337s); train time: 0.8165s; valid time: 0.08009s; loss: -30.399 (Â±0.283274); valid loss: -31.26\n",
      "[Epoch 32/100, Step 224, ETA 1m 49.61s] Best valid loss updated: from -31.436688 to -33.673909\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 32/100, Step 224, ETA 1m 53.84s] epoch time: 2.783s; step time: 0.09496s (Â±0.002265s); train time: 0.716s; valid time: 2.067s; loss: -30.5553 (Â±0.605152); valid loss: -33.6739 (*)\n",
      "[Epoch 33/100, Step 231, ETA 1m 50.52s] epoch time: 0.8613s; step time: 0.1061s (Â±0.02309s); train time: 0.7908s; valid time: 0.07042s; loss: -28.529 (Â±2.21168); valid loss: -31.1221\n",
      "[Epoch 34/100, Step 238, ETA 1m 47.15s] epoch time: 0.7633s; step time: 0.09445s (Â±0.00215s); train time: 0.6912s; valid time: 0.07208s; loss: -29.4067 (Â±0.729017); valid loss: -31.2057\n",
      "[Epoch 35/100, Step 245, ETA 1m 43.92s] epoch time: 0.7581s; step time: 0.09445s (Â±0.001639s); train time: 0.6898s; valid time: 0.06808s; loss: -30.1673 (Â±0.619838); valid loss: -31.8655\n",
      "[Epoch 36/100, Step 252, ETA 1m 40.85s] epoch time: 0.771s; step time: 0.09565s (Â±0.001633s); train time: 0.7018s; valid time: 0.06898s; loss: -31.2666 (Â±0.506314); valid loss: -33.2065\n",
      "[Epoch 37/100, Step 259, ETA 1m 37.89s] epoch time: 0.7636s; step time: 0.09484s (Â±0.001528s); train time: 0.6929s; valid time: 0.0707s; loss: -31.6999 (Â±0.633988); valid loss: -31.3873\n",
      "[Epoch 38/100, Step 266, ETA 1m 35.05s] epoch time: 0.7665s; step time: 0.09503s (Â±0.002314s); train time: 0.6957s; valid time: 0.07078s; loss: -31.1612 (Â±0.866118); valid loss: -33.5256\n",
      "[Epoch 39/100, Step 273, ETA 1m 32.32s] epoch time: 0.7643s; step time: 0.09508s (Â±0.001827s); train time: 0.6943s; valid time: 0.06996s; loss: -31.2098 (Â±1.24193); valid loss: -33.4517\n",
      "[Epoch 40/100, Step 280, ETA 1m 29.7s] epoch time: 0.7735s; step time: 0.09567s (Â±0.002001s); train time: 0.7016s; valid time: 0.07175s; loss: -31.6034 (Â±0.596551); valid loss: -32.4191\n",
      "[Epoch 40/100, Step 280, ETA 1m 29.7s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 287, ETA 1m 27.15s] Best valid loss updated: from -33.673909 to -34.161137\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 41/100, Step 287, ETA 1m 28.96s] epoch time: 2.017s; step time: 0.09527s (Â±0.001291s); train time: 0.6957s; valid time: 1.321s; loss: -32.423 (Â±0.642765); valid loss: -34.1611 (*)\n",
      "[Epoch 42/100, Step 294, ETA 1m 26.41s] Best valid loss updated: from -34.161137 to -35.890392\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 42/100, Step 294, ETA 1m 28.26s] epoch time: 2.092s; step time: 0.09441s (Â±0.002133s); train time: 0.6902s; valid time: 1.402s; loss: -33.4503 (Â±0.387554); valid loss: -35.8904 (*)\n",
      "[Epoch 43/100, Step 301, ETA 1m 25.75s] Best valid loss updated: from -35.890392 to -35.935326\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 43/100, Step 301, ETA 1m 28.47s] epoch time: 2.831s; step time: 0.09513s (Â±0.00363s); train time: 0.6997s; valid time: 2.131s; loss: -34.4342 (Â±0.186594); valid loss: -35.9353 (*)\n",
      "[Epoch 44/100, Step 308, ETA 1m 26.08s] Best valid loss updated: from -35.935326 to -36.305405\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 44/100, Step 308, ETA 1m 28.79s] epoch time: 3.022s; step time: 0.1089s (Â±0.02144s); train time: 0.8159s; valid time: 2.206s; loss: -34.653 (Â±0.265588); valid loss: -36.3054 (*)\n",
      "[Epoch 45/100, Step 315, ETA 1m 26.36s] epoch time: 0.8885s; step time: 0.1095s (Â±0.02195s); train time: 0.8177s; valid time: 0.07073s; loss: -34.8293 (Â±0.246679); valid loss: -35.4369\n",
      "[Epoch 46/100, Step 322, ETA 1m 23.84s] Best valid loss updated: from -36.305405 to -36.775030\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 46/100, Step 322, ETA 1m 25.47s] epoch time: 2.15s; step time: 0.09496s (Â±0.001611s); train time: 0.6941s; valid time: 1.456s; loss: -34.8486 (Â±0.45177); valid loss: -36.775 (*)\n",
      "[Epoch 47/100, Step 329, ETA 1m 22.96s] epoch time: 0.7581s; step time: 0.09372s (Â±0.001884s); train time: 0.6878s; valid time: 0.07018s; loss: -35.1857 (Â±0.537101); valid loss: -36.4606\n",
      "[Epoch 48/100, Step 336, ETA 1m 20.52s] epoch time: 0.7635s; step time: 0.09449s (Â±0.001882s); train time: 0.6907s; valid time: 0.07276s; loss: -34.8601 (Â±0.562681); valid loss: -36.7189\n",
      "[Epoch 49/100, Step 343, ETA 1m 18.16s] epoch time: 0.7661s; step time: 0.09489s (Â±0.00163s); train time: 0.6932s; valid time: 0.07273s; loss: -35.5569 (Â±0.283012); valid loss: -36.3034\n",
      "[Epoch 50/100, Step 350, ETA 1m 15.86s] Best valid loss updated: from -36.775030 to -37.717059\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 50/100, Step 350, ETA 1m 17.29s] epoch time: 2.192s; step time: 0.09501s (Â±0.001716s); train time: 0.6984s; valid time: 1.493s; loss: -34.9794 (Â±0.696465); valid loss: -37.7171 (*)\n",
      "[Epoch 51/100, Step 357, ETA 1m 14.99s] epoch time: 0.761s; step time: 0.094s (Â±0.002305s); train time: 0.6903s; valid time: 0.07061s; loss: -35.2707 (Â±0.826066); valid loss: -37.3097\n",
      "[Epoch 52/100, Step 364, ETA 1m 12.76s] epoch time: 0.7771s; step time: 0.09581s (Â±0.001833s); train time: 0.706s; valid time: 0.07098s; loss: -35.5697 (Â±0.353015); valid loss: -36.7258\n",
      "[Epoch 53/100, Step 371, ETA 1m 10.59s] epoch time: 0.7727s; step time: 0.09566s (Â±0.001778s); train time: 0.7006s; valid time: 0.07191s; loss: -35.652 (Â±0.307192); valid loss: -37.294\n",
      "[Epoch 54/100, Step 378, ETA 1m 8.465s] epoch time: 0.7708s; step time: 0.09543s (Â±0.001723s); train time: 0.6988s; valid time: 0.07191s; loss: -36.1248 (Â±0.595876); valid loss: -37.3095\n",
      "[Epoch 55/100, Step 385, ETA 1m 6.401s] Best valid loss updated: from -37.717059 to -37.758441\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 55/100, Step 385, ETA 1m 8.294s] epoch time: 3.096s; step time: 0.09489s (Â±0.001423s); train time: 0.7061s; valid time: 2.389s; loss: -35.836 (Â±0.668974); valid loss: -37.7584 (*)\n",
      "[Epoch 56/100, Step 392, ETA 1m 6.291s] Best valid loss updated: from -37.758441 to -37.792637\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 56/100, Step 392, ETA 1m 8.094s] epoch time: 3.192s; step time: 0.1093s (Â±0.02041s); train time: 0.8195s; valid time: 2.372s; loss: -36.7057 (Â±0.274099); valid loss: -37.7926 (*)\n",
      "[Epoch 57/100, Step 399, ETA 1m 6.01s] Best valid loss updated: from -37.792637 to -37.827953\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 57/100, Step 399, ETA 1m 7.15s] epoch time: 2.345s; step time: 0.1051s (Â±0.02258s); train time: 0.7672s; valid time: 1.578s; loss: -36.8432 (Â±0.224573); valid loss: -37.828 (*)\n",
      "[Epoch 58/100, Step 406, ETA 1m 5.004s] epoch time: 0.7541s; step time: 0.09316s (Â±0.002831s); train time: 0.6841s; valid time: 0.06985s; loss: -36.4324 (Â±0.837231); valid loss: -37.62\n",
      "[Epoch 59/100, Step 413, ETA 1m 2.913s] epoch time: 0.7656s; step time: 0.09492s (Â±0.003718s); train time: 0.6976s; valid time: 0.06798s; loss: -36.3729 (Â±0.529179); valid loss: -37.6847\n",
      "[Epoch 60/100, Step 420, ETA 1m 0.8744s] epoch time: 0.7777s; step time: 0.09625s (Â±0.002129s); train time: 0.7059s; valid time: 0.07167s; loss: -36.6042 (Â±0.233331); valid loss: -37.7574\n",
      "[Epoch 60/100, Step 420, ETA 1m 0.8744s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 427, ETA 58.87s] Best valid loss updated: from -37.827953 to -39.354127\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 61/100, Step 427, ETA 59.9s] epoch time: 2.379s; step time: 0.09544s (Â±0.00218s); train time: 0.6974s; valid time: 1.681s; loss: -36.6885 (Â±1.08556); valid loss: -39.3541 (*)\n",
      "[Epoch 62/100, Step 434, ETA 57.89s] epoch time: 0.7552s; step time: 0.09349s (Â±0.002991s); train time: 0.6861s; valid time: 0.06896s; loss: -37.406 (Â±0.465672); valid loss: -38.9434\n",
      "[Epoch 63/100, Step 441, ETA 55.93s] epoch time: 0.7756s; step time: 0.09646s (Â±0.003334s); train time: 0.7043s; valid time: 0.07123s; loss: -37.6957 (Â±0.371891); valid loss: -38.4578\n",
      "[Epoch 64/100, Step 448, ETA 54s] Best valid loss updated: from -39.354127 to -39.471369\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 64/100, Step 448, ETA 55.24s] epoch time: 2.974s; step time: 0.09598s (Â±0.002309s); train time: 0.7003s; valid time: 2.273s; loss: -37.2287 (Â±1.0559); valid loss: -39.4714 (*)\n",
      "[Epoch 65/100, Step 455, ETA 53.36s] Best valid loss updated: from -39.471369 to -39.705389\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 65/100, Step 455, ETA 54.72s] epoch time: 3.423s; step time: 0.1104s (Â±0.02523s); train time: 0.8251s; valid time: 2.598s; loss: -38.0227 (Â±0.312814); valid loss: -39.7054 (*)\n",
      "[Epoch 66/100, Step 462, ETA 52.83s] epoch time: 0.9216s; step time: 0.1123s (Â±0.027s); train time: 0.8385s; valid time: 0.08295s; loss: -38.2301 (Â±0.401679); valid loss: -38.5577\n",
      "[Epoch 67/100, Step 469, ETA 50.89s] Best valid loss updated: from -39.705389 to -39.848421\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 67/100, Step 469, ETA 51.73s] epoch time: 2.47s; step time: 0.09447s (Â±0.001814s); train time: 0.6991s; valid time: 1.77s; loss: -37.7959 (Â±0.765241); valid loss: -39.8484 (*)\n",
      "[Epoch 68/100, Step 476, ETA 49.78s] Best valid loss updated: from -39.848421 to -40.238772\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 68/100, Step 476, ETA 50.59s] epoch time: 2.468s; step time: 0.09358s (Â±0.003297s); train time: 0.6865s; valid time: 1.782s; loss: -38.0024 (Â±0.557472); valid loss: -40.2388 (*)\n",
      "[Epoch 69/100, Step 483, ETA 48.64s] epoch time: 0.7586s; step time: 0.09341s (Â±0.002895s); train time: 0.6865s; valid time: 0.07198s; loss: -38.2501 (Â±0.830192); valid loss: -39.9197\n",
      "[Epoch 70/100, Step 490, ETA 46.73s] epoch time: 0.7678s; step time: 0.09465s (Â±0.002133s); train time: 0.697s; valid time: 0.07064s; loss: -38.2905 (Â±0.566204); valid loss: -39.3246\n",
      "[Epoch 71/100, Step 497, ETA 44.85s] Best valid loss updated: from -40.238772 to -40.300824\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 71/100, Step 497, ETA 45.55s] epoch time: 2.495s; step time: 0.09568s (Â±0.002542s); train time: 0.7011s; valid time: 1.794s; loss: -38.3447 (Â±0.420514); valid loss: -40.3008 (*)\n",
      "[Epoch 72/100, Step 504, ETA 43.67s] epoch time: 0.7563s; step time: 0.09299s (Â±0.002218s); train time: 0.6856s; valid time: 0.07058s; loss: -38.7425 (Â±0.478695); valid loss: -39.109\n",
      "[Epoch 73/100, Step 511, ETA 41.82s] epoch time: 0.7782s; step time: 0.09529s (Â±0.002042s); train time: 0.6995s; valid time: 0.07855s; loss: -38.6529 (Â±0.257058); valid loss: -40.1252\n",
      "[Epoch 74/100, Step 518, ETA 40s] epoch time: 0.7901s; step time: 0.09447s (Â±0.00155s); train time: 0.7144s; valid time: 0.07554s; loss: -38.9797 (Â±0.161321); valid loss: -39.775\n",
      "[Epoch 75/100, Step 525, ETA 38.21s] Best valid loss updated: from -40.300824 to -40.471122\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 75/100, Step 525, ETA 39.09s] epoch time: 3.409s; step time: 0.09477s (Â±0.001992s); train time: 0.717s; valid time: 2.692s; loss: -38.9875 (Â±0.194695); valid loss: -40.4711 (*)\n",
      "[Epoch 76/100, Step 532, ETA 37.31s] epoch time: 0.8785s; step time: 0.1061s (Â±0.02321s); train time: 0.7972s; valid time: 0.08115s; loss: -39.19 (Â±0.145705); valid loss: -40.3343\n",
      "[Epoch 77/100, Step 539, ETA 35.52s] Best valid loss updated: from -40.471122 to -40.707289\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 77/100, Step 539, ETA 36.07s] epoch time: 2.591s; step time: 0.09473s (Â±0.00136s); train time: 0.713s; valid time: 1.878s; loss: -39.2259 (Â±0.178249); valid loss: -40.7073 (*)\n",
      "[Epoch 78/100, Step 546, ETA 34.29s] epoch time: 0.8356s; step time: 0.1045s (Â±0.02148s); train time: 0.764s; valid time: 0.07146s; loss: -39.3323 (Â±0.204506); valid loss: -40.2666\n",
      "[Epoch 79/100, Step 553, ETA 32.52s] Best valid loss updated: from -40.707289 to -40.748779\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 79/100, Step 553, ETA 33s] epoch time: 2.555s; step time: 0.09502s (Â±0.001511s); train time: 0.6925s; valid time: 1.862s; loss: -39.3662 (Â±0.119939); valid loss: -40.7488 (*)\n",
      "[Epoch 80/100, Step 560, ETA 31.24s] Best valid loss updated: from -40.748779 to -40.956604\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 80/100, Step 560, ETA 31.72s] epoch time: 2.73s; step time: 0.1046s (Â±0.02262s); train time: 0.7649s; valid time: 1.965s; loss: -39.4512 (Â±0.185555); valid loss: -40.9566 (*)\n",
      "[Epoch 80/100, Step 560, ETA 31.72s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 567, ETA 29.96s] Best valid loss updated: from -40.956604 to -41.924261\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 81/100, Step 567, ETA 30.5s] epoch time: 3.148s; step time: 0.1092s (Â±0.02462s); train time: 0.7973s; valid time: 2.35s; loss: -40.135 (Â±0.391912); valid loss: -41.9243 (*)\n",
      "[Epoch 82/100, Step 574, ETA 28.75s] Best valid loss updated: from -41.924261 to -42.022248\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 82/100, Step 574, ETA 29.38s] epoch time: 3.799s; step time: 0.1123s (Â±0.02504s); train time: 0.8442s; valid time: 2.954s; loss: -40.3766 (Â±0.200563); valid loss: -42.0222 (*)\n",
      "[Epoch 83/100, Step 581, ETA 27.6s] epoch time: 0.9134s; step time: 0.1102s (Â±0.02126s); train time: 0.8393s; valid time: 0.07386s; loss: -40.3491 (Â±0.205988); valid loss: -41.4679\n",
      "[Epoch 84/100, Step 588, ETA 25.81s] epoch time: 0.77s; step time: 0.09489s (Â±0.001718s); train time: 0.7003s; valid time: 0.06949s; loss: -40.1713 (Â±0.300102); valid loss: -41.507\n",
      "[Epoch 85/100, Step 595, ETA 24.05s] epoch time: 0.765s; step time: 0.09497s (Â±0.001664s); train time: 0.6945s; valid time: 0.07037s; loss: -40.3678 (Â±0.206297); valid loss: -41.4359\n",
      "[Epoch 86/100, Step 602, ETA 22.31s] epoch time: 0.7628s; step time: 0.09454s (Â±0.001826s); train time: 0.6907s; valid time: 0.07192s; loss: -40.4075 (Â±0.148382); valid loss: -41.8656\n",
      "[Epoch 87/100, Step 609, ETA 20.59s] epoch time: 0.7668s; step time: 0.09526s (Â±0.001339s); train time: 0.6961s; valid time: 0.07059s; loss: -40.5628 (Â±0.123815); valid loss: -41.7039\n",
      "[Epoch 88/100, Step 616, ETA 18.9s] epoch time: 0.7601s; step time: 0.09466s (Â±0.001867s); train time: 0.6914s; valid time: 0.06866s; loss: -40.5764 (Â±0.158416); valid loss: -41.9971\n",
      "[Epoch 89/100, Step 623, ETA 17.22s] epoch time: 0.7663s; step time: 0.09475s (Â±0.001651s); train time: 0.6945s; valid time: 0.07166s; loss: -40.7622 (Â±0.133719); valid loss: -41.8035\n",
      "[Epoch 90/100, Step 630, ETA 15.57s] Best valid loss updated: from -42.022248 to -42.264172\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 90/100, Step 630, ETA 15.78s] epoch time: 2.637s; step time: 0.09491s (Â±0.001848s); train time: 0.694s; valid time: 1.943s; loss: -40.7913 (Â±0.122799); valid loss: -42.2642 (*)\n",
      "[Epoch 91/100, Step 637, ETA 14.13s] epoch time: 0.8661s; step time: 0.1091s (Â±0.02549s); train time: 0.7973s; valid time: 0.06869s; loss: -40.8435 (Â±0.19491); valid loss: -42.1894\n",
      "[Epoch 92/100, Step 644, ETA 12.49s] epoch time: 0.7635s; step time: 0.09463s (Â±0.001099s); train time: 0.6917s; valid time: 0.07162s; loss: -40.8824 (Â±0.096369); valid loss: -42.2246\n",
      "[Epoch 93/100, Step 651, ETA 10.87s] epoch time: 0.7709s; step time: 0.09575s (Â±0.001953s); train time: 0.6993s; valid time: 0.07149s; loss: -40.9907 (Â±0.0872592); valid loss: -42.1815\n",
      "[Epoch 94/100, Step 658, ETA 9.266s] Best valid loss updated: from -42.264172 to -42.405908\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 94/100, Step 658, ETA 9.456s] epoch time: 3.756s; step time: 0.09532s (Â±0.001359s); train time: 0.7001s; valid time: 3.055s; loss: -41.054 (Â±0.150151); valid loss: -42.4059 (*)\n",
      "[Epoch 95/100, Step 665, ETA 7.844s] epoch time: 0.8948s; step time: 0.1086s (Â±0.02044s); train time: 0.8144s; valid time: 0.08026s; loss: -41.1233 (Â±0.10037); valid loss: -42.3549\n",
      "[Epoch 96/100, Step 672, ETA 6.243s] Best valid loss updated: from -42.405908 to -42.484394\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 96/100, Step 672, ETA 6.348s] epoch time: 3.302s; step time: 0.09416s (Â±0.001787s); train time: 0.7112s; valid time: 2.59s; loss: -41.1711 (Â±0.0950371); valid loss: -42.4844 (*)\n",
      "[Epoch 97/100, Step 679, ETA 4.738s] epoch time: 0.8473s; step time: 0.1053s (Â±0.02231s); train time: 0.7748s; valid time: 0.07235s; loss: -41.2705 (Â±0.135705); valid loss: -42.3473\n",
      "[Epoch 98/100, Step 686, ETA 3.142s] Best valid loss updated: from -42.484394 to -42.790400\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 98/100, Step 686, ETA 3.185s] epoch time: 2.843s; step time: 0.09534s (Â±0.002345s); train time: 0.6969s; valid time: 2.146s; loss: -41.2861 (Â±0.0685181); valid loss: -42.7904 (*)\n",
      "[Epoch 99/100, Step 693, ETA 1.585s] epoch time: 0.8836s; step time: 0.1112s (Â±0.02626s); train time: 0.814s; valid time: 0.06948s; loss: -41.3803 (Â±0.123857); valid loss: -42.6881\n",
      "[Epoch 100/100, Step 700, ETA 0s] Best valid loss updated: from -42.790400 to -42.815310\n",
      "Model saved at results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38.\n",
      "[Epoch 100/100, Step 700, ETA 0s] epoch time: 2.826s; step time: 0.09459s (Â±0.0007131s); train time: 0.6904s; valid time: 2.135s; loss: -41.4538 (Â±0.131372); valid loss: -42.8153 (*)\n",
      "[Epoch 100/100, Step 700, ETA 0s] Learning rate decreased to 1.5625e-06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpyzvuxohl/variables.dat-700\n",
      "2023-12-12 20:33:26,478 [INFO] tensorflow: Restoring parameters from /tmp/tmpyzvuxohl/variables.dat-700\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'best_valid_loss': -42.815309739163474,\n",
      " 'pred_time': 0.03208511603953375,\n",
      " 'pred_total_time': 107.24808955192566,\n",
      " 'train_time': 1.6086382699012756,\n",
      " 'valid_time': 0.03458460688591004}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmptktbjsfzwandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpmkrzabanwandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpiz_y7n5jwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpfmqzmfvpwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 2b w. 1% and 0.1% data"
   ],
   "metadata": {
    "id": "4FvGHliJj8uZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --restore_dir=results/tuned_model_st8000_2 --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp2b_1p --train_portion=0.01 --initial_lr=0.00005"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdBSRdNYjyrq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702411402211,
     "user_tz": 300,
     "elapsed": 1106604,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "c83965fc-bffb-4851-92f8-69818f7d30b3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "=====================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': 'results/tuned_model_st8000_2',\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'results/tuned_model_st8000_2_exp2b_1p',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': 0.01,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (50953, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 19:45:06,864 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 19:45:11.199215: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-12 19:45:11.408208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-12 19:45:11.408404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-12 19:45:11.408431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-12 19:45:11.750423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-12 19:45:11.750471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-12 19:45:11.750482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-12 19:45:11.750567: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-12 19:45:11.750611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "2023-12-12 19:45:11,807 [INFO] tensorflow: Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "Variables restored from results/tuned_model_st8000_2.\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (40763, 16)\n",
      "[Epoch 1/100, Step 79] Best valid loss updated: from inf to -33.494159\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 1/100, Step 79, ETA 22m 9.476s] epoch time: 13.43s; step time: 0.1382s (Â±0.41s); train time: 11.37s; valid time: 2.058s; loss: 19234.8 (Â±148023); valid loss: -33.4942 (*)\n",
      "[Epoch 2/100, Step 158, ETA 17m 49.67s] Best valid loss updated: from -33.494159 to -46.261584\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 2/100, Step 158, ETA 19m 2.16s] epoch time: 9.88s; step time: 0.09164s (Â±0.002021s); train time: 7.663s; valid time: 2.216s; loss: -42.5404 (Â±4.78684); valid loss: -46.2616 (*)\n",
      "[Epoch 3/100, Step 237, ETA 17m 3.437s] Best valid loss updated: from -46.261584 to -50.163047\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 3/100, Step 237, ETA 17m 33.3s] epoch time: 9.266s; step time: 0.09196s (Â±0.001445s); train time: 7.667s; valid time: 1.599s; loss: -47.0079 (Â±5.11811); valid loss: -50.163 (*)\n",
      "[Epoch 4/100, Step 316, ETA 16m 28.3s] Best valid loss updated: from -50.163047 to -53.743326\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 4/100, Step 316, ETA 16m 51.13s] epoch time: 9.553s; step time: 0.09359s (Â±0.002036s); train time: 7.902s; valid time: 1.651s; loss: -51.7597 (Â±2.43794); valid loss: -53.7433 (*)\n",
      "[Epoch 5/100, Step 395, ETA 15m 59.56s] epoch time: 8.373s; step time: 0.09301s (Â±0.001863s); train time: 7.695s; valid time: 0.6774s; loss: -53.632 (Â±2.21427); valid loss: -51.9386\n",
      "[Epoch 6/100, Step 474, ETA 15m 26.75s] Best valid loss updated: from -53.743326 to -55.524721\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 6/100, Step 474, ETA 15m 41.49s] epoch time: 9.591s; step time: 0.09466s (Â±0.001748s); train time: 7.975s; valid time: 1.615s; loss: -54.5417 (Â±2.89325); valid loss: -55.5247 (*)\n",
      "[Epoch 7/100, Step 553, ETA 15m 12.2s] Best valid loss updated: from -55.524721 to -58.082331\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 7/100, Step 553, ETA 15m 34.01s] epoch time: 10.21s; step time: 0.09396s (Â±0.001804s); train time: 7.801s; valid time: 2.405s; loss: -55.3871 (Â±3.00151); valid loss: -58.0823 (*)\n",
      "[Epoch 8/100, Step 632, ETA 15m 7.55s] epoch time: 8.615s; step time: 0.09443s (Â±0.001565s); train time: 7.941s; valid time: 0.6748s; loss: -58.4888 (Â±1.96662); valid loss: -51.0797\n",
      "[Epoch 9/100, Step 711, ETA 14m 45.47s] epoch time: 8.656s; step time: 0.09467s (Â±0.001884s); train time: 7.91s; valid time: 0.7462s; loss: -58.7882 (Â±3.01697); valid loss: -58.0778\n",
      "[Epoch 10/100, Step 790, ETA 14m 26.35s] Best valid loss updated: from -58.082331 to -58.316791\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 10/100, Step 790, ETA 14m 35.33s] epoch time: 9.684s; step time: 0.09544s (Â±0.001659s); train time: 7.997s; valid time: 1.686s; loss: -60.2379 (Â±2.02322); valid loss: -58.3168 (*)\n",
      "[Epoch 11/100, Step 869, ETA 14m 17.88s] Best valid loss updated: from -58.316791 to -60.450669\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 11/100, Step 869, ETA 14m 25.96s] epoch time: 9.769s; step time: 0.09528s (Â±0.001787s); train time: 8.019s; valid time: 1.75s; loss: -60.6669 (Â±1.8134); valid loss: -60.4507 (*)\n",
      "[Epoch 12/100, Step 948, ETA 14m 7.947s] Best valid loss updated: from -60.450669 to -64.159247\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 12/100, Step 948, ETA 14m 18.29s] epoch time: 10.01s; step time: 0.09558s (Â±0.001644s); train time: 7.907s; valid time: 2.102s; loss: -61.2529 (Â±2.0698); valid loss: -64.1592 (*)\n",
      "[Epoch 13/100, Step 1027, ETA 14m 2.19s] epoch time: 8.805s; step time: 0.09595s (Â±0.001779s); train time: 8.116s; valid time: 0.6893s; loss: -61.0758 (Â±2.89636); valid loss: -61.8827\n",
      "[Epoch 14/100, Step 1106, ETA 13m 46.87s] epoch time: 8.763s; step time: 0.09635s (Â±0.001813s); train time: 8.005s; valid time: 0.757s; loss: -61.4743 (Â±3.22064); valid loss: -61.9359\n",
      "[Epoch 15/100, Step 1185, ETA 13m 32.84s] epoch time: 8.834s; step time: 0.09694s (Â±0.001857s); train time: 8.132s; valid time: 0.7021s; loss: -63.4761 (Â±1.93236); valid loss: -62.6024\n",
      "[Epoch 16/100, Step 1264, ETA 13m 19.56s] epoch time: 8.855s; step time: 0.09698s (Â±0.001744s); train time: 8.089s; valid time: 0.7656s; loss: -64.141 (Â±2.51061); valid loss: -63.9115\n",
      "[Epoch 17/100, Step 1343, ETA 13m 6.92s] Best valid loss updated: from -64.159247 to -64.785847\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 17/100, Step 1343, ETA 13m 12.13s] epoch time: 9.945s; step time: 0.09712s (Â±0.001427s); train time: 8.177s; valid time: 1.767s; loss: -63.6814 (Â±4.3623); valid loss: -64.7858 (*)\n",
      "[Epoch 18/100, Step 1422, ETA 12m 59.83s] Best valid loss updated: from -64.785847 to -66.577858\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 18/100, Step 1422, ETA 13m 4.904s] epoch time: 10.05s; step time: 0.09747s (Â±0.001721s); train time: 8.172s; valid time: 1.88s; loss: -65.0548 (Â±2.28788); valid loss: -66.5779 (*)\n",
      "[Epoch 19/100, Step 1501, ETA 12m 51.72s] epoch time: 8.725s; step time: 0.09715s (Â±0.00178s); train time: 8.027s; valid time: 0.6972s; loss: -64.5477 (Â±4.0432); valid loss: -63.366\n",
      "[Epoch 20/100, Step 1580, ETA 12m 39.68s] Best valid loss updated: from -66.577858 to -67.794655\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 20/100, Step 1580, ETA 12m 44.26s] epoch time: 10.04s; step time: 0.09754s (Â±0.00178s); train time: 8.197s; valid time: 1.846s; loss: -66.1568 (Â±1.87877); valid loss: -67.7947 (*)\n",
      "[Epoch 20/100, Step 1580, ETA 12m 44.26s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 1659, ETA 12m 31.98s] Best valid loss updated: from -67.794655 to -71.696500\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 21/100, Step 1659, ETA 12m 38.59s] epoch time: 10.58s; step time: 0.09742s (Â±0.002009s); train time: 8.074s; valid time: 2.51s; loss: -71.8041 (Â±1.60916); valid loss: -71.6965 (*)\n",
      "[Epoch 22/100, Step 1738, ETA 12m 26.53s] Best valid loss updated: from -71.696500 to -72.261051\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 22/100, Step 1738, ETA 12m 30.48s] epoch time: 10.02s; step time: 0.09842s (Â±0.007139s); train time: 8.207s; valid time: 1.817s; loss: -72.9012 (Â±1.71631); valid loss: -72.2611 (*)\n",
      "[Epoch 23/100, Step 1817, ETA 12m 18.63s] Best valid loss updated: from -72.261051 to -72.886723\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 23/100, Step 1817, ETA 12m 22.66s] epoch time: 10.16s; step time: 0.09804s (Â±0.001737s); train time: 8.235s; valid time: 1.923s; loss: -72.9158 (Â±2.3831); valid loss: -72.8867 (*)\n",
      "[Epoch 24/100, Step 1896, ETA 12m 10.27s] Best valid loss updated: from -72.886723 to -73.849966\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 24/100, Step 1896, ETA 12m 16.22s] epoch time: 10.65s; step time: 0.09729s (Â±0.001656s); train time: 8.034s; valid time: 2.62s; loss: -73.355 (Â±1.3745); valid loss: -73.85 (*)\n",
      "[Epoch 25/100, Step 1975, ETA 12m 4.475s] epoch time: 9.002s; step time: 0.09893s (Â±0.008262s); train time: 8.3s; valid time: 0.702s; loss: -74.0968 (Â±2.14351); valid loss: -72.0766\n",
      "[Epoch 26/100, Step 2054, ETA 11m 52.82s] epoch time: 8.959s; step time: 0.09834s (Â±0.002237s); train time: 8.187s; valid time: 0.7718s; loss: -73.4016 (Â±2.47981); valid loss: -71.3992\n",
      "[Epoch 27/100, Step 2133, ETA 11m 41.58s] epoch time: 9.036s; step time: 0.09961s (Â±0.001942s); train time: 8.32s; valid time: 0.7155s; loss: -73.71 (Â±1.27543); valid loss: -73.356\n",
      "[Epoch 28/100, Step 2212, ETA 11m 30.99s] Best valid loss updated: from -73.849966 to -75.282198\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 28/100, Step 2212, ETA 11m 34.28s] epoch time: 10.51s; step time: 0.101s (Â±0.002066s); train time: 8.438s; valid time: 2.069s; loss: -74.6077 (Â±0.669443); valid loss: -75.2822 (*)\n",
      "[Epoch 29/100, Step 2291, ETA 11m 23.25s] epoch time: 9.079s; step time: 0.1013s (Â±0.002596s); train time: 8.346s; valid time: 0.7326s; loss: -75.7849 (Â±0.541045); valid loss: -74.7007\n",
      "[Epoch 30/100, Step 2370, ETA 11m 12.79s] epoch time: 9.265s; step time: 0.1013s (Â±0.002081s); train time: 8.531s; valid time: 0.7335s; loss: -72.8672 (Â±3.49652); valid loss: -74.3072\n",
      "[Epoch 31/100, Step 2449, ETA 11m 2.017s] epoch time: 9.088s; step time: 0.1004s (Â±0.00173s); train time: 8.305s; valid time: 0.783s; loss: -75.2906 (Â±1.12458); valid loss: -75.2736\n",
      "[Epoch 32/100, Step 2528, ETA 10m 51.41s] epoch time: 9.116s; step time: 0.1003s (Â±0.001693s); train time: 8.399s; valid time: 0.7169s; loss: -74.3829 (Â±4.1313); valid loss: -72.4224\n",
      "[Epoch 33/100, Step 2607, ETA 10m 40.89s] Best valid loss updated: from -75.282198 to -75.572757\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 33/100, Step 2607, ETA 10m 44.91s] epoch time: 11.1s; step time: 0.1001s (Â±0.001873s); train time: 8.334s; valid time: 2.763s; loss: -74.6798 (Â±1.2799); valid loss: -75.5728 (*)\n",
      "[Epoch 34/100, Step 2686, ETA 10m 34.12s] Best valid loss updated: from -75.572757 to -78.733252\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 34/100, Step 2686, ETA 10m 36.68s] epoch time: 10.34s; step time: 0.1003s (Â±0.00871s); train time: 8.314s; valid time: 2.028s; loss: -76.9391 (Â±1.06114); valid loss: -78.7333 (*)\n",
      "[Epoch 35/100, Step 2765, ETA 10m 26.07s] epoch time: 9.126s; step time: 0.09979s (Â±0.001796s); train time: 8.416s; valid time: 0.7102s; loss: -75.4484 (Â±3.17979); valid loss: -73.1958\n",
      "[Epoch 36/100, Step 2844, ETA 10m 15.4s] epoch time: 9.047s; step time: 0.09978s (Â±0.002169s); train time: 8.267s; valid time: 0.7797s; loss: -73.0369 (Â±6.02033); valid loss: -74.2014\n",
      "[Epoch 37/100, Step 2923, ETA 10m 4.947s] epoch time: 9.126s; step time: 0.1003s (Â±0.001661s); train time: 8.409s; valid time: 0.7165s; loss: -74.0597 (Â±1.95936); valid loss: -74.2087\n",
      "[Epoch 38/100, Step 3002, ETA 9m 54.56s] epoch time: 9.119s; step time: 0.1003s (Â±0.002054s); train time: 8.332s; valid time: 0.7865s; loss: -75.1205 (Â±0.711535); valid loss: -74.5167\n",
      "[Epoch 39/100, Step 3081, ETA 9m 44.2s] epoch time: 9.098s; step time: 0.1004s (Â±0.00182s); train time: 8.38s; valid time: 0.7178s; loss: -76.6959 (Â±0.733509); valid loss: -76.6611\n",
      "[Epoch 40/100, Step 3160, ETA 9m 33.98s] epoch time: 9.151s; step time: 0.1004s (Â±0.00187s); train time: 8.386s; valid time: 0.7644s; loss: -76.116 (Â±1.58683); valid loss: -75.4533\n",
      "[Epoch 40/100, Step 3160, ETA 9m 33.98s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 3239, ETA 9m 23.58s] Best valid loss updated: from -78.733252 to -80.508267\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 41/100, Step 3239, ETA 9m 25.38s] epoch time: 10.24s; step time: 0.09976s (Â±0.001859s); train time: 8.271s; valid time: 1.966s; loss: -79.7901 (Â±1.59769); valid loss: -80.5083 (*)\n",
      "[Epoch 42/100, Step 3318, ETA 9m 15.17s] epoch time: 9.124s; step time: 0.1002s (Â±0.002114s); train time: 8.412s; valid time: 0.7123s; loss: -81.0503 (Â±1.22663); valid loss: -79.7947\n",
      "[Epoch 43/100, Step 3397, ETA 9m 4.839s] Best valid loss updated: from -80.508267 to -80.527625\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 43/100, Step 3397, ETA 9m 7.523s] epoch time: 11.02s; step time: 0.09959s (Â±0.001878s); train time: 8.222s; valid time: 2.801s; loss: -81.3807 (Â±0.498858); valid loss: -80.5276 (*)\n",
      "[Epoch 44/100, Step 3476, ETA 8m 57.24s] Best valid loss updated: from -80.527625 to -81.046175\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 44/100, Step 3476, ETA 8m 58.91s] epoch time: 10.39s; step time: 0.1003s (Â±0.007565s); train time: 8.358s; valid time: 2.029s; loss: -81.9651 (Â±0.501394); valid loss: -81.0462 (*)\n",
      "[Epoch 45/100, Step 3555, ETA 8m 48.71s] epoch time: 9.147s; step time: 0.1002s (Â±0.002252s); train time: 8.398s; valid time: 0.7483s; loss: -82.3387 (Â±0.464887); valid loss: -80.8554\n",
      "[Epoch 46/100, Step 3634, ETA 8m 38.34s] epoch time: 8.97s; step time: 0.1001s (Â±0.001747s); train time: 8.252s; valid time: 0.7175s; loss: -81.71 (Â±4.78205); valid loss: -57.7659\n",
      "[Epoch 47/100, Step 3713, ETA 8m 28.27s] epoch time: 9.179s; step time: 0.1008s (Â±0.00245s); train time: 8.451s; valid time: 0.728s; loss: -80.1871 (Â±3.59902); valid loss: -79.8077\n",
      "[Epoch 48/100, Step 3792, ETA 8m 18.09s] epoch time: 9.043s; step time: 0.09998s (Â±0.00204s); train time: 8.249s; valid time: 0.7939s; loss: -81.5007 (Â±1.08592); valid loss: -80.4252\n",
      "[Epoch 49/100, Step 3871, ETA 8m 8.028s] Best valid loss updated: from -81.046175 to -81.656207\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 49/100, Step 3871, ETA 8m 9.378s] epoch time: 10.41s; step time: 0.1001s (Â±0.001916s); train time: 8.404s; valid time: 2.008s; loss: -82.0551 (Â±0.540393); valid loss: -81.6562 (*)\n",
      "[Epoch 50/100, Step 3950, ETA 7m 59.28s] epoch time: 9.096s; step time: 0.09974s (Â±0.00182s); train time: 8.309s; valid time: 0.7873s; loss: -82.6143 (Â±0.554388); valid loss: -81.3118\n",
      "[Epoch 51/100, Step 4029, ETA 7m 49.15s] Best valid loss updated: from -81.656207 to -82.665833\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 51/100, Step 4029, ETA 7m 50.48s] epoch time: 10.4s; step time: 0.09964s (Â±0.001793s); train time: 8.307s; valid time: 2.091s; loss: -83.0461 (Â±0.519052); valid loss: -82.6658 (*)\n",
      "[Epoch 52/100, Step 4108, ETA 7m 40.45s] epoch time: 9.134s; step time: 0.1001s (Â±0.002217s); train time: 8.417s; valid time: 0.7175s; loss: -80.6735 (Â±3.43063); valid loss: -81.57\n",
      "[Epoch 53/100, Step 4187, ETA 7m 30.29s] epoch time: 8.951s; step time: 0.0995s (Â±0.001726s); train time: 8.209s; valid time: 0.7415s; loss: -80.4935 (Â±1.21395); valid loss: -80.3972\n",
      "[Epoch 54/100, Step 4266, ETA 7m 20.37s] epoch time: 9.186s; step time: 0.1006s (Â±0.002333s); train time: 8.469s; valid time: 0.7166s; loss: -81.6835 (Â±0.717751); valid loss: -82.0831\n",
      "[Epoch 55/100, Step 4345, ETA 7m 10.39s] epoch time: 9.075s; step time: 0.1s (Â±0.001972s); train time: 8.278s; valid time: 0.7969s; loss: -82.2577 (Â±0.725789); valid loss: -81.5169\n",
      "[Epoch 56/100, Step 4424, ETA 7m 0.4893s] epoch time: 9.138s; step time: 0.1004s (Â±0.001819s); train time: 8.427s; valid time: 0.7113s; loss: -82.983 (Â±0.589612); valid loss: -82.1744\n",
      "[Epoch 57/100, Step 4503, ETA 6m 50.61s] epoch time: 9.131s; step time: 0.1003s (Â±0.001803s); train time: 8.344s; valid time: 0.7877s; loss: -83.122 (Â±0.550723); valid loss: -82.2155\n",
      "[Epoch 58/100, Step 4582, ETA 6m 40.72s] Best valid loss updated: from -82.665833 to -82.710239\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 58/100, Step 4582, ETA 6m 41.82s] epoch time: 10.59s; step time: 0.1001s (Â±0.001602s); train time: 8.356s; valid time: 2.23s; loss: -83.5959 (Â±0.518103); valid loss: -82.7102 (*)\n",
      "[Epoch 59/100, Step 4661, ETA 6m 31.95s] Best valid loss updated: from -82.710239 to -82.942241\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 59/100, Step 4661, ETA 6m 32.97s] epoch time: 10.61s; step time: 0.1002s (Â±0.002146s); train time: 8.414s; valid time: 2.193s; loss: -84.0507 (Â±0.528998); valid loss: -82.9422 (*)\n",
      "[Epoch 60/100, Step 4740, ETA 6m 23.01s] epoch time: 9.011s; step time: 0.09957s (Â±0.002145s); train time: 8.233s; valid time: 0.7779s; loss: -81.8586 (Â±6.02951); valid loss: -81.4136\n",
      "[Epoch 60/100, Step 4740, ETA 6m 23.01s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 4819, ETA 6m 13.14s] Best valid loss updated: from -82.942241 to -85.034094\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 61/100, Step 4819, ETA 6m 14.08s] epoch time: 10.58s; step time: 0.09995s (Â±0.001845s); train time: 8.406s; valid time: 2.174s; loss: -85.7068 (Â±0.893253); valid loss: -85.0341 (*)\n",
      "[Epoch 62/100, Step 4898, ETA 6m 4.205s] Best valid loss updated: from -85.034094 to -85.358752\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 62/100, Step 4898, ETA 6m 5.372s] epoch time: 11.04s; step time: 0.1s (Â±0.002146s); train time: 8.354s; valid time: 2.681s; loss: -86.6142 (Â±0.459158); valid loss: -85.3588 (*)\n",
      "[Epoch 63/100, Step 4977, ETA 5m 55.42s] Best valid loss updated: from -85.358752 to -85.648752\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 63/100, Step 4977, ETA 5m 56.85s] epoch time: 11.46s; step time: 0.1007s (Â±0.00716s); train time: 8.313s; valid time: 3.15s; loss: -86.9742 (Â±0.368209); valid loss: -85.6488 (*)\n",
      "[Epoch 64/100, Step 5056, ETA 5m 46.94s] Best valid loss updated: from -85.648752 to -85.664054\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 64/100, Step 5056, ETA 5m 47.88s] epoch time: 10.85s; step time: 0.1011s (Â±0.007447s); train time: 8.474s; valid time: 2.38s; loss: -87.2253 (Â±0.441472); valid loss: -85.6641 (*)\n",
      "[Epoch 65/100, Step 5135, ETA 5m 37.97s] Best valid loss updated: from -85.664054 to -86.329319\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 65/100, Step 5135, ETA 5m 38.92s] epoch time: 10.97s; step time: 0.1005s (Â±0.002231s); train time: 8.397s; valid time: 2.569s; loss: -87.4463 (Â±0.371267); valid loss: -86.3293 (*)\n",
      "[Epoch 66/100, Step 5214, ETA 5m 28.9s] epoch time: 9.018s; step time: 0.1001s (Â±0.001863s); train time: 8.259s; valid time: 0.7586s; loss: -87.6167 (Â±0.419748); valid loss: -85.9161\n",
      "[Epoch 67/100, Step 5293, ETA 5m 18.99s] epoch time: 9.192s; step time: 0.1005s (Â±0.00205s); train time: 8.476s; valid time: 0.7154s; loss: -86.6195 (Â±1.44554); valid loss: -86.2718\n",
      "[Epoch 68/100, Step 5372, ETA 5m 9.042s] epoch time: 9.074s; step time: 0.09999s (Â±0.0015s); train time: 8.291s; valid time: 0.7827s; loss: -87.47 (Â±0.446771); valid loss: -86.2043\n",
      "[Epoch 69/100, Step 5451, ETA 4m 59.13s] Best valid loss updated: from -86.329319 to -86.875518\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 69/100, Step 5451, ETA 4m 59.89s] epoch time: 10.78s; step time: 0.1001s (Â±0.002165s); train time: 8.379s; valid time: 2.403s; loss: -87.7728 (Â±0.466997); valid loss: -86.8755 (*)\n",
      "[Epoch 70/100, Step 5530, ETA 4m 50.03s] epoch time: 9.227s; step time: 0.1008s (Â±0.007209s); train time: 8.449s; valid time: 0.7774s; loss: -87.1315 (Â±1.33407); valid loss: -86.8194\n",
      "[Epoch 71/100, Step 5609, ETA 4m 40.05s] epoch time: 8.914s; step time: 0.0993s (Â±0.001748s); train time: 8.195s; valid time: 0.7192s; loss: -86.9657 (Â±1.54534); valid loss: -83.1619\n",
      "[Epoch 72/100, Step 5688, ETA 4m 30.19s] epoch time: 9.128s; step time: 0.1003s (Â±0.001767s); train time: 8.412s; valid time: 0.7156s; loss: -86.8881 (Â±2.43373); valid loss: -79.4307\n",
      "[Epoch 73/100, Step 5767, ETA 4m 20.3s] epoch time: 8.993s; step time: 0.09948s (Â±0.001833s); train time: 8.207s; valid time: 0.7857s; loss: -86.1608 (Â±2.53823); valid loss: -86.0123\n",
      "[Epoch 74/100, Step 5846, ETA 4m 10.49s] epoch time: 9.162s; step time: 0.1004s (Â±0.001928s); train time: 8.452s; valid time: 0.7104s; loss: -87.8949 (Â±0.457898); valid loss: -86.7553\n",
      "[Epoch 75/100, Step 5925, ETA 4m 0.6758s] epoch time: 9.1s; step time: 0.1002s (Â±0.002146s); train time: 8.309s; valid time: 0.7904s; loss: -88.1051 (Â±0.430926); valid loss: -86.5297\n",
      "[Epoch 76/100, Step 6004, ETA 3m 50.89s] Best valid loss updated: from -86.875518 to -86.883435\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 76/100, Step 6004, ETA 3m 51.43s] epoch time: 10.83s; step time: 0.1004s (Â±0.001996s); train time: 8.4s; valid time: 2.432s; loss: -88.2315 (Â±0.374489); valid loss: -86.8834 (*)\n",
      "[Epoch 77/100, Step 6083, ETA 3m 41.67s] epoch time: 9.245s; step time: 0.1014s (Â±0.006468s); train time: 8.492s; valid time: 0.7533s; loss: -88.41 (Â±0.435314); valid loss: -86.732\n",
      "[Epoch 78/100, Step 6162, ETA 3m 31.84s] epoch time: 8.954s; step time: 0.09989s (Â±0.001619s); train time: 8.233s; valid time: 0.7209s; loss: -88.0116 (Â±1.30759); valid loss: -85.579\n",
      "[Epoch 79/100, Step 6241, ETA 3m 22.08s] Best valid loss updated: from -86.883435 to -87.186748\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 79/100, Step 6241, ETA 3m 22.55s] epoch time: 10.9s; step time: 0.1003s (Â±0.001954s); train time: 8.422s; valid time: 2.483s; loss: -87.8329 (Â±0.766847); valid loss: -87.1867 (*)\n",
      "[Epoch 80/100, Step 6320, ETA 3m 12.77s] epoch time: 9.108s; step time: 0.1003s (Â±0.003194s); train time: 8.323s; valid time: 0.7846s; loss: -88.3463 (Â±0.510369); valid loss: -86.6038\n",
      "[Epoch 80/100, Step 6320, ETA 3m 12.77s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 6399, ETA 3m 3.001s] epoch time: 9.081s; step time: 0.09992s (Â±0.001859s); train time: 8.362s; valid time: 0.7186s; loss: -88.4738 (Â±1.05312); valid loss: -85.8381\n",
      "[Epoch 82/100, Step 6478, ETA 2m 53.26s] Best valid loss updated: from -87.186748 to -88.309908\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 82/100, Step 6478, ETA 2m 53.74s] epoch time: 11.34s; step time: 0.1001s (Â±0.001797s); train time: 8.338s; valid time: 2.997s; loss: -89.4207 (Â±0.750401); valid loss: -88.3099 (*)\n",
      "[Epoch 83/100, Step 6557, ETA 2m 43.96s] Best valid loss updated: from -88.309908 to -88.350312\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 83/100, Step 6557, ETA 2m 44.52s] epoch time: 11.74s; step time: 0.1006s (Â±0.007601s); train time: 8.298s; valid time: 3.444s; loss: -89.9887 (Â±0.44035); valid loss: -88.3503 (*)\n",
      "[Epoch 84/100, Step 6636, ETA 2m 34.75s] epoch time: 9.172s; step time: 0.1009s (Â±0.006635s); train time: 8.45s; valid time: 0.7216s; loss: -89.9795 (Â±0.848003); valid loss: -87.0243\n",
      "[Epoch 85/100, Step 6715, ETA 2m 24.99s] epoch time: 9.186s; step time: 0.1007s (Â±0.002175s); train time: 8.396s; valid time: 0.7893s; loss: -88.9488 (Â±1.02712); valid loss: -84.7346\n",
      "[Epoch 86/100, Step 6794, ETA 2m 15.23s] Best valid loss updated: from -88.350312 to -88.709512\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 86/100, Step 6794, ETA 2m 15.52s] epoch time: 10.89s; step time: 0.1006s (Â±0.00184s); train time: 8.357s; valid time: 2.535s; loss: -89.0716 (Â±1.01076); valid loss: -88.7095 (*)\n",
      "[Epoch 87/100, Step 6873, ETA 2m 5.78s] epoch time: 9.248s; step time: 0.1019s (Â±0.008423s); train time: 8.534s; valid time: 0.7135s; loss: -89.2693 (Â±0.780734); valid loss: -88.0372\n",
      "[Epoch 88/100, Step 6952, ETA 1m 56.02s] epoch time: 9.04s; step time: 0.09997s (Â±0.002023s); train time: 8.255s; valid time: 0.7847s; loss: -89.4897 (Â±0.80303); valid loss: -86.8236\n",
      "[Epoch 89/100, Step 7031, ETA 1m 46.28s] epoch time: 9.132s; step time: 0.1004s (Â±0.001893s); train time: 8.42s; valid time: 0.7121s; loss: -89.5399 (Â±0.68716); valid loss: -88.383\n",
      "[Epoch 90/100, Step 7110, ETA 1m 36.56s] Best valid loss updated: from -88.709512 to -89.079752\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 90/100, Step 7110, ETA 1m 36.86s] epoch time: 11.84s; step time: 0.09975s (Â±0.001765s); train time: 8.302s; valid time: 3.542s; loss: -89.7976 (Â±0.686145); valid loss: -89.0798 (*)\n",
      "[Epoch 91/100, Step 7189, ETA 1m 27.11s] epoch time: 8.985s; step time: 0.1002s (Â±0.007579s); train time: 8.271s; valid time: 0.713s; loss: -90.4925 (Â±0.589437); valid loss: -87.8655\n",
      "[Epoch 92/100, Step 7268, ETA 1m 17.38s] epoch time: 9.115s; step time: 0.1002s (Â±0.001846s); train time: 8.404s; valid time: 0.7117s; loss: -90.2674 (Â±0.547792); valid loss: -88.6482\n",
      "[Epoch 93/100, Step 7347, ETA 1m 7.66s] epoch time: 9.036s; step time: 0.09983s (Â±0.001769s); train time: 8.246s; valid time: 0.7903s; loss: -90.4992 (Â±0.423203); valid loss: -88.776\n",
      "[Epoch 94/100, Step 7426, ETA 57.96s] epoch time: 9.155s; step time: 0.1005s (Â±0.001857s); train time: 8.439s; valid time: 0.7154s; loss: -90.6071 (Â±0.437117); valid loss: -88.8997\n",
      "[Epoch 95/100, Step 7505, ETA 48.27s] epoch time: 9.105s; step time: 0.1001s (Â±0.00212s); train time: 8.31s; valid time: 0.7945s; loss: -90.6932 (Â±0.399463); valid loss: -88.908\n",
      "[Epoch 96/100, Step 7584, ETA 38.6s] Best valid loss updated: from -89.079752 to -89.110629\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 96/100, Step 7584, ETA 38.68s] epoch time: 11.12s; step time: 0.1001s (Â±0.001475s); train time: 8.393s; valid time: 2.726s; loss: -90.7751 (Â±0.444544); valid loss: -89.1106 (*)\n",
      "[Epoch 97/100, Step 7663, ETA 28.99s] epoch time: 9.194s; step time: 0.1009s (Â±0.007054s); train time: 8.48s; valid time: 0.7139s; loss: -90.845 (Â±0.458036); valid loss: -89.0848\n",
      "[Epoch 98/100, Step 7742, ETA 19.31s] Best valid loss updated: from -89.110629 to -89.202639\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 98/100, Step 7742, ETA 19.37s] epoch time: 11.6s; step time: 0.09932s (Â±0.001618s); train time: 8.196s; valid time: 3.402s; loss: -90.9003 (Â±0.483336); valid loss: -89.2026 (*)\n",
      "[Epoch 99/100, Step 7821, ETA 9.679s] epoch time: 9.142s; step time: 0.1007s (Â±0.006694s); train time: 8.43s; valid time: 0.7121s; loss: -90.9515 (Â±0.41713); valid loss: -89.1693\n",
      "[Epoch 100/100, Step 7900, ETA 0s] Best valid loss updated: from -89.202639 to -89.330322\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_1p_2023-12-12_19-45-04.\n",
      "[Epoch 100/100, Step 7900, ETA 0s] epoch time: 11.69s; step time: 0.1002s (Â±0.002196s); train time: 8.356s; valid time: 3.333s; loss: -91.0181 (Â±0.383693); valid loss: -89.3303 (*)\n",
      "[Epoch 100/100, Step 7900, ETA 0s] Learning rate decreased to 1.5625e-06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp84_pm90m/variables.dat-7900\n",
      "2023-12-12 20:01:22,532 [INFO] tensorflow: Restoring parameters from /tmp/tmp84_pm90m/variables.dat-7900\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'best_valid_loss': -89.33032194418432,\n",
      " 'pred_time': 0.033099033344597045,\n",
      " 'pred_total_time': 109.899178981781,\n",
      " 'train_time': 9.705114121437072,\n",
      " 'valid_time': 0.03258818280696869}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpya0l0vvpwandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpf3v6e1f6wandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpf_5bf4_swandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpu543l5l_wandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --restore_dir=results/tuned_model_st8000_2 --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp2b_0_1p --train_portion=0.001 --initial_lr=0.00005"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tnVUgQztNsO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702413030039,
     "user_tz": 300,
     "elapsed": 277391,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "85e66a41-2e9b-406f-e8e1-39205e3d4f85"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "=======================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 100,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': 'results/tuned_model_st8000_2',\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'results/tuned_model_st8000_2_exp2b_0_1p',\n",
      " 'save_z': False,\n",
      " 'scaler_path': None,\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': 0.001,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (5095, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 20:26:04,291 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 20:26:08.388826: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-12 20:26:08.592858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-12 20:26:08.593043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-12 20:26:08.593070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-12 20:26:08.878569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-12 20:26:08.878615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-12 20:26:08.878627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-12 20:26:08.878714: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-12 20:26:08.878761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "2023-12-12 20:26:08,931 [INFO] tensorflow: Restoring parameters from /content/csc2233-2023/results/tuned_model_st8000_2/variables.dat\n",
      "Variables restored from results/tuned_model_st8000_2.\n",
      "Start val loss: inf\n",
      "Trainable Parameters                                           (3,060,036 in total)\n",
      "-----------------------------------------------------------------------------------\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/kernel  (515, 2000)  1,030,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/kernel                (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense/bias                  (500,)             500\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/kernel              (500, 500)     250,000\n",
      "model/q_z_given_x/hidden/rnn_q_z/dense_1/bias                (500,)             500\n",
      "model/q_z_given_x/z_mean/kernel                              (500, 3)         1,500\n",
      "model/q_z_given_x/z_mean/bias                                (3,)                 3\n",
      "model/q_z_given_x/z_std/kernel                               (500, 3)         1,500\n",
      "model/q_z_given_x/z_std/bias                                 (3,)                 3\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/kernel  (503, 2000)  1,006,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/rnn/basic_lstm_cell/bias    (2000,)          2,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/kernel                (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense/bias                  (500,)             500\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel              (500, 500)     250,000\n",
      "model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                (500,)             500\n",
      "model/p_x_given_z/x_mean/kernel                              (500, 15)        7,500\n",
      "model/p_x_given_z/x_mean/bias                                (15,)               15\n",
      "model/p_x_given_z/x_std/kernel                               (500, 15)        7,500\n",
      "model/p_x_given_z/x_std/bias                                 (15,)               15\n",
      "\n",
      "train_values: (4076, 16)\n",
      "[Epoch 1/100, Step 7] Best valid loss updated: from inf to 4.026730\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 1/100, Step 7, ETA 11m 11.7s] epoch time: 6.784s; step time: 0.6312s (Â±1.316s); train time: 4.463s; valid time: 2.321s; loss: 168996 (Â±403559); valid loss: 4.02673 (*)\n",
      "[Epoch 2/100, Step 14, ETA 6m 13.32s] Best valid loss updated: from 4.026730 to -2.627119\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 2/100, Step 14, ETA 6m 57.11s] epoch time: 1.727s; step time: 0.1044s (Â±0.0227s); train time: 0.7671s; valid time: 0.9598s; loss: 28.6067 (Â±48.532); valid loss: -2.62712 (*)\n",
      "[Epoch 3/100, Step 21, ETA 4m 58.3s] Best valid loss updated: from -2.627119 to -11.156439\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 3/100, Step 21, ETA 5m 28.25s] epoch time: 1.639s; step time: 0.08811s (Â±0.002093s); train time: 0.6464s; valid time: 0.9923s; loss: 11.7647 (Â±29.0723); valid loss: -11.1564 (*)\n",
      "[Epoch 4/100, Step 28, ETA 4m 20.85s] Best valid loss updated: from -11.156439 to -22.502321\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 4/100, Step 28, ETA 4m 42.39s] epoch time: 1.614s; step time: 0.08842s (Â±0.002283s); train time: 0.6472s; valid time: 0.9663s; loss: -16.6541 (Â±2.41727); valid loss: -22.5023 (*)\n",
      "[Epoch 5/100, Step 35, ETA 3m 57.43s] Best valid loss updated: from -22.502321 to -30.052658\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 5/100, Step 35, ETA 4m 24.03s] epoch time: 2.129s; step time: 0.0894s (Â±0.001656s); train time: 0.6636s; valid time: 1.465s; loss: -23.9995 (Â±1.91421); valid loss: -30.0527 (*)\n",
      "[Epoch 6/100, Step 42, ETA 3m 48.9s] epoch time: 0.7136s; step time: 0.0881s (Â±0.00189s); train time: 0.646s; valid time: 0.06745s; loss: -25.4691 (Â±3.44038); valid loss: -28.4363\n",
      "[Epoch 7/100, Step 49, ETA 3m 23.71s] Best valid loss updated: from -30.052658 to -31.821498\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 7/100, Step 49, ETA 3m 36.3s] epoch time: 1.669s; step time: 0.08945s (Â±0.001991s); train time: 0.6566s; valid time: 1.012s; loss: -28.0084 (Â±2.24491); valid loss: -31.8215 (*)\n",
      "[Epoch 8/100, Step 56, ETA 3m 15.45s] epoch time: 0.7151s; step time: 0.08839s (Â±0.001949s); train time: 0.6472s; valid time: 0.06778s; loss: -22.4121 (Â±10.3582); valid loss: -24.0525\n",
      "[Epoch 9/100, Step 63, ETA 2m 59.48s] Best valid loss updated: from -31.821498 to -32.325207\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 9/100, Step 63, ETA 3m 16.15s] epoch time: 2.403s; step time: 0.0907s (Â±0.001861s); train time: 0.6798s; valid time: 1.722s; loss: -26.6868 (Â±1.93331); valid loss: -32.3252 (*)\n",
      "[Epoch 10/100, Step 70, ETA 3m 1.45s] Best valid loss updated: from -32.325207 to -33.214508\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 10/100, Step 70, ETA 3m 17.4s] epoch time: 2.533s; step time: 0.09085s (Â±0.002483s); train time: 0.6866s; valid time: 1.846s; loss: -31.3424 (Â±1.8045); valid loss: -33.2145 (*)\n",
      "[Epoch 11/100, Step 77, ETA 3m 3.753s] Best valid loss updated: from -33.214508 to -34.451000\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 11/100, Step 77, ETA 3m 14.23s] epoch time: 2.072s; step time: 0.09078s (Â±0.002423s); train time: 0.6989s; valid time: 1.373s; loss: -33.3591 (Â±1.42789); valid loss: -34.451 (*)\n",
      "[Epoch 12/100, Step 84, ETA 3m 1.311s] epoch time: 0.7175s; step time: 0.08888s (Â±0.002072s); train time: 0.6524s; valid time: 0.065s; loss: -34.0174 (Â±1.49275); valid loss: -34.2266\n",
      "[Epoch 13/100, Step 91, ETA 2m 50.33s] Best valid loss updated: from -34.451000 to -36.092595\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 13/100, Step 91, ETA 2m 57.72s] epoch time: 1.831s; step time: 0.09007s (Â±0.002276s); train time: 0.6603s; valid time: 1.171s; loss: -35.09 (Â±1.11699); valid loss: -36.0926 (*)\n",
      "[Epoch 14/100, Step 98, ETA 2m 47.57s] epoch time: 0.722s; step time: 0.08941s (Â±0.002229s); train time: 0.6541s; valid time: 0.06775s; loss: -36.1947 (Â±1.29192); valid loss: -34.8798\n",
      "[Epoch 15/100, Step 105, ETA 2m 38.69s] Best valid loss updated: from -36.092595 to -37.338932\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 15/100, Step 105, ETA 2m 44.69s] epoch time: 1.783s; step time: 0.09004s (Â±0.001955s); train time: 0.6584s; valid time: 1.124s; loss: -35.0878 (Â±1.79285); valid loss: -37.3389 (*)\n",
      "[Epoch 16/100, Step 112, ETA 2m 36.41s] Best valid loss updated: from -37.338932 to -40.846296\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 16/100, Step 112, ETA 2m 42.34s] epoch time: 1.858s; step time: 0.09033s (Â±0.002488s); train time: 0.6636s; valid time: 1.194s; loss: -38.0093 (Â±1.19322); valid loss: -40.8463 (*)\n",
      "[Epoch 17/100, Step 119, ETA 2m 34.55s] epoch time: 0.7329s; step time: 0.09s (Â±0.002886s); train time: 0.6645s; valid time: 0.06832s; loss: -36.9984 (Â±2.26095); valid loss: -39.4184\n",
      "[Epoch 18/100, Step 126, ETA 2m 27.56s] epoch time: 0.7358s; step time: 0.09121s (Â±0.002354s); train time: 0.6676s; valid time: 0.06809s; loss: -39.0088 (Â±0.995069); valid loss: -39.6518\n",
      "[Epoch 19/100, Step 133, ETA 2m 21.25s] epoch time: 0.7422s; step time: 0.09193s (Â±0.00214s); train time: 0.6752s; valid time: 0.06682s; loss: -39.7787 (Â±1.43565); valid loss: -34.1253\n",
      "[Epoch 20/100, Step 140, ETA 2m 15.61s] epoch time: 0.7687s; step time: 0.0925s (Â±0.004278s); train time: 0.685s; valid time: 0.08354s; loss: -36.3237 (Â±2.422); valid loss: -40.0202\n",
      "[Epoch 20/100, Step 140, ETA 2m 15.61s] Learning rate decreased to 2.5e-05\n",
      "[Epoch 21/100, Step 147, ETA 2m 10.48s] Best valid loss updated: from -40.846296 to -41.699867\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 21/100, Step 147, ETA 2m 17.49s] epoch time: 2.644s; step time: 0.09325s (Â±0.004751s); train time: 0.7062s; valid time: 1.938s; loss: -40.8533 (Â±0.931025); valid loss: -41.6999 (*)\n",
      "[Epoch 22/100, Step 154, ETA 2m 12.72s] Best valid loss updated: from -41.699867 to -42.132775\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 22/100, Step 154, ETA 2m 19.12s] epoch time: 2.691s; step time: 0.1073s (Â±0.02538s); train time: 0.8129s; valid time: 1.878s; loss: -41.9194 (Â±1.57003); valid loss: -42.1328 (*)\n",
      "[Epoch 23/100, Step 161, ETA 2m 14.2s] Best valid loss updated: from -42.132775 to -46.327788\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 23/100, Step 161, ETA 2m 18.48s] epoch time: 2.124s; step time: 0.1036s (Â±0.02307s); train time: 0.7782s; valid time: 1.346s; loss: -43.3352 (Â±1.22893); valid loss: -46.3278 (*)\n",
      "[Epoch 24/100, Step 168, ETA 2m 13.28s] epoch time: 0.7235s; step time: 0.08948s (Â±0.002689s); train time: 0.6546s; valid time: 0.06881s; loss: -43.9412 (Â±1.32839); valid loss: -45.5736\n",
      "[Epoch 25/100, Step 175, ETA 2m 8.467s] epoch time: 0.7335s; step time: 0.09103s (Â±0.00114s); train time: 0.666s; valid time: 0.06741s; loss: -44.2371 (Â±1.15545); valid loss: -46.0387\n",
      "[Epoch 26/100, Step 182, ETA 2m 3.955s] epoch time: 0.7291s; step time: 0.09073s (Â±0.002102s); train time: 0.6622s; valid time: 0.06679s; loss: -46.1962 (Â±1.076); valid loss: -42.2014\n",
      "[Epoch 27/100, Step 189, ETA 1m 59.73s] Best valid loss updated: from -46.327788 to -48.371524\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 27/100, Step 189, ETA 2m 2.978s] epoch time: 1.932s; step time: 0.09059s (Â±0.001342s); train time: 0.6645s; valid time: 1.268s; loss: -45.6651 (Â±2.09105); valid loss: -48.3715 (*)\n",
      "[Epoch 28/100, Step 196, ETA 1m 58.83s] epoch time: 0.728s; step time: 0.0898s (Â±0.002385s); train time: 0.6575s; valid time: 0.07034s; loss: -47.5356 (Â±1.41212); valid loss: -46.2625\n",
      "[Epoch 29/100, Step 203, ETA 1m 54.94s] Best valid loss updated: from -48.371524 to -49.025337\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 29/100, Step 203, ETA 1m 57.92s] epoch time: 1.951s; step time: 0.09039s (Â±0.004031s); train time: 0.6634s; valid time: 1.287s; loss: -45.9956 (Â±0.659363); valid loss: -49.0253 (*)\n",
      "[Epoch 30/100, Step 210, ETA 1m 54.1s] epoch time: 0.7334s; step time: 0.09008s (Â±0.00227s); train time: 0.6602s; valid time: 0.07304s; loss: -47.796 (Â±1.95261); valid loss: -44.2878\n",
      "[Epoch 31/100, Step 217, ETA 1m 50.47s] epoch time: 0.7334s; step time: 0.09065s (Â±0.002016s); train time: 0.6637s; valid time: 0.06963s; loss: -46.9841 (Â±1.63374); valid loss: -47.2175\n",
      "[Epoch 32/100, Step 224, ETA 1m 47.09s] epoch time: 0.7602s; step time: 0.09211s (Â±0.002806s); train time: 0.685s; valid time: 0.07504s; loss: -46.4431 (Â±2.25525); valid loss: -38.9145\n",
      "[Epoch 33/100, Step 231, ETA 1m 43.89s] epoch time: 0.7754s; step time: 0.0918s (Â±0.001923s); train time: 0.699s; valid time: 0.07627s; loss: -44.1349 (Â±2.39801); valid loss: -48.2225\n",
      "[Epoch 34/100, Step 238, ETA 1m 40.83s] epoch time: 0.7747s; step time: 0.09241s (Â±0.002503s); train time: 0.701s; valid time: 0.07352s; loss: -45.9889 (Â±1.84022); valid loss: -46.4279\n",
      "[Epoch 35/100, Step 245, ETA 1m 37.91s] Best valid loss updated: from -49.025337 to -49.165690\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 35/100, Step 245, ETA 1m 41.64s] epoch time: 2.786s; step time: 0.09258s (Â±0.001757s); train time: 0.6967s; valid time: 2.089s; loss: -47.6498 (Â±0.753334); valid loss: -49.1657 (*)\n",
      "[Epoch 36/100, Step 252, ETA 1m 38.83s] Best valid loss updated: from -49.165690 to -50.700043\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 36/100, Step 252, ETA 1m 41.35s] epoch time: 2.278s; step time: 0.1045s (Â±0.02528s); train time: 0.7844s; valid time: 1.493s; loss: -47.7908 (Â±2.31485); valid loss: -50.7 (*)\n",
      "[Epoch 37/100, Step 259, ETA 1m 38.31s] epoch time: 0.7265s; step time: 0.09008s (Â±0.001492s); train time: 0.6595s; valid time: 0.06689s; loss: -43.6062 (Â±4.15661); valid loss: -46.5414\n",
      "[Epoch 38/100, Step 266, ETA 1m 35.4s] epoch time: 0.735s; step time: 0.09121s (Â±0.002383s); train time: 0.6666s; valid time: 0.06822s; loss: -46.268 (Â±2.19242); valid loss: -46.7874\n",
      "[Epoch 39/100, Step 273, ETA 1m 32.61s] epoch time: 0.7354s; step time: 0.091s (Â±0.001626s); train time: 0.6648s; valid time: 0.07054s; loss: -46.528 (Â±2.54814); valid loss: -45.6919\n",
      "[Epoch 40/100, Step 280, ETA 1m 29.91s] epoch time: 0.7318s; step time: 0.09102s (Â±0.001275s); train time: 0.665s; valid time: 0.06664s; loss: -47.5225 (Â±1.48578); valid loss: -49.0118\n",
      "[Epoch 40/100, Step 280, ETA 1m 29.91s] Learning rate decreased to 1.25e-05\n",
      "[Epoch 41/100, Step 287, ETA 1m 27.31s] Best valid loss updated: from -50.700043 to -51.185194\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 41/100, Step 287, ETA 1m 29.17s] epoch time: 2.026s; step time: 0.09125s (Â±0.001865s); train time: 0.6668s; valid time: 1.359s; loss: -50.3706 (Â±0.95556); valid loss: -51.1852 (*)\n",
      "[Epoch 42/100, Step 294, ETA 1m 26.59s] Best valid loss updated: from -51.185194 to -51.733378\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 42/100, Step 294, ETA 1m 28.43s] epoch time: 2.069s; step time: 0.09011s (Â±0.002357s); train time: 0.6646s; valid time: 1.404s; loss: -51.6429 (Â±0.463014); valid loss: -51.7334 (*)\n",
      "[Epoch 43/100, Step 301, ETA 1m 25.86s] Best valid loss updated: from -51.733378 to -53.288038\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 43/100, Step 301, ETA 1m 27.8s] epoch time: 2.192s; step time: 0.09016s (Â±0.002605s); train time: 0.6617s; valid time: 1.53s; loss: -52.3542 (Â±0.4467); valid loss: -53.288 (*)\n",
      "[Epoch 44/100, Step 308, ETA 1m 25.29s] Best valid loss updated: from -53.288038 to -53.369991\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 44/100, Step 308, ETA 1m 28.14s] epoch time: 3.022s; step time: 0.09238s (Â±0.002555s); train time: 0.7064s; valid time: 2.315s; loss: -52.9639 (Â±0.340734); valid loss: -53.37 (*)\n",
      "[Epoch 45/100, Step 315, ETA 1m 25.7s] epoch time: 0.8582s; step time: 0.1045s (Â±0.02407s); train time: 0.7808s; valid time: 0.07716s; loss: -52.9369 (Â±0.638485); valid loss: -53.055\n",
      "[Epoch 46/100, Step 322, ETA 1m 23.24s] epoch time: 0.7899s; step time: 0.09444s (Â±0.003813s); train time: 0.7117s; valid time: 0.07807s; loss: -53.442 (Â±0.865335); valid loss: -50.8837\n",
      "[Epoch 47/100, Step 329, ETA 1m 20.85s] Best valid loss updated: from -53.369991 to -54.752365\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 47/100, Step 329, ETA 1m 22.68s] epoch time: 2.412s; step time: 0.09275s (Â±0.00145s); train time: 0.7117s; valid time: 1.701s; loss: -52.5779 (Â±1.64524); valid loss: -54.7524 (*)\n",
      "[Epoch 48/100, Step 336, ETA 1m 20.22s] epoch time: 0.7291s; step time: 0.09022s (Â±0.001989s); train time: 0.6612s; valid time: 0.06783s; loss: -54.118 (Â±0.973307); valid loss: -54.5939\n",
      "[Epoch 49/100, Step 343, ETA 1m 17.84s] epoch time: 0.7422s; step time: 0.09191s (Â±0.00248s); train time: 0.6723s; valid time: 0.06985s; loss: -54.2141 (Â±1.0053); valid loss: -54.392\n",
      "[Epoch 50/100, Step 350, ETA 1m 15.53s] Best valid loss updated: from -54.752365 to -55.040047\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 50/100, Step 350, ETA 1m 16.97s] epoch time: 2.177s; step time: 0.09135s (Â±0.002333s); train time: 0.6689s; valid time: 1.508s; loss: -53.8083 (Â±1.02565); valid loss: -55.04 (*)\n",
      "[Epoch 51/100, Step 357, ETA 1m 14.66s] epoch time: 0.7388s; step time: 0.09108s (Â±0.002099s); train time: 0.6681s; valid time: 0.07058s; loss: -54.4597 (Â±0.80711); valid loss: -53.6058\n",
      "[Epoch 52/100, Step 364, ETA 1m 12.42s] Best valid loss updated: from -55.040047 to -56.536349\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 52/100, Step 364, ETA 1m 13.76s] epoch time: 2.197s; step time: 0.09149s (Â±0.001846s); train time: 0.6723s; valid time: 1.525s; loss: -53.5379 (Â±3.20427); valid loss: -56.5363 (*)\n",
      "[Epoch 53/100, Step 371, ETA 1m 11.51s] epoch time: 0.7346s; step time: 0.09066s (Â±0.001519s); train time: 0.6652s; valid time: 0.06935s; loss: -50.0989 (Â±4.54932); valid loss: -53.7391\n",
      "[Epoch 54/100, Step 378, ETA 1m 9.328s] epoch time: 0.7406s; step time: 0.09201s (Â±0.002061s); train time: 0.6724s; valid time: 0.06808s; loss: -52.6512 (Â±1.1051); valid loss: -50.9333\n",
      "[Epoch 55/100, Step 385, ETA 1m 7.197s] epoch time: 0.7447s; step time: 0.09181s (Â±0.001812s); train time: 0.6738s; valid time: 0.07083s; loss: -53.2366 (Â±1.12231); valid loss: -55.2495\n",
      "[Epoch 56/100, Step 392, ETA 1m 5.138s] epoch time: 0.7733s; step time: 0.09208s (Â±0.001506s); train time: 0.6936s; valid time: 0.07959s; loss: -51.1744 (Â±2.85342); valid loss: -52.0344\n",
      "[Epoch 57/100, Step 399, ETA 1m 3.131s] epoch time: 0.7817s; step time: 0.09282s (Â±0.001666s); train time: 0.704s; valid time: 0.07758s; loss: -52.5237 (Â±1.3356); valid loss: -51.8644\n",
      "[Epoch 58/100, Step 406, ETA 1m 1.161s] epoch time: 0.7748s; step time: 0.09194s (Â±0.001824s); train time: 0.6948s; valid time: 0.07984s; loss: -53.105 (Â±1.07208); valid loss: -52.2234\n",
      "[Epoch 59/100, Step 413, ETA 59.24s] epoch time: 0.7928s; step time: 0.09435s (Â±0.001653s); train time: 0.7123s; valid time: 0.08047s; loss: -53.7766 (Â±0.911474); valid loss: -52.6076\n",
      "[Epoch 60/100, Step 420, ETA 57.35s] epoch time: 0.7744s; step time: 0.09316s (Â±0.002202s); train time: 0.701s; valid time: 0.07325s; loss: -53.98 (Â±0.643774); valid loss: -54.5937\n",
      "[Epoch 60/100, Step 420, ETA 57.35s] Learning rate decreased to 6.25e-06\n",
      "[Epoch 61/100, Step 427, ETA 55.5s] epoch time: 0.7827s; step time: 0.09358s (Â±0.002604s); train time: 0.7056s; valid time: 0.07693s; loss: -55.6536 (Â±0.829585); valid loss: -55.3309\n",
      "[Epoch 62/100, Step 434, ETA 53.69s] Best valid loss updated: from -56.536349 to -57.774144\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 62/100, Step 434, ETA 54.81s] epoch time: 2.618s; step time: 0.09423s (Â±0.002254s); train time: 0.7091s; valid time: 1.909s; loss: -56.8729 (Â±0.768027); valid loss: -57.7741 (*)\n",
      "[Epoch 63/100, Step 441, ETA 53.01s] epoch time: 0.8305s; step time: 0.1044s (Â±0.02213s); train time: 0.7621s; valid time: 0.06827s; loss: -56.2121 (Â±1.22085); valid loss: -57.3977\n",
      "[Epoch 64/100, Step 448, ETA 51.19s] epoch time: 0.7412s; step time: 0.09211s (Â±0.001485s); train time: 0.6734s; valid time: 0.06767s; loss: -57.363 (Â±0.425817); valid loss: -57.1776\n",
      "[Epoch 65/100, Step 455, ETA 49.4s] Best valid loss updated: from -57.774144 to -58.452634\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 65/100, Step 455, ETA 50.24s] epoch time: 2.298s; step time: 0.0923s (Â±0.001226s); train time: 0.675s; valid time: 1.623s; loss: -57.895 (Â±0.392208); valid loss: -58.4526 (*)\n",
      "[Epoch 66/100, Step 462, ETA 48.45s] epoch time: 0.7372s; step time: 0.09127s (Â±0.001959s); train time: 0.6682s; valid time: 0.06891s; loss: -58.2133 (Â±0.575303); valid loss: -57.9499\n",
      "[Epoch 67/100, Step 469, ETA 46.69s] epoch time: 0.7469s; step time: 0.09269s (Â±0.002695s); train time: 0.6769s; valid time: 0.06989s; loss: -58.2059 (Â±0.167788); valid loss: -58.0996\n",
      "[Epoch 68/100, Step 476, ETA 44.96s] epoch time: 0.7413s; step time: 0.09198s (Â±0.001706s); train time: 0.6748s; valid time: 0.06639s; loss: -58.8599 (Â±0.388773); valid loss: -56.4884\n",
      "[Epoch 69/100, Step 483, ETA 43.25s] Best valid loss updated: from -58.452634 to -59.481464\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 69/100, Step 483, ETA 43.96s] epoch time: 2.316s; step time: 0.09214s (Â±0.001382s); train time: 0.6732s; valid time: 1.643s; loss: -57.9148 (Â±1.11707); valid loss: -59.4815 (*)\n",
      "[Epoch 70/100, Step 490, ETA 42.26s] Best valid loss updated: from -59.481464 to -59.801983\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 70/100, Step 490, ETA 43.29s] epoch time: 3.15s; step time: 0.09158s (Â±0.002564s); train time: 0.6721s; valid time: 2.477s; loss: -58.9305 (Â±0.424335); valid loss: -59.802 (*)\n",
      "[Epoch 71/100, Step 497, ETA 41.62s] epoch time: 0.8851s; step time: 0.1076s (Â±0.02116s); train time: 0.8086s; valid time: 0.0763s; loss: -58.95 (Â±0.859143); valid loss: -58.761\n",
      "[Epoch 72/100, Step 504, ETA 39.93s] epoch time: 0.7806s; step time: 0.09359s (Â±0.00185s); train time: 0.7068s; valid time: 0.0737s; loss: -58.9592 (Â±0.760813); valid loss: -58.8254\n",
      "[Epoch 73/100, Step 511, ETA 38.27s] epoch time: 0.7862s; step time: 0.09372s (Â±0.002357s); train time: 0.7054s; valid time: 0.08066s; loss: -59.6086 (Â±0.380464); valid loss: -58.619\n",
      "[Epoch 74/100, Step 518, ETA 36.63s] Best valid loss updated: from -59.801983 to -60.430517\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 74/100, Step 518, ETA 37.26s] epoch time: 2.596s; step time: 0.0937s (Â±0.002195s); train time: 0.7079s; valid time: 1.888s; loss: -59.4085 (Â±0.758917); valid loss: -60.4305 (*)\n",
      "[Epoch 75/100, Step 525, ETA 35.63s] epoch time: 0.8398s; step time: 0.1058s (Â±0.02062s); train time: 0.771s; valid time: 0.06871s; loss: -59.2101 (Â±1.27165); valid loss: -59.8576\n",
      "[Epoch 76/100, Step 532, ETA 33.99s] epoch time: 0.7505s; step time: 0.09278s (Â±0.001984s); train time: 0.68s; valid time: 0.07037s; loss: -59.8032 (Â±0.395447); valid loss: -60.1919\n",
      "[Epoch 77/100, Step 539, ETA 32.38s] epoch time: 0.7422s; step time: 0.09215s (Â±0.001973s); train time: 0.6741s; valid time: 0.068s; loss: -59.8676 (Â±0.590635); valid loss: -58.0935\n",
      "[Epoch 78/100, Step 546, ETA 30.78s] Best valid loss updated: from -60.430517 to -60.575652\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 78/100, Step 546, ETA 31.25s] epoch time: 2.394s; step time: 0.09294s (Â±0.001619s); train time: 0.6784s; valid time: 1.715s; loss: -59.6864 (Â±0.96039); valid loss: -60.5757 (*)\n",
      "[Epoch 79/100, Step 553, ETA 29.65s] epoch time: 0.7431s; step time: 0.09158s (Â±0.002089s); train time: 0.6732s; valid time: 0.06982s; loss: -58.8668 (Â±1.53692); valid loss: -59.2629\n",
      "[Epoch 80/100, Step 560, ETA 28.07s] epoch time: 0.7504s; step time: 0.09324s (Â±0.002307s); train time: 0.6822s; valid time: 0.06805s; loss: -59.5407 (Â±1.11016); valid loss: -57.36\n",
      "[Epoch 80/100, Step 560, ETA 28.07s] Learning rate decreased to 3.125e-06\n",
      "[Epoch 81/100, Step 567, ETA 26.51s] epoch time: 0.7479s; step time: 0.09273s (Â±0.001299s); train time: 0.68s; valid time: 0.06777s; loss: -59.2311 (Â±1.21408); valid loss: -59.8893\n",
      "[Epoch 82/100, Step 574, ETA 24.98s] Best valid loss updated: from -60.575652 to -60.993352\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 82/100, Step 574, ETA 25.45s] epoch time: 2.883s; step time: 0.09219s (Â±0.001477s); train time: 0.6756s; valid time: 2.207s; loss: -60.5373 (Â±0.428436); valid loss: -60.9934 (*)\n",
      "[Epoch 83/100, Step 581, ETA 23.92s] Best valid loss updated: from -60.993352 to -61.486587\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 83/100, Step 581, ETA 24.46s] epoch time: 3.505s; step time: 0.1082s (Â±0.02108s); train time: 0.8082s; valid time: 2.697s; loss: -61.1147 (Â±0.579291); valid loss: -61.4866 (*)\n",
      "[Epoch 84/100, Step 588, ETA 22.92s] Best valid loss updated: from -61.486587 to -61.570064\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 84/100, Step 588, ETA 23.3s] epoch time: 2.902s; step time: 0.1095s (Â±0.02553s); train time: 0.8177s; valid time: 2.084s; loss: -61.4899 (Â±0.183845); valid loss: -61.5701 (*)\n",
      "[Epoch 85/100, Step 595, ETA 21.73s] epoch time: 0.8243s; step time: 0.1034s (Â±0.02382s); train time: 0.7558s; valid time: 0.06838s; loss: -61.5906 (Â±0.333038); valid loss: -61.4453\n",
      "[Epoch 86/100, Step 602, ETA 20.17s] Best valid loss updated: from -61.570064 to -61.691965\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 86/100, Step 602, ETA 20.47s] epoch time: 2.602s; step time: 0.09271s (Â±0.002221s); train time: 0.6777s; valid time: 1.924s; loss: -61.603 (Â±0.300226); valid loss: -61.692 (*)\n",
      "[Epoch 87/100, Step 609, ETA 18.92s] epoch time: 0.8229s; step time: 0.1026s (Â±0.02419s); train time: 0.7508s; valid time: 0.07201s; loss: -61.7471 (Â±0.25469); valid loss: -61.454\n",
      "[Epoch 88/100, Step 616, ETA 17.37s] Best valid loss updated: from -61.691965 to -61.821775\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 88/100, Step 616, ETA 17.62s] epoch time: 2.644s; step time: 0.09341s (Â±0.001592s); train time: 0.6837s; valid time: 1.961s; loss: -61.815 (Â±0.255437); valid loss: -61.8218 (*)\n",
      "[Epoch 89/100, Step 623, ETA 16.08s] Best valid loss updated: from -61.821775 to -61.986488\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 89/100, Step 623, ETA 16.39s] epoch time: 3.4s; step time: 0.1058s (Â±0.02113s); train time: 0.7752s; valid time: 2.624s; loss: -62.0226 (Â±0.306011); valid loss: -61.9865 (*)\n",
      "[Epoch 90/100, Step 630, ETA 14.84s] Best valid loss updated: from -61.986488 to -62.212774\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 90/100, Step 630, ETA 15.16s] epoch time: 3.752s; step time: 0.1082s (Â±0.02102s); train time: 0.8108s; valid time: 2.941s; loss: -62.1408 (Â±0.249258); valid loss: -62.2128 (*)\n",
      "[Epoch 91/100, Step 637, ETA 13.57s] epoch time: 0.8468s; step time: 0.1043s (Â±0.02455s); train time: 0.7754s; valid time: 0.07122s; loss: -62.1927 (Â±0.34811); valid loss: -61.4689\n",
      "[Epoch 92/100, Step 644, ETA 12s] epoch time: 0.7481s; step time: 0.09263s (Â±0.001441s); train time: 0.6793s; valid time: 0.0687s; loss: -62.2072 (Â±0.629326); valid loss: -61.4073\n",
      "[Epoch 93/100, Step 651, ETA 10.44s] epoch time: 0.7517s; step time: 0.09305s (Â±0.001902s); train time: 0.683s; valid time: 0.06854s; loss: -62.3971 (Â±0.503149); valid loss: -61.5683\n",
      "[Epoch 94/100, Step 658, ETA 8.905s] Best valid loss updated: from -62.212774 to -62.441154\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 94/100, Step 658, ETA 9.034s] epoch time: 2.767s; step time: 0.09244s (Â±0.001583s); train time: 0.6789s; valid time: 2.088s; loss: -61.5706 (Â±1.25335); valid loss: -62.4412 (*)\n",
      "[Epoch 95/100, Step 665, ETA 7.494s] epoch time: 0.8554s; step time: 0.1076s (Â±0.02272s); train time: 0.7871s; valid time: 0.06823s; loss: -61.1865 (Â±1.0965); valid loss: -58.9506\n",
      "[Epoch 96/100, Step 672, ETA 5.964s] epoch time: 0.7529s; step time: 0.09276s (Â±0.001566s); train time: 0.6848s; valid time: 0.06798s; loss: -60.2009 (Â±1.72995); valid loss: -61.4\n",
      "[Epoch 97/100, Step 679, ETA 4.45s] Best valid loss updated: from -62.441154 to -62.651495\n",
      "Model saved at results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01.\n",
      "[Epoch 97/100, Step 679, ETA 4.511s] epoch time: 2.721s; step time: 0.09276s (Â±0.001454s); train time: 0.6815s; valid time: 2.039s; loss: -61.7082 (Â±0.653286); valid loss: -62.6515 (*)\n",
      "[Epoch 98/100, Step 686, ETA 2.994s] epoch time: 0.8425s; step time: 0.1052s (Â±0.02389s); train time: 0.7716s; valid time: 0.07081s; loss: -62.1937 (Â±0.494119); valid loss: -62.2344\n",
      "[Epoch 99/100, Step 693, ETA 1.49s] epoch time: 0.7866s; step time: 0.09382s (Â±0.002233s); train time: 0.7035s; valid time: 0.08295s; loss: -62.4665 (Â±0.270118); valid loss: -62.3105\n",
      "[Epoch 100/100, Step 700, ETA 0s] epoch time: 0.786s; step time: 0.09365s (Â±0.001486s); train time: 0.7089s; valid time: 0.07693s; loss: -62.6503 (Â±0.276997); valid loss: -62.1785\n",
      "[Epoch 100/100, Step 700, ETA 0s] Learning rate decreased to 1.5625e-06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpnhn56oc2/variables.dat-679\n",
      "2023-12-12 20:28:37,790 [INFO] tensorflow: Restoring parameters from /tmp/tmpnhn56oc2/variables.dat-679\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'best_valid_loss': -62.651494943412246,\n",
      " 'pred_time': 0.03150501110637928,\n",
      " 'pred_total_time': 104.88886547088623,\n",
      " 'train_time': 1.4883687376976014,\n",
      " 'valid_time': 0.03396685242652893}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpfkbdg05mwandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp2xmimkkowandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmptn86puefwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpt8u2kweuwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test transfer-learned model"
   ],
   "metadata": {
    "id": "zd_RkfIW8LEW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%shell\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate myenv\n",
    "python main.py --dataset_folder=/content/processed_st12000 --save_dir=results/tuned_model_st8000_2_exp3_test --max_epoch=0 --restore_dir=results/tuned_model_st8000_2_exp3 --scaler_path=results/tuned_model_st8000_2_exp3/results/scaler.pkl"
   ],
   "metadata": {
    "id": "GrQ8OUbx8Nb4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702400022746,
     "user_tz": 300,
     "elapsed": 513720,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "83bdae3b-55a9-4350-b85a-8b59329a69bc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/csc2233-2023/omni_anomaly/vae.py:378: DeprecationWarning: invalid escape sequence \\*\n",
      "  \"\"\"\n",
      "/content/csc2233-2023/omni_anomaly/vae.py:419: DeprecationWarning: invalid escape sequence \\*\n",
      "  \"\"\"\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/tfver.py:22: DeprecationWarning: Function 'semver.compare' is deprecated. Deprecated since version 2.10.0.  This function will be removed in semver 3. Use the respective 'semver.VersionInfo.compare' instead.\n",
      "  compare_result = semver.compare(version, tf.__version__)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "/usr/local/envs/myenv/lib/python3.6/site-packages/tfsnippet/utils/config_utils.py:394: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  value = yaml.load(values)\n",
      "Configurations\n",
      "=======================================================================\n",
      "{'batch_size': 512,\n",
      " 'dataset_folder': '/content/processed_st12000',\n",
      " 'dense_dim': 500,\n",
      " 'early_stopping_patience': 20,\n",
      " 'get_score_on_dim': False,\n",
      " 'gradient_clip_norm': 10.0,\n",
      " 'hyperparameter_search': False,\n",
      " 'initial_lr': 5e-05,\n",
      " 'lr_anneal_epoch_freq': 20,\n",
      " 'lr_anneal_factor': 0.5,\n",
      " 'max_epoch': 0,\n",
      " 'nf_layers': 20,\n",
      " 'posterior_flow_type': 'None',\n",
      " 'restore_dir': 'results/tuned_model_st8000_2_exp3',\n",
      " 'rnn_cell': 'LSTM',\n",
      " 'rnn_num_hidden': 500,\n",
      " 'save_dir': 'results/tuned_model_st8000_2_exp3_test',\n",
      " 'save_z': False,\n",
      " 'scaler_path': 'results/tuned_model_st8000_2_exp3/results/scaler.pkl',\n",
      " 'std_epsilon': 0.0001,\n",
      " 'sweepID': None,\n",
      " 'test_batch_size': 512,\n",
      " 'test_n_z': 1,\n",
      " 'test_score_filename': 'test_score.pkl',\n",
      " 'train_days_per_disk': None,\n",
      " 'train_portion': None,\n",
      " 'train_score_filename': 'train_score.pkl',\n",
      " 'train_start': 0,\n",
      " 'use_connected_z_p': False,\n",
      " 'use_connected_z_q': False,\n",
      " 'valid_portion': 0.2,\n",
      " 'window_length': 25,\n",
      " 'x_dim': 15,\n",
      " 'z_dim': 3}\n",
      "\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (5095382, 16)\n",
      "test set shape:  (1493061, 16)\n",
      "WARNING:tensorflow:From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 16:45:28,485 [WARNING] tensorflow: From /content/csc2233-2023/omni_anomaly/wrapper.py:103: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "2023-12-12 16:45:34.548171: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-12 16:45:34.832224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-12 16:45:34.832477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 14.75GiB freeMemory: 14.65GiB\n",
      "2023-12-12 16:45:34.832515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2023-12-12 16:45:35.264841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-12 16:45:35.266083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2023-12-12 16:45:35.266121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2023-12-12 16:45:35.266232: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-12 16:45:35.266277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14169 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13/variables.dat\n",
      "2023-12-12 16:45:35,352 [INFO] tensorflow: Restoring parameters from /content/drive/MyDrive/CSC2233/tuned_model_st8000_2_exp3_2023-12-11_14-50-13/variables.dat\n",
      "Variables restored from results/tuned_model_st8000_2_exp3.\n",
      "Start val loss: inf\n",
      "------------------------------ testing ------------------------------\n",
      "==============================result==============================\n",
      "{'pred_time': 0.033006852483111866, 'pred_total_time': 109.8865294456482}\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp24q5b9c2wandb'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpev3jkduwwandb-artifacts'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpf7qbca7xwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "/usr/local/envs/myenv/lib/python3.6/tempfile.py:800: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpr1qokyvjwandb-media'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git diff"
   ],
   "metadata": {
    "id": "jjpF1IpD6KWC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1701524770942,
     "user_tz": 300,
     "elapsed": 12372,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "9ce143cf-8951-4668-c939-7a85818e2bb6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "^C\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git add ."
   ],
   "metadata": {
    "id": "fW6WsvoHFKXJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!git config --global user.email \"nick@hauptvogel.cc\"\n",
    "!git config --global user.name \"Nick Hauptvogel Colab\"\n",
    "!git commit -m \"results\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsdiBPOxIdE9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702413333524,
     "user_tz": 300,
     "elapsed": 394,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "0fca736f-374c-44a4-9044-9be62a696dc2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[master 47f1d86] results\n",
      " 18 files changed, 8 insertions(+)\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/latest\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/results/config.defaults.json\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/results/config.json\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/results/scaler.pkl\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/results/test_score.pkl\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/results/train_score.pkl\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/variables.dat.data-00000-of-00001\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/variables.dat.index\n",
      " create mode 100644 results/tuned_model_st8000_2_exp2b_0_1p_2023-12-12_20-26-01/variables.dat.meta\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/latest\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/results/config.defaults.json\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/results/config.json\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/results/scaler.pkl\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/results/test_score.pkl\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/results/train_score.pkl\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/variables.dat.data-00000-of-00001\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/variables.dat.index\n",
      " create mode 100644 results/tuned_model_st8000_2_exp4_0_1p_2023-12-12_20-30-38/variables.dat.meta\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git push https://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@github.com/NickHauptvogel/csc2233-2023.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-UUH7NbLfOC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702413346786,
     "user_tz": 300,
     "elapsed": 11224,
     "user": {
      "displayName": "Nick",
      "userId": "01362377837326549481"
     }
    },
    "outputId": "67ea6e41-6659-4da5-b2e2-698ab41e53e3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Enumerating objects: 25, done.\n",
      "Counting objects:   4% (1/25)\rCounting objects:   8% (2/25)\rCounting objects:  12% (3/25)\rCounting objects:  16% (4/25)\rCounting objects:  20% (5/25)\rCounting objects:  24% (6/25)\rCounting objects:  28% (7/25)\rCounting objects:  32% (8/25)\rCounting objects:  36% (9/25)\rCounting objects:  40% (10/25)\rCounting objects:  44% (11/25)\rCounting objects:  48% (12/25)\rCounting objects:  52% (13/25)\rCounting objects:  56% (14/25)\rCounting objects:  60% (15/25)\rCounting objects:  64% (16/25)\rCounting objects:  68% (17/25)\rCounting objects:  72% (18/25)\rCounting objects:  76% (19/25)\rCounting objects:  80% (20/25)\rCounting objects:  84% (21/25)\rCounting objects:  88% (22/25)\rCounting objects:  92% (23/25)\rCounting objects:  96% (24/25)\rCounting objects: 100% (25/25)\rCounting objects: 100% (25/25), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects: 100% (23/23), done.\n",
      "Writing objects: 100% (23/23), 74.75 MiB | 10.16 MiB/s, done.\n",
      "Total 23 (delta 6), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (6/6), completed with 2 local objects.\u001B[K\n",
      "To https://github.com/NickHauptvogel/csc2233-2023.git\n",
      "   386be79..47f1d86  master -> master\n"
     ]
    }
   ]
  }
 ]
}
